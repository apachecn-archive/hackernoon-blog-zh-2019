# 声音:不可见界面的剖析

> 原文：<https://medium.com/hackernoon/voice-anatomy-of-the-invisible-interface-28f5635a9091>

![](img/16cfddc8fd867ffe92b3fe46116aad42.png)

我 7 岁的孩子第一次与电脑互动是通过语音。他让苹果 Siri 回答一些琐事，比如“哪辆车最快？”。我们买亚马逊 Echo 的时候，父亲指挥 Alexa 唱老歌。基于语音的交互在我们的日常生活中变得无处不在。我们可以在苹果 Siri 等智能手机、亚马逊 Alexa、谷歌 Home 等语音助手以及一系列其他产品中找到它们。很明显，基于语音的交互将很快取代图形用户界面。据行业专家称，在未来 2-3 年内，30 %的设备交互将通过语音进行。

## **语音是一种自然的交互方式**

长期以来，用户通过在键盘上键入命令或使用图形用户界面(GUI)来与计算机进行交互。GUI 或通过键盘输入命令需要用户在每次交互时学习界面和回忆。这经常导致用户和计算机之间的摩擦。声音减少了摩擦，就像魔术一样。对设备说几句话就能实现愿望。语音是一种自然的交互方式。

## **我们终于为声音做好了准备**

语音识别并不新鲜，它已经存在了一段时间。 [IBM 鞋盒](https://en.wikipedia.org/wiki/IBM_Shoebox)是 20 世纪 60 年代最先进的语音识别机。这种软件需要长时间的训练来学习特定的版本，受到计算能力的限制。我们现在处于计算廉价的时代，计算机和电话在世界各地的快速渗透使得机器学习算法可以使用来自互联网的数百万样本进行训练。它赋予系统识别几乎任何人的语音的能力。

![](img/2d614ea64bfa950d63c2fc46f58dee5f.png)

**Voice makes experience personal**

## **声音让体验变得个性化**

像 Siri、Alexa 这样的语音助手节省了查看天气、点餐、播放音乐、回复信息等日常任务的时间。它们让体验更加个性化。

## **设计基于语音的交互**

设计基于语音的交互包括三个关键因素:意图、话语和时间段。

让我们分析下面的请求:“在 Alexa 上播放放松的音乐。”

**意图(语音交互的目的)** 意图表示用户语音命令的更广泛的目的。在这个例子中，意图很明显:用户想要听音乐。

**话语(用户如何表达命令)** 话语反映了用户如何表达他们的请求。在给定的例子中，我们知道用户想通过说“播放我…”在 Alexa 上播放音乐，但这并不是用户发出这一请求的唯一方式。例如，用户也可以说，“我想听音乐……”

你需要考虑话语的每一种变化。这将有助于引擎识别请求，并将其链接到正确的操作或响应。

**Slots(必需的或可选的变量)** 有时仅仅有一个意图是不够的，为了满足请求，需要用户提供更多的信息。Alexa 称之为“插槽”，插槽就像传统的表单字段一样，可以是可选的，也可以是必需的，这取决于完成请求需要什么。在我们的例子中，这个槽是“放松的”，但是因为没有它请求仍然可以完成，所以这个槽是可选的。

## **挑战**

虽然计算机可以更可靠地识别语音，听起来也更自然，但它们不理解上下文。例如，苹果 Siri 不理解上下文，它只是说我听不懂。对简单的命令做出反应是好的，但很不幸地无法理解上下文，无法进行对话。如果它需要蓬勃发展并被消费者广泛接受，就需要克服这个障碍。

## **结论**

当道格拉斯·恩格尔巴特展示如何使用键盘和鼠标时，它改变了我们与计算机互动的方式。语音同样有可能极大地改变我们与计算机互动的方式。对语音的需求是真实的，早期体验对用户与计算机交互的方式有积极的影响。希望这能通向无障碍世界。