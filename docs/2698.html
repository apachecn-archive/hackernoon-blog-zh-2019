<html>
<head>
<title>How to choose optimal hardware for neural network inference. Study of AWS GPUs and Elastic Inference Accelerators.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络推理如何选择最优硬件？AWS GPUs和弹性推理加速器的研究。</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-choose-optimal-hardware-for-neural-network-inference-36c2188269ad?source=collection_archive---------11-----------------------#2019-04-26">https://medium.com/hackernoon/how-to-choose-optimal-hardware-for-neural-network-inference-36c2188269ad?source=collection_archive---------11-----------------------#2019-04-26</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="2f9d" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">我在4种不同的神经架构中测量了各种AWS硬件选项的性能，重点是推理。这是我的发现。</h2></div><h1 id="d85b" class="jj jk hu bd jl jm jn jo jp jq jr js jt ja ju jb jv jd jw je jx jg jy jh jz ka dt translated">急什么？</h1><figure class="kc kd ke kf fq kg fe ff paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="fe ff kb"><img src="../Images/2f832b3a6692dd6db63dd17177e18374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xinnWqG_6WICrvLakx5Asg.png"/></div></div></figure><p id="098d" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">AWS为神经网络推理和训练提供了广泛的GPU设备。这里有一个众所周知的事实:90%的神经网络成本用于神经网络推理(实际使用它们)，只有10%用于训练。所以，优化推理对业务单位经济有更大的影响。我在Skylum Software运营一个人工智能部门，我们为大型B2B企业提供基于神经网络的图像处理云解决方案。自然，推理的成本对我们很重要。</p><p id="13e6" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">在神经网络推理上省钱包括几个阶段。</p><p id="2f62" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">首先，当然是优化神经网络本身。有各种各样的技术——修剪和提取，量化是几个主要的。我不打算在这里讨论这个。另一种是将计算转换为float16精度，这需要特定的软件，这里没有几个例子。另一个是选择最佳的硬件进行推理。</p><h2 id="9ec9" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">为什么这不明显？</h2><p id="75e7" class="pw-post-body-paragraph kn ko hu kp b kq lx iv ks kt ly iy kv kw lz ky kz la ma lc ld le mb lg lh li hn dt translated">这里的要点很简单。我们用于训练的GPU和软件针对训练进行了优化，而不是推理。GPU的内存很大，可以存储大批量的训练样本以及用于反向传播的梯度。当我们有稳定的批量数据流时，我们能够利用快速和大容量的内存，并实现接近100%的GPU功率利用率。<br/>通常在推断过程中，我们无法获得足够多的数据来将它们打包成稳定的批次流。等待足够的数据将导致对业务来说致命的延迟。因此，现实世界的推断可能适用于小批量的样本(1-4)，并侧重于延迟。这没有充分利用GPU的能力，使它们效率低下。经常，但不总是。</p><h2 id="fec3" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">亚马逊的AWS解决方案</h2><p id="f2e8" class="pw-post-body-paragraph kn ko hu kp b kq lx iv ks kt ly iy kv kw lz ky kz la ma lc ld le mb lg lh li hn dt translated">亚马逊想出了解决上述问题的方法——弹性推理加速器。这些是未知架构的设备(至少对我来说是这样),专门用于对小批量数据进行快速推断。它们配备了比GPU少得多的内存(1Gb-4Gb)和更低的处理能力，但也便宜得多。</p><h1 id="ec3f" class="jj jk hu bd jl jm jn jo jp jq jr js jt ja ju jb jv jd jw je jx jg jy jh jz ka dt translated">性能和成本节约分析。</h1><h2 id="a4b8" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">硬件和型号的选择。</h2><p id="754a" class="pw-post-body-paragraph kn ko hu kp b kq lx iv ks kt ly iy kv kw lz ky kz la ma lc ld le mb lg lh li hn dt translated">为了进行这项研究，我选择了4种硬件设置:</p><ul class=""><li id="f354" class="mc md hu kp b kq kr kt ku kw me la mf le mg li mh mi mj mk dt translated">p2.xlarge .最早的GPU产品。</li><li id="3726" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">p 3.4x大型顶级GPU卡，完全支持float16。</li><li id="2036" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">g3.4xlarge. GPU，内存有限(8Gb)，专注于软件的3D加速。不明显，但非常有趣的设备。</li><li id="c72a" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">eia.large .最大的(4Gb) AWS弹性加速器产品。</li></ul><p id="cde4" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">对于神经网络架构，我选择了4个最典型的解决方案——2个用于图像分类，2个用于pix2pix图像转换:</p><ul class=""><li id="814e" class="mc md hu kp b kq kr kt ku kw me la mf le mg li mh mi mj mk dt translated">VGG19。最古老、研究最深入的建筑，虽然缓慢而庞大。</li><li id="6cbd" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">ResNet50。图像分类中大多数现代应用的基本结构。</li><li id="1984" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">UNet。缓慢但有效的图像分割架构。</li><li id="3f85" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">EDSR。用于图像超分辨率等任务的典型神经网络。</li></ul><p id="32b0" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">弹性推理对软件有一套特殊的要求。目前，AWS支持两种框架——谷歌的TensorFlow和亚马逊MXNet。因为我的大部分代码都在MXNet中，所以我坚持使用它。</p><h2 id="a96d" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">分类网络的测量结果。</h2><p id="ab52" class="pw-post-body-paragraph kn ko hu kp b kq lx iv ks kt ly iy kv kw lz ky kz la ma lc ld le mb lg lh li hn dt translated">让我们先来看看在两种截然不同的架构下，不同的硬件在批量扩展时的表现——vgg 19和ResNet50。</p><figure class="kc kd ke kf fq kg fe ff paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="fe ff mq"><img src="../Images/92e5d60beab812d518bc50f189cd9a35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sK3K3DLdi-XQ6US9L4kbgA.png"/></div></div><figcaption class="mr ms fg fe ff mt mu bd b be z ek">VGG19 and ResNet50 performance on different AWS hardware</figcaption></figure><p id="f20b" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">哇！那很有趣。它们都随着批处理大小的增加而线性扩展(直到耗尽内存)，p3.2xlarge在性能上处于领先地位。基于GPU的硬件对比，按照NVIDIA规格和AWS定价，都在意料之中。</p><p id="ed57" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">但是，弹性推理加速器表现不同。它比ResNet50中的任何东西都慢，但是使用VGG19时性能更好。这给了我们一个线索——它针对某些类型的架构和操作进行了某种硬件优化。</p><p id="52c1" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">但是，这些图并没有给出最低可能批次的推断性能的答案— 1。这对于实际生产性能是有意义的。让我们看看那个。</p><figure class="kc kd ke kf fq kg fe ff paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="fe ff mv"><img src="../Images/714f1da6688b61cf7bda01d30aabe060.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t4s3wYQO88_IiF8OtW4Gfg.png"/></div></div><figcaption class="mr ms fg fe ff mt mu bd b be z ek">Batch=1 performance</figcaption></figure><p id="1392" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">又一个哇！这就是弹性推理的目的！在这里，EIA显然是第二位的。p3.2xlarge大约快2倍，但贵6倍。这里不用动脑筋——如果10ms的性能提升对您来说可以忽略不计，请坚持使用EIA。但是，请记住，吞吐量将减少2倍(按月计算)，而成本将降低6倍。</p><p id="07e7" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">对于这种类型的任务(分类),你也应该尝试低内存EIA实例——我认为这样可以节省更多的钱，10-15毫秒的推理速度是一个很大的数字。</p><p id="6761" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">我还在float16上测试了推理，但是在这种情况下性能提升可以忽略不计。</p><h2 id="aae3" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">图像分割和超分辨率。</h2><p id="328d" class="pw-post-body-paragraph kn ko hu kp b kq lx iv ks kt ly iy kv kw lz ky kz la ma lc ld le mb lg lh li hn dt translated">那些是不同的野兽。UNet通常用于更高分辨率的图像，224像素不足以实现高质量的分割。所以，我尝试了一系列的解决方案。为了让数据具有代表性，我采用了分辨率的平方——遵循^2法则的数量。</p><figure class="kc kd ke kf fq kg fe ff paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="fe ff mw"><img src="../Images/e80104083b78afad99a17578424cf6fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MSRlpi1QY_itfvTd2IXxpw.png"/></div></div><figcaption class="mr ms fg fe ff mt mu bd b be z ek">Image megapixels to inference time</figcaption></figure><p id="58d8" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">所有硬件都遵循百万像素时间的线性趋势，弹性推理开始更加显著地丧失。让我们仔细看看一个用500x500像素图像进行图像分割的真实场景。</p><figure class="kc kd ke kf fq kg fe ff paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="fe ff mx"><img src="../Images/4c287cf2bc7684ff05681e8aae350d97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jy7M5X3hzc0VhskwiOYrow.png"/></div></div></figure><p id="ed39" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">哦，哇哦！UNet根本不是为弹性推理而创建的。金钱方面的单一推断价格如下:</p><ul class=""><li id="0c40" class="mc md hu kp b kq kr kt ku kw me la mf le mg li mh mi mj mk dt translated">EIA.xlarge = 0.001531美元</li><li id="e062" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">g3.4xlarge = 0.000203美元</li><li id="7792" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">p2.xlarge = 0.000250美元</li><li id="07dd" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">p3.2xlarge = 0.000163美元</li></ul><p id="3b97" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">在这里，如果你的企业提供稳定的工作负载，并且每月3k不会吓跑你，那么P3.2xlarge是最便宜的。</p><h2 id="6709" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">EDSR和超分辨率</h2><p id="a022" class="pw-post-body-paragraph kn ko hu kp b kq lx iv ks kt ly iy kv kw lz ky kz la ma lc ld le mb lg lh li hn dt translated">这是另一个有趣的边缘案例。</p><figure class="kc kd ke kf fq kg fe ff paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="fe ff mx"><img src="../Images/800bcca2003e6f14a0aa9c830fcae3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cuks2f6IjSglebzd04qw8g.png"/></div></div></figure><p id="ba45" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">EDSR架构的EIA性能要好得多(实际上是基于ResNet的)。EIA在这里是一个明显的赢家。但是等等，你还记得p3.2xlarge的float16功能吗？这是一个有用的例子。这里有一个单个500px x 500px的成本推断。</p><ul class=""><li id="faf0" class="mc md hu kp b kq kr kt ku kw me la mf le mg li mh mi mj mk dt translated">EIA.xlarge = 0.000133美元</li><li id="2caa" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">g3.4xlarge = 0.000522美元</li><li id="92c7" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">p2.xlarge = 0.000833美元</li><li id="61c0" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">p3.2xlarge (float32)= 0.000252美元</li><li id="284d" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">p 3.2x大(浮动16)= 0.000130美元</li></ul><p id="ea5b" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated">全精度下的EIA与运行在半精度模式下的p3.2xlarge不相上下。<br/>同样，如果你能使用fp16，并且你的业务有稳定的数据流，坚持使用p3。否则，EIA会给你带来显著的成本效益。</p><h2 id="83f8" class="lj jk hu bd jl lk ll lm jp ln lo lp jt kw lq lr jv la ls lt jx le lu lv jz lw dt translated">诺塔贝纳酒店</h2><ul class=""><li id="e21d" class="mc md hu kp b kq lx kt ly kw mz la na le nb li mh mi mj mk dt translated">在测量过程中，我做了11个推理循环，取最后10次测量的平均时间。由于机制的原因，第一次推理总是慢很多(10倍)。</li><li id="8d8a" class="mc md hu kp b kq ml kt mm kw mn la mo le mp li mh mi mj mk dt translated">据我所知，我可以在float16模式下运行EIA，但从未获得任何速度增益。</li></ul><p id="4224" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated"><a class="ae nc" href="https://docs.google.com/spreadsheets/d/170TDMk3jBuNDOSQ1WfscsyqkdeRuATI6Tfn1T0KW9ik/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">为了更好的利益，我正在分享200个测量和数据点的所有原始数据。</a></p><p id="b3dc" class="pw-post-body-paragraph kn ko hu kp b kq kr iv ks kt ku iy kv kw kx ky kz la lb lc ld le lf lg lh li hn dt translated"><strong class="kp hv">有问题别忘了鼓掌，分享，联系我。</strong></p></div></div>    
</body>
</html>