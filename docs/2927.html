<html>
<head>
<title>UI2code: How to Fine-tune Background and Foreground Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ui2 代码:如何微调背景和前景分析</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/ui2code-how-to-fine-tune-background-and-foreground-analysis-fb269edcd12c#2019-05-08">https://medium.com/hackernoon/ui2code-how-to-fine-tune-background-and-foreground-analysis-fb269edcd12c#2019-05-08</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="0efe" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">阿里巴巴技术团队分享了他们在复杂 UI 设计中使用 UI2code 的最佳实践</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/6abb33c7a294e6944ea389863696ce1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w46LzSKaxtyZOmy7COlU3w.jpeg"/></div></div></figure><p id="c37a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">UI2code 使用深度学习来分析一个 UI 设计，并将其直接转换为前端开发人员的骨架代码，在将设计师的工作实现到应用程序中时，节省了他们大量的时间。这个转换过程的第一阶段是布局分析，对于一个简单的白色背景的应用程序来说，将图像信息分割成 GUI 元素就像切蛋糕一样简单。</p><blockquote class="kr ks kt"><p id="dc07" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated">要了解阿里巴巴的 ui2 代码，请点击这里:</p><p id="0fe7" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><a class="ae ky" href="https://hackernoon.com/introducing-ui2code-an-automatic-flutter-ui-code-generator-7e0a575c193" rel="noopener ugc nofollow" target="_blank">介绍 UI2CODE:一个自动的颤振 UI 代码生成器</a></p></blockquote><p id="a6d0" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然而，在大多数情况下，这可能更像是第一次尝试取出一条鱼的内脏:结果可能会有点乱，直到你对方法进行了微调。阿里巴巴旗下的“闲鱼”应用程序的工作人员就是这种情况。闲鱼是一个供用户出售二手商品的平台。</p><p id="42c7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">具体来说，他们在流程的背景分析和前景分析部分遇到了困难，下图完整地展示了这些困难。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff kz"><img src="../Images/52eef47722c662e447a8d4cb77ba064a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*QQX_4PKwNWmdFNkihpscww.jpeg"/></div></figure><p id="8cbd" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">背景/前景分析需要使用上下文分离算法将 UI 图像分割成 GUI 元素:</p><p id="468b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">背景分析</strong>:使用机器视觉算法分析背景颜色、渐变方向和背景的连通区域。</p><p id="02d5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">前景分析</strong>:利用深度学习算法整理、合并、识别 GUI 片段。</p><p id="14c5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">本文介绍了 Xianyu 团队在微调背景/前景分析算法方面的经验和结果。前景分析更复杂，需要更多的微调；因此，本文的大部分内容都是关于这个主题的。</p><h1 id="2d1f" class="la lb hu bd lc ld le lf lg lh li lj lk ja ll jb lm jd ln je lo jg lp jh lq lr dt translated">背景分析</h1><p id="754f" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">背景分析的关键是找到连通区域和区域边界。本节以实际的仙寓 UI 为例，一步步地介绍背景提取过程。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff lx"><img src="../Images/312cfb9040007527a1afae341d6b15fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uvdkSTL-7dRKXot51G30sw.jpeg"/></div></div></figure><h2 id="330c" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">第一步</h2><p id="1fc6" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">该步骤试图通过以下方式获得纯色和渐变背景区域:</p><p id="7f19" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">识别背景块</p><p id="a6ca" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">通过边缘检测算法(例如 sobel、拉普拉斯、canny 等)计算梯度变化的方向。)</p><p id="1673" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">基于拉普拉斯算子的背景区域提取算法如下:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mm"><img src="../Images/e2a335f342a34be5cc20537dedbe7653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D3lCLBQmADm-9noGxAG1uA.jpeg"/></div></div></figure><p id="4380" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">简单模板和扩展模板如下所示。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/09328a331f0743758f12bf0a67a18581.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*bAnycfprGj_aj5WJXf67IA.png"/></div></figure><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mo"><img src="../Images/1befa5a5d392e85861e8c513c498263f.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*WzN4TDFUfmie6v00-E3y7g.png"/></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Simple (left) and extended (right) templates for the Laplacian operator</figcaption></figure><p id="3e51" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">当区域点乘以模板点时获得的值越小，区域越平坦，因此越接近背景。如果结果是渐变区域，则计算渐变的方向(即从左到右、从右到左、从上到下或从下到上)。</p><p id="0993" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">提取效果如下:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff lx"><img src="../Images/9f8628cd18bf15b469ac0605e3448df4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*taFQPiy_7DVAgRMtMBValQ.png"/></div></div></figure><p id="962a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">虽然图像的背景轮廓已经被很好地提取，但是梯度的结果相当差。如果在计算梯度方向时确定确实存在梯度，则进行步骤 2 以改进提取结果。</p><h2 id="3f71" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">第二步</h2><p id="e12a" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">基于洪水填充算法，选择一个洪水的种子节点来过滤掉梯度背景的噪声。</p><p id="4622" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">def fill<em class="ku">color</em>diffuse<em class="ku">water from img</em>(<em class="ku">task</em>out<em class="ku">dir</em>，<em class="ku"> image </em>，<em class="ku"> x </em>，<em class="ku"> y </em>，<em class="ku"> thres </em> up = (10，10，10)，thres<em class="ku">down</em>=(<em class="ku">10</em>，<em class="ku"> 10 </em>，<em class="ku"/></p><blockquote class="kr ks kt"><p id="027a" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> #创建 h+2、w+2、</em>的蒙版图层</p><p id="752d" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> #这里需要注意 OpenCV 的默认规则，</em></p><p id="8857" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> #遮罩层的形状必须是 h+2，w+2 且必须是 8 位单通道。我不知道为什么。</em></p><p id="732b" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> mask = np.zeros([h + 2，w + 2]，np.uint8) </em></p><p id="d6f0" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> #此时运行注水，参数表示:</em></p><p id="856c" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # copyImg:要填充的图像</em></p><p id="ad89" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # mask:遮罩层</em></p><p id="b874" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # (x，y):开始填充的位置(起始种子点)</em></p><p id="3a88" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # (255，255，255):填充值；这里的填充颜色是白色</em></p><p id="7c72" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # (100，100，100):起始种子点与整个图像像素值的最大负差</em></p><p id="521b" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # (50，50，50):起始种子点与整个图像像素值之间的最大正差值</em></p><p id="d062" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> # cv。FLOODFILL_FIXED_RANGE:处理图像的方法，通常用于处理彩色图像</em></p><p id="3263" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> cv2.floodFill(图像，遮罩，(x，y)，fill_color，thres_down，thres_up，cv2。</em></p><p id="186f" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu">cv2 . im write(task _ out _ dir+"/ui/tmp 2 . png "，image) </em></p><p id="c7e7" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> #遮罩是一个非常重要的区域。它显示哪些区域填充了颜色</em></p><p id="ab12" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu"> #对于 UI 自动化，可以将遮罩设置为形状，宽度和高度小于 1。</em></p><p id="2542" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><em class="hu">返回图像，遮罩</em></p></blockquote><p id="484d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">处理后的效果如下:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff lx"><img src="../Images/dfca6bc3a4efc4424d2afc88fa3cc6a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QeW4cQMQtLRru1oMGNi3tA.png"/></div></div></figure><h2 id="4dbb" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">第三步</h2><p id="1988" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">通过 UI 切片提取 GUI 元素(切片方法如前所述)。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mt"><img src="../Images/de191b361ca29b44abd35de290fb57a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkyHah80b1-_NdgMBBxNDg.png"/></div></div></figure><p id="cbdc" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在已经成功提取了 80%的 GUI 元素；然而，覆盖层的元素仍然没有被解析。</p><h2 id="70d0" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">第四步</h2><p id="32e7" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">使用霍夫线、霍夫圆和轮廓搜索找到对称的轮廓区域，然后在提取的轮廓区域上重复步骤 2 到 4，直到获得期望的结果。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mu"><img src="../Images/81377b54472441d1b7cb1ea3d9e4a0e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*d23QzYhxYwH0yjwAhDhmqw.png"/></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Results of Hough line/circle and contour search</figcaption></figure><p id="a330" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">复杂背景的提取是后续前景分析的基础。提取背景区域后，通过连通区域识别分析前景区域，然后通过成分识别分析前景类别；最后通过语义分析对前景进行拆分和合并。</p><h1 id="d473" class="la lb hu bd lc ld le lf lg lh li lj lk ja ll jb lm jd ln je lo jg lp jh lq lr dt translated">摘要</h1><p id="f7cd" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">对于相对简单的渐变背景，上述四个步骤足以产生令人满意的结果。简单来说，过程就是基于 Hough 线和 Hough 圆的思想搜索特定的轮廓区域，对这些轮廓区域进行详细分析，然后通过 flood fill 消除渐变背景。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mv"><img src="../Images/f5550a1e30ac185b7c23475193ce4787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJblitmSqp6XZehFEnjYaQ.png"/></div></div></figure><p id="fc2f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">对于复杂的背景，我们可以利用目标检测找到特定的内容，然后利用马尔可夫随机场(MRF)来细化边缘特征。</p><h1 id="0410" class="la lb hu bd lc ld le lf lg lh li lj lk ja ll jb lm jd ln je lo jg lp jh lq lr dt translated">前景分析</h1><p id="1d0e" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">前景分析的关键是组件切片和识别的完整性。可以通过连接区域分析、基于人工智能的组件类型识别以及基于所识别的组件类型的片段合并来防止组件碎片化。应该重复这些步骤，直到没有特征属性片段剩余。</p><p id="b8e1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然而，有些情况比这更复杂。一个例子是瀑布卡片布局环境中的卡片提取。</p><p id="b91b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">对于闲鱼 app 中的页面来说，瀑布卡片识别是布局分析的重要一步。要求如下:</p><p id="d1e9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">当卡片完全显示在屏幕捕获图像中时，即使部分被图标遮挡，也应该能够被识别)</p><p id="aba8" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">当卡片被背景部分遮挡时，不应该识别该卡片。</p><p id="06ee" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">下图所示的瀑布式卡片布局，由于布局紧凑，风格多样，容易被遗漏或误认。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mw"><img src="../Images/4ecf7faa77fcb0212d097c1460069f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KnvFpRTv57Xiv-XBV2T6vA.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Examples of waterfall card layouts: the bottom-right card in (a) is partially obscured by an icon and the color of the image in the top-right card in (b) is similar to the background color</figcaption></figure><p id="7e03" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">先宇团队采用了一种新颖的卡片识别方法，将传统的图像处理方法与深度学习相融合:</p><p id="98ff" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">传统的图像处理，基于边缘梯度或连通区域识别，根据图像本身的灰度或形状特征提取卡片轮廓。它具有交并比高(IOU)和计算速度快的优点。缺点是易受干扰，召回率低。</p><p id="0f05" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">基于目标检测或特征点检测的深度学习方法以监督的方式学习卡片的风格特征。这里的优点是抗干扰，召回率高。缺点是计算速度较慢，原因是由于回归过程导致 IOU 低于传统方法，并且需要大量的手工标注。</p><p id="4715" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">鲜宇团队的集成方法得益于两者的优势，具有高精度、高召回率和高 IOU 的特点。本节的其余部分更详细地概述了传统的深度学习和集成方法。</p><h2 id="04fe" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">传统方法</h2><p id="6481" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated"><strong class="jx hv">概述</strong></p><p id="2f2c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">传统图像处理方法的算法流程如下:</p><p id="9cd4" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(1)将输入瀑布卡图像转换成灰度图像，并用对比度受限的自适应直方图均衡化(CLAHE)来增强它们。</p><p id="f1d9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(2)使用 Canny 算子进行边缘检测，得到二值化图像。</p><p id="4705" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(3)对二值化图像使用形态学膨胀并连接开放边缘。</p><p id="21ce" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(4)提取连续边缘的外轮廓，根据外轮廓覆盖的面积大小丢弃较小的轮廓，输出候选轮廓。</p><p id="cd65" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(5)使用道格拉斯-普克算法进行矩形近似，保留与矩形最相似的外轮廓，并输出新的候选轮廓。</p><p id="57b7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(6)对步骤 4 得到的候选轮廓进行水平和垂直投影，得到平滑的轮廓作为输出。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mx"><img src="../Images/5f8d432f48bb954a859972fdcd3fa154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cogqUM-DJjNFih3OdZO8aA.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Card contour extraction process</figcaption></figure><p id="456b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">算法流程的步骤 1-3 包括边缘检测，而步骤 4-6 包括轮廓提取。现在让我们更详细地看一下这些阶段中的每一个。</p><p id="36d5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">边缘检测(步骤 1-3)</strong></p><p id="c0d1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">由于各种原因，图像在转换为灰度期间会退化，需要增强以提高边缘检测的有效性。使用整个图像的单一直方图进行均衡显然不是最佳选择，因为截取的瀑布图像不同区域的对比度可能相差很大，增强后的图像可能会产生伪影。自适应直方图均衡(AHE)算法通过引入块处理对单一直方图方法进行了改进，但 AHE 有时会在增强边缘的同时放大噪声。</p><p id="e75e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">最新的方法 CLAHE 通过使用对比度阈值来消除噪声干扰，进一步改进了 AHE。如下图所示，CLAHE 不会丢弃直方图中超过阈值的部分，而是将其均匀分布在其他条柱之间。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff my"><img src="../Images/48e1b3d616b45ee164c324aaca9df947.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*hoSUcrgZ42zKjt1UpWM6sA.jpeg"/></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Diagram of CLAHE contrast limit</figcaption></figure><p id="6c27" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">Canny 算子是给出精确边缘位置的经典边缘检测算子。Canny 检测流程有四个基本步骤:</p><p id="bd1d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(1)使用高斯滤波器来降低噪声。</p><p id="95d5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(2)使用一阶偏导数的 FD 近似计算梯度的大小和方向。</p><p id="45f8" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(3)对梯度幅度使用非最大抑制。</p><p id="57ac" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(4)使用双阈值方法检测和连接边缘。需要多次尝试来选择最佳的双阈值参数。</p><p id="358e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">检测到的边缘可能在某些位置断开。这可以通过使用特定形状和大小的结构元素对二值化图像进行形态学膨胀来纠正。</p><p id="2f60" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">每个阶段的边缘检测结果如下图所示。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mz"><img src="../Images/7300c4a69075a1ad85e5b62493730949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQUuA8QNUQOJWmujaoetrw.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">a) original image; b) grayscale conversion; c) CLAHE enhancement; d) Canny detection; e) morphological dilation</figcaption></figure><p id="9c66" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">注意事项:</p><p id="fac0" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在 c)中，CLAHE 增强的对比度阈值是 10.0，区域的大小是(10，10)。</p><p id="1257" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在 d)中，Canny 检测的双阈值是(20，80)。</p><p id="6595" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在 e)中，形态学膨胀的结构元素是大小为(3，3)的十字准线。</p><p id="7701" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">轮廓提取(步骤 4-6)</strong></p><p id="27ec" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">对二值图像进行形态学膨胀后，首先提取连续边缘的外轮廓。下图显示了只有 0 和 1 的二进制图像。假设:</p><p id="f203" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">S1 是一组像素值为 0 的背景点。</p><p id="0590" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">S2 是一组像素值为 1 的前景点。</p><p id="3df4" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">外部轮廓 B1 是在最远边缘的一串前景点。</p><p id="105c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">内部轮廓 B2 是最内部区域中的一串前景点。</p><p id="3b4b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">对二进制图像执行行扫描，并为不同的轮廓边界分配不同的整数值，以确定轮廓的类型以及它们之间的层次关系。提取外轮廓后，计算轮廓面积，舍弃面积相对较小的外轮廓，输出第一阶段候选轮廓。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff na"><img src="../Images/aef9b335689c85aeef15f514f43e1d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*QYwJ0wSJlp34SAIE4znNGw.jpeg"/></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Inner and outer contours</figcaption></figure><p id="3fab" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">仙寓中的瀑布卡轮廓为圆角矩形。在这种情况下，可以对提取的候选轮廓使用道格拉斯-普克算法进行矩形近似，并保留那些类似矩形的外部轮廓。Douglas-Peucker 算法将曲线或多边形表示的点集拟合为一组较少的点，从而将两组点之间的距离保持在设定的精度水平。然后，输出第二阶段候选轮廓。</p><p id="1451" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">通过水平和垂直投影与第二阶段候选轮廓的位置相对应的第一阶段候选轮廓来消除毛刺效应，并输出矩形轮廓。</p><p id="e6a7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">各阶段的轮廓提取结果如下图所示。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nb"><img src="../Images/75f0f87f7d1b2992951d085f8d1152b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPBLOXdwXEuLtrKcaF0grg.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">a) original image; b) morphological dilation; c) first-stage candidate contours (shown in red); d) second-stage candidate contours (shown in red); e) final output of rectangular contours (shown in red)</figcaption></figure><p id="ecc7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">注意事项:</p><p id="59d5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在 c)中，轮廓覆盖区域的阈值是 10，000。</p><p id="425b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">d)中，道格拉斯-普克算法的精度为 0.01*[ <em class="ku">轮廓长度</em>。</p><p id="3b97" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">本文中提到的所有提取轮廓都包含搜索框。</p><h2 id="a855" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">深度学习方法</h2><p id="158d" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">如前所述，使用传统的图像处理方法提取轮廓特征会产生一个问题:当图像不清晰或被遮挡时，轮廓无法提取(即召回率低)。</p><p id="b4e9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">基于卷积神经网络(CNN)的目标检测算法可以通过输入大量的样本数据来学习更有代表性和区别性的特征。目前，目标检测算法主要分为两派:</p><p id="7751" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">以你为代表的单级流只看一次(YOLO)和单触发检测器(SSD)网络。</p><p id="2001" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">区域 CNN (R-CNN)族代表的两阶段流。</p><p id="0fb3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">一级流程和二级流程</strong></p><p id="b470" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">一阶段流程直接对预测目标进行分类和回归。它速度很快，但与两级流程相比，mAP 较低。</p><p id="1573" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">两阶段流程在分类和回归预测目标之前生成候选目标区域，因此在训练时更容易收敛。它的 mAP 更高，但比一级流慢。</p><p id="2098" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">下图显示了一阶段和两阶段流程中使用的对象检测推理。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nc"><img src="../Images/b41124cf782b8dff76bf1a1c9183cff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A_nITKHbtyFVY4Tvs_vlGw.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Target detection reasoning process</figcaption></figure><p id="b252" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">流程如下:</p><p id="2724" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">将图像输入到特征提取网络(经典的 CNN 网络，如 VGG、Inception、Resnet 等是可选的)以获得图像特征。</p><p id="0f8b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">将特定区域特征分别发送到分类器和回归器，用于类别分类和位置回归。</p><p id="00b5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">输出盒子的类别和位置。</p><p id="48b2" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">更快的 R-CNN </strong></p><p id="fdc0" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">更快的 R-CNN 对 R-CNN 家族的最大贡献在于，它将生成候选目标区域的过程集成到了整个网络中。这导致整体性能的显著提高，尤其是在检测速度方面。</p><p id="ce9a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">更快的 R-CNN 的基本结构如下图所示。它由四部分组成:</p><p id="ad95" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">①<strong class="jx hv">conv 层</strong></p><p id="8a4f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">一组基本的 conv+relu+池层，用于提取图像特征，然后与后续 RPN 网络和全连接层共享。</p><p id="96bf" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(2) <strong class="jx hv">地区提案网</strong></p><p id="736a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">生成候选目标框，通过 softmax 判断是前景还是背景。使用回归来校正候选框的位置。</p><p id="6222" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(3) <strong class="jx hv"> RoI 汇集</strong></p><p id="e894" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">收集输入要素地图和候选区域。候选区域被映射到固定大小的区域，并被发送到后续的全连接层。</p><p id="8924" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">(4) <strong class="jx hv">分类器</strong></p><p id="c6ad" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">计算候选框的特定类别。使用回归再次校正候选框的位置。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nd"><img src="../Images/a1b48dd03a21401815590dbde0c99843.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*2H0TSpdw2SfYNocYjnFQWg.jpeg"/></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Basic structure of the Faster R-CNN</figcaption></figure><p id="d55d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">使用更快的 R-CNN 进行瀑布卡识别的结果如下图所示。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff ne"><img src="../Images/30d52cfdf42731918f7efb31976fe77e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PIl71Ob3Rsg65qzzPUnv1A.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">a) original image; b) recognized cards (shown in red)</figcaption></figure><h2 id="c3f9" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">综合方法</h2><p id="396c" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">传统的图像处理可以获得具有高 IOU 的牌位置，但是由于牌的显示方式，召回率不高。同时，深度学习方法具有高泛化能力并实现高召回率，但是在回归过程中不能在高 IOU 下获得卡片位置。</p><p id="62df" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">正如我们已经看到的，实际上这意味着对于上面的图像:</p><p id="1989" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">传统的图像处理无法检测右上牌。</p><p id="ff2c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">深度学习检测右上和左上的卡片，但它们的边界几乎重叠。</p><p id="fd63" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">融合两种方法得到的结果，取得了高精度、高召回率和高 IOU 的较好效果。</p><p id="1318" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">集成过程如下:</p><p id="2e2a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">1.输入一幅图像，并行运行传统图像处理方法和深度学习方法，分别获得提取的卡盒 trbox(传统)和 dlbox(深度学习)。</p><p id="bd3c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">IOU 以 trbox 为基准，精度和召回率以 dlbox 为基准。</p><p id="6a07" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">2.过滤器 trbox。</p><p id="05f5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">规则是当 trbox 和 dlbox 的 IOU 大于某个阈值(比如 0.8)时，保持 tr box；否则丢弃它并获取 trbox1。</p><p id="35a9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">3.过滤器 dlbox。</p><p id="eec1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">规则是当 dlbox 和 trbox1 的 IOU 大于某个阈值(例如 0.8)时，丢弃 dl box；否则保留它并获取 dlbox1。</p><p id="1fa3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">4.纠正 dlbox1 的位置。</p><p id="6a70" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">规则是 dlbox1 的每条边都移动到离它最近的直线上，约束条件是移动的距离不能超过给定的阈值(比如 20 个像素)，移动的边不能越过 trbox1 的边。由此获得修改的 dlbox2。</p><p id="32a9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">5.输出 trbox1+dlbox2 作为最终合并的卡盒。</p><p id="c3a5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">下表描述了用于衡量集成方法性能的性能指标。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nf"><img src="../Images/6733224c1a9e5d0e0a1d9b6612b6dcb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hX4GAv6pI-2FrzIHr_llJQ.png"/></div></div></figure><p id="73de" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">下图比较了每种方法的卡片识别结果。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff ng"><img src="../Images/4f0cd47b302f60b6380ef4fff923e9d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-IIkUWo8u8Q4fgIYzAKTw.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">a) original image; b) traditional image processing; c) deep learning; d) integrated approach (combines b) and c))</figcaption></figure><p id="979e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">显然，图像 d)比 b)具有更好的回忆，比 c)具有更好的 IOU。</p><p id="b2f5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">下面的三组图片展示了更多的例子。对于每行图像:</p><p id="f0f3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">第一列显示原始图像。</p><p id="3103" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">第二列显示了传统图像处理的结果。</p><p id="d533" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">第三列显示深度学习的结果。</p><p id="8955" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">第四栏显示了综合方法的结果。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nh"><img src="../Images/7b7113108fafe10e538cb85dc1f563a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nN5dGwJ7zxVQeO_9OwxbA.jpeg"/></div></div></figure><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff ni"><img src="../Images/cc0ef7c1aa898511ac849b65bfd3d303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wZqkKue_OtvjPCJ-qb62Ew.jpeg"/></div></div></figure><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff ng"><img src="../Images/01d3b01863407eef528c5133769a32dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ryKirCzdcjPV0ZN42cQ6sw.jpeg"/></div></div></figure><p id="5649" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在前两行中，卡片轮廓被准确地识别。在第三行中，卡片的底边没有完全贴合。这是因为当在融合步骤中校正 dlbox1 位置时，使用传统的图像处理方法来寻找范围中最近的直线，这受到图像风格的影响。找到的直线不是卡片的预期底边。</p><h2 id="72c1" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">测试</h2><p id="4a19" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">传统、深度学习和集成方法在随机捕获的 50 张仙鱼瀑布卡片图像上进行测试，这些图像之间总共包含 96 张卡片(搜索框除外)。传统方法识别了 65 张卡片，深度学习方法识别了 97 张卡片，综合方法识别了 98 张卡片。</p><p id="31be" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">精度、召回和 IOU 如下表所示。结果证实，整合方法结合了传统方法和深度学习方法的优点。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nj"><img src="../Images/5fb3539ed533cec046046bdc4d928f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QWlXtz6QJXMrxzxHTQ2BGQ.jpeg"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">Summary of test results</figcaption></figure><h2 id="9251" class="ly lb hu bd lc lz ma mb lg mc md me lk ke mf mg lm ki mh mi lo km mj mk lq ml dt translated">后续步骤</h2><p id="4ae3" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">先宇团队提出的集成方法在识别任务中实现了高精度、高召回率和高 IOU 然而，它也不是没有缺点。例如，在融合过程中对组成元素的校正受到图像风格的干扰。未来的工作应寻求优化这一部分的进程。</p><p id="c47b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt"><strong class="jx hv">(Original article by Chen Yongxin 陈永新, Zhang Tonghui 张仝辉 and Chen Jie 陈浩)</strong></p><blockquote class="kr ks kt"><p id="2c41" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated">要了解阿里巴巴的 ui2 代码，请点击这里:</p><p id="5dd2" class="jv jw ku jx b jy jz iv ka kb kc iy kd kv kf kg kh kw kj kk kl kx kn ko kp kq hn dt translated"><a class="ae ky" href="https://hackernoon.com/introducing-ui2code-an-automatic-flutter-ui-code-generator-7e0a575c193" rel="noopener ugc nofollow" target="_blank">介绍 UI2CODE:一个自动的颤振 UI 代码生成器</a></p></blockquote></div><div class="ab cl nk nl hc nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="hn ho hp hq hr"><h1 id="ad7f" class="la lb hu bd lc ld nr lf lg lh ns lj lk ja nt jb lm jd nu je lo jg nv jh lq lr dt translated">阿里巴巴科技</h1><p id="01dc" class="pw-post-body-paragraph jv jw hu jx b jy ls iv ka kb lt iy kd ke lu kg kh ki lv kk kl km lw ko kp kq hn dt translated">关于阿里巴巴最新技术的第一手深度资料→脸书:<a class="ae ky" href="http://www.facebook.com/AlibabaTechnology" rel="noopener ugc nofollow" target="_blank"> <strong class="jx hv">“阿里巴巴科技”</strong> </a>。推特:<a class="ae ky" href="https://twitter.com/AliTech2017" rel="noopener ugc nofollow" target="_blank"> <strong class="jx hv">【阿里巴巴技术】</strong> </a>。</p></div></div>    
</body>
</html>