# 大型科技公司需要把人权放在商业之前

> 原文：<https://medium.com/hackernoon/big-tech-needs-to-put-human-rights-before-business-609e1a0b34ac>

## 当你的客户是整个国家和整个人类时，你就不能无视人权。

![](img/641fd4b22d4e23e6abecfdc4ae9b842f.png)

Image by Markus Spiske

技术在不断发展。这并不奇怪。从万维网到自动驾驶汽车，一直到人工智能(AI)的最终到来，我们生活在一个技术比以往任何时候都更能推动社会变革并影响常态的时代。具体来说，当谈到他们的技术对社会的影响时，谷歌、苹果、脸书和亚马逊等大型技术公司似乎都被绑在了驾驶座上。

在一个金钱万能的世界，这些跨国公司非常重视财务增长，并以此维护对客户的服务条款，这似乎是很自然的。然而，当你的客户通常是整个国家及其选民时，必须划出一条界限:科技公司需要将人权和道德作为与全球商业互动的基线。从认可征服人口的应用到建立无效的伦理委员会，很明显底线不存在。

## 服务条款是不够的。

[2 月 24 日，14 名国会议员起草了一封给苹果和谷歌的信，要求从科技公司的服务中移除沙特政府应用程序 Absher。这款应用受到了人权监督机构的广泛批评，因为它被用于沙特政府支持的压制妇女权利的行为，允许“监护人”监管和跟踪妇女的行动，甚至可以随时拒绝或吊销她们的护照。](https://www.thisisinsider.com/absher-14-members-of-congress-demand-apple-google-remove-saudi-app-2019-2)

这两家科技公司最懦弱的反应令人震惊。苹果公司声称他们会“调查此事”，截至本文撰写之时，还没有明显的进展。谷歌以更冷漠的方式回应，声称应用“[没有违反任何协议](https://www.thisisinsider.com/absher-google-refuses-to-remove-saudi-govt-app-that-tracks-women-2019-3?utm_source=twitter&utm_medium=referral&utm_content=topbar&utm_term=desktop&referrer=twitter)”以此为由，谷歌拒绝从 Play Store 下架该应用。

这是令人愤怒的，[来自一个有胆量引用 2011 年联合国《世界人权宣言》的公司。请告诉我，一致性在哪里？这就是核心问题所在——不存在，因为不存在对问责的恐惧。躲在服务条款和协议的概念后面，并不是无视人权的正当理由。这并不是说苹果的反应更好，因为它选择掩盖问题，直到它离开公众的视线。总而言之，这整个奇观突出了一点，人权问题并没有在大科技公司眼中占据中心位置。](https://publicpolicy.googleblog.com/2011/10/technology-and-human-rights.html)

## 侵犯人权——甚至背着员工。

谷歌的道德困境近年来越来越多，最近他们处理人权不当的另一个例子是秘密的[项目蜻蜓，一个旨在维护和执行中国严格的国家审查条例的搜索引擎。](https://theintercept.com/2018/09/21/google-suppresses-memo-revealing-plans-to-closely-track-search-users-in-china/)蜻蜓被设计用来加强对维基百科等网站的国家审查，这些网站包含人权、言论自由、宗教和许多其他在自由世界永远不会被审查的话题。它甚至不会通知公民搜索结果已经被完全删除。

在关于蜻蜓的信息泄露给公众后，谷歌声称该项目不会很快准备部署，甚至试图证明建立搜索引擎是正确的，[声称它只会影响 1%的搜索查询](https://www.washingtonpost.com/opinions/does-dont-be-evil-still-apply-google/2018/12/04/634f065c-f731-11e8-863c-9e2f864d47e7_story.html?utm_term=.bcab628bee0a)。这怎么能用来辩护呢？封锁信息的数量不是最重要的部分；重要的是*被屏蔽的*是什么。然而，据报道，在谷歌的隐私团队发现该项目不适合部署后，蜻蜓已于 12 月中旬停止。

然而，在今年三月，谷歌员工声称他们有“强烈的迹象”表明蜻蜓仍在进行一些事情。色吾惊。科技公司愿意绕过自己员工的道德观点，以确保他们的“客户”(在这种情况下，是中国政府)满意，他们自己的腰包鼓起来。这个案例再一次清楚地表明，商业是大科技运营的第一线，而不是人权的第一线*。*

## 谷歌顾问委员会的问题是

最近头条新闻的焦点是[谷歌高级技术外部顾问委员会(ATEAC)](https://blog.google/technology/ai/external-advisory-council-help-advance-responsible-development-ai/) 的崛起和近乎立即的衰落，这应该在一英里之外就能看到。该委员会是围绕“补充内部治理结构和流程”的想法建立的，这是谷歌首席执行官桑德尔·皮帅之前概述的。

让我们先解决这个问题。这显然是为了成为一个围绕未来人工智能技术和算法的外部伦理委员会。无论谷歌是否选择这样称呼它(他们更喜欢“顾问委员会”)，讨论的问题无疑将集中在未来技术的伦理和人权方面。

这就是对董事会的大部分批评的来源，凯·科尔斯·詹姆斯被任命为传统基金会的主席。传统基金会是一个保守的智库，以其反 LGBTQ 观点、彻底否认科学(以否认气候变化的形式)及其对美国在尼加拉瓜和柬埔寨等国家的外交政策的影响而闻名。顺便说一下，他们的影响仍然很大。[福布斯将基金会列为 2019 年社交媒体影响力最具影响力的智库](https://www.forbes.com/sites/alejandrochafuen/2019/04/10/the-2019-ranking-of-free-market-think-tanks-measured-by-social-media-impact/#6ed29b832fe7)。

那么*为什么*詹姆斯被任命为 ATEAC 的成员？[詹姆斯本人提出的观点](https://www.washingtonpost.com/opinions/i-wanted-to-help-google-make-ai-more-responsible-instead-i-was-treated-with-hostility/2019/04/09/cafd1fb6-5b07-11e9-842d-7d3ed7eb3957_story.html?utm_term=.0949019204ad)是，由于董事会的解散，她的其他理事会成员“被剥夺了向[她]提问的机会，他们可能会认为[她]的政策观点与[她]绝对无条件地接受人类大家庭的每个成员”是矛盾的。

由可能是世界上最有影响力的科技公司设计的伦理委员会 ATEAC，会是讨论人权和保守主义理想的合适场所吗？这是一个毫无意义的问题，因为它本来就不该存在。

## 伦理委员会的整个想法都是假的。

整个伦理委员会的事实是，它从来都不是一个谈论人工智能伦理的地方。委员会，以及它特别挑选的任命，在公司内部没有任何形式的实际机构权力，委员会和公众之间从来没有任何透明的协议，否认公众的任何监督。这只是另一种灵活、模糊的理想主义，在未来调节人工智能对人权的影响方面没有真正的权力。

如果谷歌真的认真对待这个委员会，为什么他们要任命一个直接违背他们之前声明的人工智能原则的人进入委员会？在前面提到的人工智能路线中，谷歌首席执行官表示，“其目的违反广泛接受的国际法和人权原则的技术”在谷歌是不会被容忍的。谷歌还表示，它将避免基于“种族、民族、性别、国籍、收入、性取向、能力、政治或宗教信仰等敏感特征”而“不公正地影响”人们的技术。那么谎言在哪里？要么谷歌对他们自己的人工智能原则漠不关心，要么他们建立了一个与它们直接矛盾的伦理委员会。这两种回答都是不可接受的。

## 为什么科技公司要将人权作为政策的基线，甚至一开始就关心人权？

科技公司需要履行自己的人权义务的原因是多方面的，但也是有益的。科技公司可以也应该将人权视为与全球商业互动的更好方式，而不是将人权视为一种限制。

最紧迫的原因是，正如联合国所概述和接受的那样，人权是普遍的，企业也应该遵守人权。通过拒绝将这些准则作为规范，科技公司冒着贬低普遍规律、支持文化相对论的风险。与一些人可能说的相反，人权是定义明确的，并为政策决定提供了有用和重要的出发点。

从一个不那么道德的角度来看，遵守人权有利于公司的形象。[总的来说，人们对维护人权的公司有好感。为了迎合某些群体而拒绝这样做，科技公司正在损害他们在消费者心目中的形象。](https://www.weforum.org/agenda/2017/01/now-more-than-ever-we-need-to-protect-human-rights-but-do-people-still-care/)

## 展望未来:需要什么样的改变？

人权应该是科技公司的出发点。他们的影响是不可估量的，他们选择在政策中代表的立场有着严重的影响。

像谷歌对阿布舍和蜻蜓项目所做的那样维持现状是应该受到谴责的，并且只会通过使用他们的产品来合理化系统性的滥用。相反，科技公司需要在他们的政策中建立具体的指导方针，规定哪些内容可以在他们的应用程序和产品中实现，哪些不可以。首先，他们可以像谷歌在 2011 年所做的那样，重新审视一下《联合国人权宣言》( UN Declaration of Human Rights ),并将该宣言的规定落实到他们的政策中，而不是在博客上发布他们有多在乎。

建立缺乏明确责任和权力的伦理委员会也无助于人权的改善。相反，如果科技公司希望对未来如何使用科技产生影响，它们需要经过严格审查、具有指导发展实际能力的伦理委员会。仅靠理想主义只能让他们走到这一步，还需要有实际的、切实的支持。

只有时间才能证明科技公司是否真的想给人类带来好的、强大的影响。目前，作为消费者，我们的工作是让对话继续下去，并在我们发现不公正时大声疾呼。