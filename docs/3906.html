<html>
<head>
<title>Does your NLP model able to prevent adversarial attack?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的 NLP 模型能够防止恶意攻击吗？</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c#2019-06-30">https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c#2019-06-30</a></blockquote><div><div class="ef ho hp hq hr hs"/><div class="ht hu hv hw hx"><div class=""/><div class=""><h2 id="cea8" class="pw-subtitle-paragraph ix hz ia bd b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo ek translated">对抗性攻击</h2></div><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff jp"><img src="../Images/badf9cfc3c9ace7bdffeb02f4a1f1728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vRNje9mcR06tl9Gp"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Photo by <a class="ae kf" href="https://unsplash.com/@jeffreyflin?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jeffrey F Lin</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="0858" class="pw-post-body-paragraph kg kh ia ki b kj kk jb kl km kn je ko kp kq kr ks kt ku kv kw kx ky kz la lb ht dt translated">对抗性攻击是通过异常输入来欺骗模型的方法。Szegedy 等人(2013)在计算机视觉领域对其进行了介绍。给定一组正常的图片，优越的图像分类模型能够正确地对其进行分类。然而，同一模型不再对带有噪声(非随机噪声)的输入进行分类。</p></div></div>    
</body>
</html>