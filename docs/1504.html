<html>
<head>
<title>Introduction to Web Scraping using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的Web抓取简介</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/introduction-to-web-scraping-using-python-89b15b57150c?source=collection_archive---------3-----------------------#2019-03-04">https://medium.com/hackernoon/introduction-to-web-scraping-using-python-89b15b57150c?source=collection_archive---------3-----------------------#2019-03-04</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="03ab" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">摘要:这是一个关于如何借助python内置模块Requests和Bs4来抓取web的快速教程。</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/6ee4f77cb52a847d0c840b688a9d6361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XE3SRZFkIrd0Lmo5"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Photo by <a class="ae jz" href="https://unsplash.com/@charlesdeluvio?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Charles 🇵🇭</a> on <a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5622" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">作为一名数据科学家，收集数据的最有效方式之一是借助<em class="kw">网络搜集。</em></p><h2 id="8021" class="kx ky hu bd kz la lb lc ld le lf lg lh kj li lj lk kn ll lm ln kr lo lp lq lr dt translated">网页抓取</h2><p id="e882" class="pw-post-body-paragraph ka kb hu kc b kd ls iv kf kg lt iy ki kj lu kl km kn lv kp kq kr lw kt ku kv hn dt translated">这是一种从网络上获取数据到我们的本地机器上的技术，以对其执行特定的数据分析或数据可视化操作，从而从该数据中获得有用的见解。<strong class="kc hv"> <em class="kw">也称为Web收割(或数据抽取)。</em> </strong></p><p id="df13" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在本文中，我们将借助两个名为Requests和bs4(Beautiful Soup)的黄金库来抓取web。选择这两个库的原因是它们比其他可用的库更加强大和灵活。这两个库在StackOverflow上也有一个很好的社区，如果你是这个web抓取之旅的新手，它可以提供帮助。</p><p id="239f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在这篇文章结束的时候，你一定会有很多关于网络抓取的知识。</p><p id="3dc4" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><strong class="kc hv">先决条件</strong></p><p id="c6ab" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">需要HTML标签和CSS选择器的基础知识。</p><p id="6766" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">从web捕获数据开始于向web发送一个请求，请求从哪个网站捕获数据。这个任务是在<strong class="kc hv"> <em class="kw">请求</em> </strong>模块的帮助下完成的。</p><p id="bf3f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">要向网站发出请求，首先我们需要在python中导入请求模块。它不是python中的内置模块。我们需要在<strong class="kc hv"> <em class="kw"> pip的帮助下安装那个包。</em>T15】</strong></p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="ba34" class="kx ky hu ly b fv mc md l me mf">&gt;&gt;&gt;import requests  # Module imported Sucessfully.</span><span id="e02b" class="kx ky hu ly b fv mg md l me mf"># To make a request</span><span id="24c0" class="kx ky hu ly b fv mg md l me mf">&gt;&gt;&gt; response = requests.get('<a class="ae jz" href="https://www.hackthissite.org/" rel="noopener ugc nofollow" target="_blank">https://www.hackthissite.org/</a>')</span><span id="390a" class="kx ky hu ly b fv mg md l me mf"># The response variable will contain the response of that request object.</span></pre><p id="7638" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">为了检查请求对象的状态，我们需要使用请求模块中的<strong class="kc hv"> <em class="kw"> status_code </em> </strong>属性。</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="f443" class="kx ky hu ly b fv mc md l me mf">&gt;&gt;&gt;response.status_code</span></pre><p id="67d0" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">如果状态代码值的结果是200，那么您得到了网站的成功响应。否则，你会得到一个糟糕的网页响应。问题可能出在web URL或服务器上。</p><h2 id="17d5" class="kx ky hu bd kz la lb lc ld le lf lg lh kj li lj lk kn ll lm ln kr lo lp lq lr dt translated">请求的类型</h2><p id="f67d" class="pw-post-body-paragraph ka kb hu kc b kd ls iv kf kg lt iy ki kj lu kl km kn lv kp kq kr lw kt ku kv hn dt translated">在请求模块的帮助下，主要有六种类型的请求是可能的。</p><ol class=""><li id="9cb6" class="mh mi hu kc b kd ke kg kh kj mj kn mk kr ml kv mm mn mo mp dt translated">get()请求</li><li id="df60" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">post()请求</li><li id="f16c" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">put()请求</li><li id="ac7a" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">delete()请求</li><li id="ef56" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">head()请求</li><li id="8674" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">options()请求</li></ol><p id="eb45" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">向网页发出任何请求的语法是—</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="ef64" class="kx ky hu ly b fv mc md l me mf">requests.methodName('url')</span></pre><p id="fe8b" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">但是最流行的请求网页的方法是只使用get()和post()方法。</p><p id="25b0" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">要将任何类型的敏感数据与URL一起发送，如登录凭证等，那么post()请求更为可取，因为HTTP get()请求不能为发送到web页面的请求提供任何安全性。</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="7d09" class="kx ky hu ly b fv mc md l me mf">r = requests.post<strong class="ly hv">(</strong>'https://facebook.com/post'<strong class="ly hv">,</strong> data = <strong class="ly hv">{</strong>'key'<strong class="ly hv">:</strong>'value'<strong class="ly hv">})</strong></span></pre><h2 id="9be6" class="kx ky hu bd kz la lb lc ld le lf lg lh kj li lj lk kn ll lm ln kr lo lp lq lr dt translated">响应结果</h2><p id="8878" class="pw-post-body-paragraph ka kb hu kc b kd ls iv kf kg lt iy ki kj lu kl km kn lv kp kq kr lw kt ku kv hn dt translated">我们请求的响应内容是在文本属性的帮助下获得的。</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="1dba" class="kx ky hu ly b fv mc md l me mf">&gt;&gt;&gt;response.text</span></pre><p id="5f28" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">上述语句将产生如下所示的结果—</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mv"><img src="../Images/5bb66dc27a0fcc1e286ba4f418166730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*75Ar_mDmMMyUo4Lwehy9Iw.png"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Don’t be afraid of that result because it is the initial response from the webpage</figcaption></figure><p id="fa90" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">从上面的图像中，我们可以得出结论，我们将网页内容下载到了本地机器上。为了使内容更加灵活和有用，我们需要借助漂亮的汤库。这个库帮助我们从可用的数据中获得有用的见解。</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="606e" class="kx ky hu ly b fv mc md l me mf"># Importing the beautiful soup library<br/>&gt;&gt;&gt;import bs4</span></pre><p id="fff6" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">为了使我们的原始HTML数据更加漂亮，我们需要借助一些解析器来解析我们的内容。经常使用的解析器是—</p><ol class=""><li id="181d" class="mh mi hu kc b kd ke kg kh kj mj kn mk kr ml kv mm mn mo mp dt translated">lxml</li><li id="c864" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">HTML5lib</li><li id="858f" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">XML解析器</li><li id="d29d" class="mh mi hu kc b kd mq kg mr kj ms kn mt kr mu kv mm mn mo mp dt translated">HTML.parser</li></ol><p id="d22f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">但是最灵活、最流行的是lxml解析器。它可以非常快速有效地解析数据。</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="9ce0" class="kx ky hu ly b fv mc md l me mf">&gt;&gt;&gt;soup_obj = bs4.BeautifulSoup(response.text,'lxml')<br/># The soup_obj will us to fetch the our required results</span><span id="b839" class="kx ky hu ly b fv mg md l me mf"># To make our previous data more understandable we will use prettify() on soup_obj</span><span id="35cf" class="kx ky hu ly b fv mg md l me mf">&gt;&gt;&gt;soup_obj.prettify()</span></pre><p id="ad19" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">结果将会是—</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mw"><img src="../Images/9be7d77dcf822fdf6ee20fa68b16249b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6v6KElW-_F2Cg7XhmmCGyQ.gif"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">The output from Soup Object</figcaption></figure><p id="d4d2" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">最后，我们又前进了一步。数据的提取从这里开始—</p><p id="3b27" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">要提取网页的名称，我们需要使用选择器和适当的HTML标签来获得结果</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="ac9f" class="kx ky hu ly b fv mc md l me mf">&gt;&gt;&gt;soup_obj.select('title')[0].getText()</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mx"><img src="../Images/4f6ad5bf653570fd501bbeb6525ec8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fe8sowh7yhdWvktoEXYjXQ.png"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">Title Output</figcaption></figure><p id="84d9" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">要从该网页中提取所有链接，您需要找到页面中的所有锚标签，并将结果存储到一个变量中。在for循环迭代的帮助下，它完成并打印结果</p><pre class="jk jl jm jn fq lx ly lz ma aw mb dt"><span id="ce6f" class="kx ky hu ly b fv mc md l me mf">&gt;&gt;&gt;links = soup_obj.find_all('a')<br/># find_all() will help to fetch all the details of the selected tag.</span><span id="69d3" class="kx ky hu ly b fv mg md l me mf">&gt;&gt;&gt;for link in links:<br/>...    print(link.get('href'))<br/>...</span><span id="7cd9" class="kx ky hu ly b fv mg md l me mf"># get() is used to extract the specific content from the tag</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mv"><img src="../Images/f9b8b5fd8520822e51df7281d122365b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdOPP875dIwduhmb7tmxzA.png"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">The output of extracting links</figcaption></figure><p id="2d95" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">这是一个从网页获取链接的简单例子。如果您想从网页中提取一些其他数据，请选择与您的内容相关的适当标签，并借助soup对象获取结果。起初，这感觉很难，但当你在做的时候，你肯定能在几分钟内找到任何类型的网站。</p><h2 id="0120" class="kx ky hu bd kz la lb lc ld le lf lg lh kj li lj lk kn ll lm ln kr lo lp lq lr dt translated">放弃</h2><p id="3324" class="pw-post-body-paragraph ka kb hu kc b kd ls iv kf kg lt iy ki kj lu kl km kn lv kp kq kr lw kt ku kv hn dt translated">✋:没有管理员的许可，你不应该进行网站抓取。这可能会导致非法活动。公司中的数据科学家通常在他们自己的网页和业务上进行网络抓取，他们没有在其他公司网站上进行任何非法行为。所以要小心。如果你造成任何损坏，我不负责。✋</p><h2 id="31a6" class="kx ky hu bd kz la lb lc ld le lf lg lh kj li lj lk kn ll lm ln kr lo lp lq lr dt translated">我在本教程中使用的网页是免费的，所以没有任何问题。使用这类网站来学习或提高你的技能。</h2><h2 id="f0e2" class="kx ky hu bd kz la lb lc ld le lf lg lh kj li lj lk kn ll lm ln kr lo lp lq lr dt translated">结论</h2><p id="0913" class="pw-post-body-paragraph ka kb hu kc b kd ls iv kf kg lt iy ki kj lu kl km kn lv kp kq kr lw kt ku kv hn dt translated">从上面所有的例子，我想现在你可以很容易地使用Request和bs4库。您可以借助不同的HTML标签从web中提取不同类型的内容，并将这些数据存储到CSV文件或文本文件中。只需对数据应用python文件操作，将其保存到本地机器中。</p><p id="2729" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">希望这能帮助你以一种简单的方式学习python中的web抓取。</p><p id="bf43" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><strong class="kc hv">如果你喜欢这篇文章，请点击拍手，给我留下你宝贵的反馈。</strong></p></div></div>    
</body>
</html>