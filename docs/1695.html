<html>
<head>
<title>Build your first Neural Network to predict house prices with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Keras建立你的第一个预测房价的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4?source=collection_archive---------2-----------------------#2019-03-12">https://medium.com/hackernoon/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4?source=collection_archive---------2-----------------------#2019-03-12</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="d309" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">一步一步完整的初学者指南，像深度学习专家一样用几行代码构建你的第一个神经网络！</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/4ecc90addea5b922c5ad567584d34c4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*93f3Bpwd9gZfy8xFl0mZrw.jpeg"/></div></div></figure><p id="74de" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt kr translated">编写你的第一个神经网络只需要几行代码！在本帖中，我们将探索如何使用一个名为Keras的包来构建我们的第一个神经网络，以预测房价是高于还是低于中值。特别是，我们将通过完整的深度学习渠道，从:</p><ul class=""><li id="1e5d" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">探索和处理数据</li><li id="53a5" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">建立和训练我们的神经网络</li><li id="e499" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">可视化损失和准确性</li><li id="9987" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">将正则化加入我们的神经网络</li></ul><p id="9f10" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">只需20到30分钟，你就可以像深度学习实践者一样编写自己的神经网络了！</p></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><p id="2d9c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">先决条件</strong>:</p><p id="ec46" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这篇文章假设你已经在Jupyter笔记本上安装了<em class="lv"> keras </em>，<em class="lv"> tensorflow </em>，<em class="lv"> pandas </em>，<em class="lv"> scikit-learn </em>和<em class="lv"> matplotlib </em>软件包。如果您还没有这样做，请按照下面教程中的说明进行操作:</p><ul class=""><li id="3d3d" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated"><a class="ae lw" rel="noopener" href="/intuitive-deep-learning/getting-started-with-python-for-deep-learning-and-data-science-9ca785560bbc">深度学习和数据科学Python入门</a></li></ul><p id="f08c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们假设您对神经网络及其工作方式有一些直观的了解，包括一些基本细节，如什么是过度拟合以及解决它们的策略。如果您需要复习，请阅读这些直观的介绍:</p><ul class=""><li id="c07f" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated"><a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1a-introduction-to-neural-networks-d7b16ebf6b99">直观深度学习第1a部分:神经网络简介</a></li><li id="b5c8" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated"><a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1b-introduction-to-neural-networks-8565d97ddd2d">直觉深度学习第1b部分:神经网络简介</a></li></ul><p id="7ac5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">你需要的资源:</p><p id="377e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们今天要用的数据集改编自<a class="ae lw" href="https://www.kaggle.com/c/zillow-prize-1/data" rel="noopener ugc nofollow" target="_blank"> Zillow的房屋价值预测Kaggle竞赛数据</a>。我们减少了输入要素的数量，并将任务改为预测房价是高于还是低于中值。请访问下面的链接下载下面的修改数据集，并将其放在与您的笔记本相同的目录中。下载图标应该在右上角。</p><p id="4a73" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><a class="ae lw" href="https://drive.google.com/file/d/1GfvKA0qznNVknghV4botnNxyH-KvODOC/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">下载数据集</a></p><p id="2dc6" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">或者，你也可以下载一个带注释的Jupyter笔记本，它包含了这篇文章中的所有代码:<a class="ae lw" href="https://github.com/josephlee94/intuitive-deep-learning/blob/master/Part%201/Coding%20Companion%20for%20Intuitive%20Deep%20Learning%20Part%201%20Annotated.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>。</p><p id="8ced" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">注意，要从Github下载这款笔记本，你得去<a class="ae lw" href="https://github.com/josephlee94/intuitive-deep-learning" rel="noopener ugc nofollow" target="_blank">首页</a>下载ZIP下载所有文件:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff lx"><img src="../Images/97a6a6d30e76af40649873824fb70fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*liEdhFpxRUxNyTNtqX1YiA.png"/></div></figure><p id="c338" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，让我们开始吧！</p></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><h1 id="fcae" class="ly lz hu bd ma mb mc md me mf mg mh mi ja mj jb mk jd ml je mm jg mn jh mo mp dt translated">探索和处理数据</h1><p id="10e8" class="pw-post-body-paragraph jv jw hu jx b jy mq iv ka kb mr iy kd ke ms kg kh ki mt kk kl km mu ko kp kq hn dt translated">在我们编写任何ML算法之前，我们需要做的第一件事是把我们的数据转换成算法想要的格式。特别是，我们需要:</p><ul class=""><li id="7f72" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">读入CSV(逗号分隔值)文件并将它们转换为数组。数组是我们的算法可以处理的一种数据格式。</li><li id="4c36" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">将数据集分为输入要素(我们称之为x)和标注(我们称之为y)。</li><li id="4485" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">缩放数据(我们称之为<em class="lv">归一化</em>)，使输入要素具有相似的数量级。</li><li id="282e" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">将我们的数据集分成训练集、验证集和测试集。如果您需要复习为什么我们需要这三个数据集，请参考<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1b-introduction-to-neural-networks-8565d97ddd2d">直观深度学习第1b部分</a>。</li></ul><p id="fb18" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">所以让我们开始吧！从<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/getting-started-with-python-for-deep-learning-and-data-science-9ca785560bbc">深度学习和数据科学Python入门</a>教程中，您应该已经将pandas包下载到您的环境中。我们需要告诉我们的笔记本，我们将通过导入来使用该包。键入以下代码，然后按键盘上的Alt-Enter键:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="d14b" class="na lz hu mw b fv nb nc l nd ne">import pandas as pd</span></pre><p id="c749" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这仅仅意味着，如果我想引用包‘pandas’中的代码，我将用名称pd来引用它。然后，我们通过运行这行代码读入CSV文件:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="0b20" class="na lz hu mw b fv nb nc l nd ne">df = pd.read_csv('housepricedata.csv')</span></pre><p id="2fc9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这一行代码意味着我们将读取csv文件'<a class="ae lw" href="https://github.com/josephlee94/intuitive-deep-learning/blob/master/Part%201/housepricedata.csv" rel="noopener ugc nofollow" target="_blank"> housepricedata.csv </a>'(它应该与您的笔记本在同一个目录中)并将其存储在变量' df '中。如果我们想知道df中有什么，只需在灰色框中键入df，然后单击Alt-Enter:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="cfab" class="na lz hu mw b fv nb nc l nd ne">df</span></pre><p id="fd54" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">您的笔记本应该是这样的:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nf"><img src="../Images/f3c36ca4f82c6df480b6627d863cc061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A-7GF-yHyOfpOZzXuboFBQ.png"/></div></div></figure><p id="4570" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在这里，您可以稍微探索一下数据。前十列中有我们的输入特性:</p><ul class=""><li id="f41c" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">地块面积(平方英尺)</li><li id="8029" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">总体质量(从1到10分)</li><li id="1bc1" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">总体状况(从1到10分)</li><li id="67bf" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">地下室总面积(平方英尺)</li><li id="fda8" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">全浴室数量</li><li id="bb28" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">半个浴室的数量</li><li id="08a0" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">地上卧室的数量</li><li id="7423" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">地上房间总数</li><li id="2b18" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">壁炉数量</li><li id="5665" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">车库面积(平方英尺)</li></ul><p id="3ebe" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在我们的上一篇专栏文章中，我们有一个想要预测的特性:</p><ul class=""><li id="d48e" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">房价到底是不是中值以上？(1表示是，0表示否)</li></ul><p id="3738" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">既然我们已经看到了我们的数据的样子，我们想把它转换成数组供我们的机器处理:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="018e" class="na lz hu mw b fv nb nc l nd ne">dataset = df.values</span></pre><p id="5d25" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">为了将我们的数据帧转换成数组，我们只需将df的值(通过访问<em class="lv"> df.values </em>)存储到变量‘dataset’中。要查看变量“数据集”中的内容，只需在笔记本上的灰色框中键入“数据集”并运行单元格(Alt-Enter):</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="2ac1" class="na lz hu mw b fv nb nc l nd ne">dataset</span></pre><p id="5b76" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">如您所见，它现在都存储在一个数组中:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff ng"><img src="../Images/d5474f0ffe22c4815a014aa83b992960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*uXS0KUz1bkFzbdAFejqDHg.png"/></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">Converting our dataframe into an array</figcaption></figure><p id="9f7c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，我们将数据集分为输入要素(X)和我们希望预测的要素(Y)。要进行这种分割，我们只需将数组的前10列赋给一个名为X的变量，将数组的最后一列赋给一个名为y的变量。</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="1501" class="na lz hu mw b fv nb nc l nd ne">X = dataset[:,0:10]</span></pre><p id="ebe9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这可能看起来有点奇怪，但让我解释一下方括号内的内容。逗号之前的所有内容都是指数组的行，逗号之后的所有内容都是指数组的列。</p><p id="781f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">因为我们没有拆分行，所以我们在逗号前放了“:”。这意味着将数据集中的所有行放入x。</p><p id="3671" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们希望提取出前10列，因此逗号后面的‘0:10’意味着取第0到第9列并放入X中(我们不包括第10列)。我们的列从索引0开始，所以前10列实际上是列0到9。</p><p id="a637" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然后，我们将数组的最后一列赋给Y:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="98d2" class="na lz hu mw b fv nb nc l nd ne">Y = dataset[:,10]</span></pre><p id="5602" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">好了，现在我们已经将数据集分为输入要素(X)和我们想要预测的内容的标注(Y)。</p><p id="95e2" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们处理的下一步是确保输入要素的比例相似。现在，像地段面积这样的特征是以千计的，整体质量的分数范围是从1到10，壁炉的数量倾向于0、1或2。</p><p id="196e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这使得神经网络的初始化变得困难，从而引起一些实际问题。扩展数据的一种方法是使用scikit-learn的现有包(我们已经安装在<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/getting-started-with-python-for-deep-learning-and-data-science-9ca785560bbc">入门</a>帖子中)。</p><p id="ac35" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们首先必须导入我们想要使用的代码:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="e66d" class="na lz hu mw b fv nb nc l nd ne">from sklearn import preprocessing</span></pre><p id="23e3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这表示我想在sklearn包的“预处理”中使用代码。然后，我们使用一个名为最小-最大缩放器的函数来缩放数据集，以便所有输入要素都位于0和1之间(包括0和1):</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="fdb7" class="na lz hu mw b fv nb nc l nd ne">min_max_scaler = preprocessing.MinMaxScaler()<br/>X_scale = min_max_scaler.fit_transform(X)</span></pre><p id="86f8" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，我们的缩放数据集存储在数组‘X _ scale’中。如果您希望看到“X_scale”的样子，只需运行单元格:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="71f7" class="na lz hu mw b fv nb nc l nd ne">X_scale</span></pre><p id="41fc" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">您的Jupyter笔记本现在应该看起来有点像这样:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nl"><img src="../Images/a90f0ed7d84319c69e75ce3b8297cbe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7ckBFRxdO_qkeorz_rV8w.png"/></div></div></figure><p id="6c7a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，我们到了处理数据的最后一步，即将数据集分成训练集、验证集和测试集。</p><p id="2b21" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们将使用来自scikit-learn的名为“train_test_split”的代码，顾名思义，它将我们的数据集分成一个训练集和一个测试集。我们首先导入我们需要的代码:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="8e6e" class="na lz hu mw b fv nb nc l nd ne">from sklearn.model_selection import train_test_split</span></pre><p id="fd88" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然后，像这样分割数据集:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="3bfa" class="na lz hu mw b fv nb nc l nd ne">X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)</span></pre><p id="2b61" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这告诉scikit-learn您的val_and_test大小将占整个数据集的30%。如变量名所示，代码将把拆分的数据存储到等号左边的前四个变量中。</p><p id="9c2b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">不幸的是，这个函数只能帮助我们将数据集一分为二。由于我们想要一个单独的验证集和测试集，我们可以使用相同的函数在val_and_test上再次进行分割:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="3ced" class="na lz hu mw b fv nb nc l nd ne">X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)</span></pre><p id="7f0e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">上面的代码将val_and_test的大小平均分配给验证集和测试集。</p><p id="198c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">总之，我们现在将使用的数据集总共有六个变量:</p><ul class=""><li id="f0cb" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">X_train <em class="lv"> (10个输入特征，70%的完整数据集)</em></li><li id="d9f7" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">X_val <em class="lv"> (10个输入要素，15%的完整数据集)</em></li><li id="0eae" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">X_test <em class="lv"> (10个输入特征，全部数据集的15%)</em></li><li id="1cc4" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">Y_train <em class="lv"> (1个标签，全数据集的70)</em></li><li id="90b8" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">Y_val <em class="lv"> (1个标签，15%的完整数据集)</em></li><li id="19e7" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">Y_test <em class="lv"> (1个标签，15%的完整数据集)</em></li></ul><p id="c404" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">如果您想查看每个数组的形状(即它们的维度)，只需运行</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="4b1e" class="na lz hu mw b fv nb nc l nd ne">print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)</span></pre><p id="1b03" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">你的Jupyter笔记本应该是这样的:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nm"><img src="../Images/c8a25594b210ffb05e80224bf0b679db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dL42iPBuHdHPALcOXWy3iQ.png"/></div></div></figure><p id="e63a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">如您所见，训练集有1022个数据点，而验证和测试集各有219个数据点。X变量有10个输入特征，而Y变量只有一个要预测的特征。</p><p id="6921" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">而现在，我们的数据终于准备好了！唷！</p><p id="cb5a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">总结</strong>:在数据处理过程中，我们:</p><ul class=""><li id="64e6" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">读入CSV(逗号分隔值)文件并将它们转换为数组。</li><li id="d4ba" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">将数据集分割成输入要素和标注。</li><li id="3423" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">缩放数据，使输入要素具有相似的数量级。</li><li id="356c" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">将我们的数据集分成训练集、验证集和测试集。</li></ul></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><h1 id="51eb" class="ly lz hu bd ma mb mc md me mf mg mh mi ja mj jb mk jd ml je mm jg mn jh mo mp dt translated">建立和训练我们的第一个神经网络</h1><p id="a674" class="pw-post-body-paragraph jv jw hu jx b jy mq iv ka kb mr iy kd ke ms kg kh ki mt kk kl km mu ko kp kq hn dt translated">在<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1a-introduction-to-neural-networks-d7b16ebf6b99">直觉深度学习第1a部分</a>中，我们说过机器学习由两步组成。第一步是指定一个模板(一个架构)，第二步是从数据中找出最好的数字来填充这个模板。从现在开始，我们的代码也将遵循这两个步骤。</p><p id="180e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">第一步:建立架构</strong></p><p id="c8df" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们要做的第一件事是建立架构。我们先来思考一下我们想要什么样的神经网络架构。假设我们想要这个神经网络:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nn"><img src="../Images/437b5d99642ac5a12d9bab5497aa7635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*n-SIfloaWQxvQ5XMgnKmRA.png"/></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">Neural network architecture that we will use for our problem</figcaption></figure><p id="3f82" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">换句话说，我们想要这些层次:</p><ul class=""><li id="7424" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">隐藏层1: 32个神经元，ReLU激活</li><li id="7108" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">隐藏层2: 32个神经元，ReLU激活</li><li id="4afe" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">输出层:1个神经元，乙状结肠激活</li></ul><p id="3664" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，我们需要向Keras描述这个架构。我们将使用顺序模型，这意味着我们只需要按顺序描述上面的层。</p><p id="6fb5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">首先，让我们从Keras导入必要的代码:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="741b" class="na lz hu mw b fv nb nc l nd ne">from keras.models import Sequential<br/>from keras.layers import Dense</span></pre><p id="47c6" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然后，我们在Keras序列模型中指定如下内容:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="69a6" class="na lz hu mw b fv nb nc l nd ne">model = Sequential([<br/>    Dense(32, activation='relu', input_shape=(10,)),<br/>    Dense(32, activation='relu'),<br/>    Dense(1, activation='sigmoid'),<br/>])</span></pre><p id="bc1c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">就这样，上面的代码片段定义了我们的架构！上面的代码可以这样解释:</p><p id="6e08" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">model = Sequential([ ... ])</code></p><p id="485a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这意味着我们将把我们的模型存储在变量“model”中，我们将在方括号中依次(一层一层)描述它。</p><p id="c0c8" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">Dense(32, activation='relu', input_shape=(10,)),</code></p><p id="cb4a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们的第一层是一个密集层，有32个神经元，ReLU激活，输入形状是10，因为我们有10个输入特征。请注意,“密集”是指完全连接的层，这是我们将使用的层。</p><p id="4508" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">Dense(32, activation='relu'),</code></p><p id="05ed" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们的第二层也是致密层，有32个神经元，ReLU激活。请注意，我们不必描述输入形状，因为Keras可以从第一层的输出中进行推断。</p><p id="4d9f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">Dense(1, activation='sigmoid'),</code></p><p id="dab3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们的第三层是具有1个神经元的致密层，即乙状结肠激活。</p><p id="b503" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">就这样，我们用代码编写了我们的模型架构(模板)!</p><p id="16a1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">第二步:填入最佳数字</strong></p><p id="fb7c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">既然我们已经指定了我们的架构，我们需要为它找到最佳的数字。在我们开始培训之前，我们必须通过以下方式配置模型</p><ul class=""><li id="0224" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">告诉它你想用哪种算法来进行优化</li><li id="776b" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">告诉它使用什么损失函数</li><li id="543e" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">告诉它除了损失函数之外，你还想跟踪哪些指标</li></ul><p id="d320" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">用这些设置配置模型需要我们调用函数model.compile，就像这样:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="c393" class="na lz hu mw b fv nb nc l nd ne">model.compile(optimizer='sgd',<br/>              loss='binary_crossentropy',<br/>              metrics=['accuracy'])</span></pre><p id="ee87" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们将以下设置放在model.compile后面的括号中:</p><p id="9924" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">optimizer='sgd'</code></p><p id="e386" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">‘SGD’指的是随机梯度下降(这里指的是小批量梯度下降)，我们已经在<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1b-introduction-to-neural-networks-8565d97ddd2d">直观深度学习第1b部分</a>看到过。</p><p id="65e8" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">loss='binary_crossentropy'</code></p><p id="5923" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">取值为1或0的输出的损失函数称为二进制交叉熵。</p><p id="b156" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">metrics=['accuracy']</code></p><p id="5227" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">最后，我们希望在损失函数之上跟踪精度。现在，一旦我们运行了单元，我们就可以开始训练了！</p><p id="4ce0" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">对数据的训练非常简单，只需要我们写一行代码:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="ae7a" class="na lz hu mw b fv nb nc l nd ne">hist = model.fit(X_train, Y_train,<br/>          batch_size=32, epochs=100,<br/>          validation_data=(X_val, Y_val))</span></pre><p id="9b83" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">该函数被称为“拟合”,因为我们将参数与数据进行拟合。我们必须指定我们正在训练的数据，即<em class="lv"> X_train </em>和<em class="lv"> Y_train </em>。然后，我们指定我们的小批量的大小以及我们想要训练它多长时间(epochs)。最后，我们指定我们的验证数据是什么，这样模型将告诉我们在每个点上我们是如何处理验证数据的。这个函数将输出一个历史，我们将它保存在变量hist下。我们稍后在可视化时会用到这个变量。</p><p id="1e52" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，运行细胞，看它训练！您的Jupyter笔记本应该是这样的:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff nr"><img src="../Images/fd8a30bc9020e08c518a9d1e5cf29625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QyTgYnglgJ3pQV8k2skoBg.png"/></div></div></figure><p id="8bcc" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">你现在可以看到模型正在训练！通过观察这些数字，您应该能够看到随着时间的推移，损耗在减少，精度在提高。此时，您可以试验超参数和神经网络架构。再次运行单元格，查看调整超参数后，您的训练有何变化。</p><p id="eb89" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">一旦你对你的最终模型满意，我们可以在测试集上评估它。为了找到测试集的准确性，我们运行以下代码片段:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="2a1c" class="na lz hu mw b fv nb nc l nd ne">model.evaluate(X_test, Y_test)[1]</span></pre><p id="af76" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们之所以在model.evaluate函数后使用索引1，是因为该函数返回损失作为第一个元素，精度作为第二个元素。要仅输出精度，只需访问第二个元素(索引为1，因为第一个元素从0开始索引)。</p><p id="903b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">由于我们分割数据集的方式以及权重初始化的随机性，每次运行笔记本时，数字和图形都会略有不同。尽管如此，如果您遵循了我上面指定的架构，您应该可以获得80%到95%之间的测试准确率！</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff ns"><img src="../Images/ed55c6b1d3cbe456b99ff50ecb2a0b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCzPmGD2zlF46NJ7W5dXyQ.png"/></div></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">Evaluating on the test set</figcaption></figure><p id="8390" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在你有了，你已经编码了你的第一个神经网络并训练了它！恭喜你！</p><p id="6525" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">总结</strong>:编写我们的第一个神经网络只需要几行代码:</p><ul class=""><li id="d1e3" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">我们用Keras顺序模型来指定架构。</li><li id="ccfb" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">我们用<em class="lv"> model.compile </em>指定一些设置(优化器、损失函数、要跟踪的指标)</li><li id="6e5a" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">我们用<em class="lv"> model.fit </em>的训练数据来训练我们的模型(为我们的架构找到最佳参数)</li><li id="e96a" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">我们用<em class="lv">模型在测试集上评估我们的模型</em></li></ul></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><h1 id="12a1" class="ly lz hu bd ma mb mc md me mf mg mh mi ja mj jb mk jd ml je mm jg mn jh mo mp dt translated">可视化损失和准确性</h1><p id="dc0b" class="pw-post-body-paragraph jv jw hu jx b jy mq iv ka kb mr iy kd ke ms kg kh ki mt kk kl km mu ko kp kq hn dt translated">在<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1b-introduction-to-neural-networks-8565d97ddd2d">直觉深度学习第1b部分</a>中，我们谈到过拟合和一些正则化技术。我们如何知道我们的模型目前是否过度拟合？</p><p id="4d29" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们可能要做的是绘制训练损失和val损失在经过的时期数上的曲线。为了显示一些漂亮的图形，我们将使用matplotlib包。像往常一样，我们必须导入我们希望使用的代码:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="7540" class="na lz hu mw b fv nb nc l nd ne">import matplotlib.pyplot as plt</span></pre><p id="945d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然后，我们想要可视化训练损失和验证损失。为此，请运行以下代码片段:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="8f63" class="na lz hu mw b fv nb nc l nd ne">plt.plot(hist.history['loss'])<br/>plt.plot(hist.history['val_loss'])<br/>plt.title('Model loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Val'], loc='upper right')<br/>plt.show()</span></pre><p id="92c1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们将解释上面代码片段的每一行。前两行表示我们要绘制损失和val_loss。第三行指定了该图的标题“模型损耗”。第四行和第五行告诉我们y轴和x轴应该分别标注什么。第六行包括我们图表的图例，图例的位置在右上方。第七行告诉Jupyter notebook显示图形。</p><p id="df8d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">您的Jupyter笔记本应该是这样的:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nt"><img src="../Images/1e0eace578d60a9d576013a5a98b397e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*s26DJqI0JZaUvm3FQP4QdA.png"/></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">A graph of model loss that you should see in your Jupyter notebook</figcaption></figure><p id="f542" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们可以用下面的代码做同样的事情来绘制我们的训练精度和验证精度:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="25cc" class="na lz hu mw b fv nb nc l nd ne">plt.plot(hist.history['acc'])<br/>plt.plot(hist.history['val_acc'])<br/>plt.title('Model accuracy')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Val'], loc='lower right')<br/>plt.show()</span></pre><p id="24a4" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">您应该会得到一个看起来有点像这样的图表:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nu"><img src="../Images/3ce568a452dea21e816b02deadcd648f.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*vn6RYv6i4Um7zth2TNNSXQ.png"/></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">Plot of model accuracy for training and validation set</figcaption></figure><p id="3064" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">由于我们的模型对训练集的改进看起来与对验证集的改进有些匹配，所以过度拟合似乎不是我们模型中的一个<em class="lv">大问题。</em></p><p id="6069" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">总结</strong>:我们使用<em class="lv"> matplotlib </em>来可视化训练和验证随时间的损失/准确性，以查看我们的模型中是否存在过度拟合。</p></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><h1 id="9d12" class="ly lz hu bd ma mb mc md me mf mg mh mi ja mj jb mk jd ml je mm jg mn jh mo mp dt translated">将正则化加入我们的神经网络</h1><p id="b9c6" class="pw-post-body-paragraph jv jw hu jx b jy mq iv ka kb mr iy kd ke ms kg kh ki mt kk kl km mu ko kp kq hn dt translated">为了将正则化引入我们的神经网络，让我们用一个会严重过度适应我们的训练集的神经网络来公式化。我们称之为模型2。</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="d8d2" class="na lz hu mw b fv nb nc l nd ne">model_2 = Sequential([<br/>    Dense(1000, activation='relu', input_shape=(10,)),<br/>    Dense(1000, activation='relu'),<br/>    Dense(1000, activation='relu'),<br/>    Dense(1000, activation='relu'),<br/>    Dense(1, activation='sigmoid'),<br/>])</span><span id="7428" class="na lz hu mw b fv nv nc l nd ne">model_2.compile(optimizer='adam',<br/>              loss='binary_crossentropy',<br/>              metrics=['accuracy'])</span><span id="8aac" class="na lz hu mw b fv nv nc l nd ne">hist_2 = model_2.fit(X_train, Y_train,<br/>          batch_size=32, epochs=100,<br/>          validation_data=(X_val, Y_val))</span></pre><p id="545c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">如果我们运行此代码，并使用下面的代码绘制hist_2的损失图(注意，除了我们使用“hist_2”而不是“hist”之外，代码是相同的):</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="15a4" class="na lz hu mw b fv nb nc l nd ne">plt.plot(hist_2.history['loss'])<br/>plt.plot(hist_2.history['val_loss'])<br/>plt.title('Model loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Val'], loc='upper right')<br/>plt.show()</span></pre><p id="d9b0" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们得到了这样一幅图:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nw"><img src="../Images/2cdc0daaca759a1a6041c01b481283ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*x0UpMPtTfyupv9S1XRqCyQ.png"/></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">Loss curves for over-fitting model</figcaption></figure><p id="8797" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这是过度拟合的明显标志。训练损失正在减少，但是验证损失远远高于训练损失，并且还在增加(超过第20个时期的拐点)。如果我们使用下面的代码绘制精度图:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="0d2f" class="na lz hu mw b fv nb nc l nd ne">plt.plot(hist_2.history['acc'])<br/>plt.plot(hist_2.history['val_acc'])<br/>plt.title('Model accuracy')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Val'], loc='lower right')<br/>plt.show()</span></pre><p id="26bf" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们还可以看到训练和验证准确性之间更明显差异:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nx"><img src="../Images/dfe818cea635f52fbf864aaae99e816b.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*U7SNJNFYKu2DiU0WIn0M5w.png"/></div><figcaption class="nh ni fg fe ff nj nk bd b be z ek">Training and validation accuracy for our overfitting model</figcaption></figure><p id="2ff4" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，让我们尝试一些减少过度拟合的策略(除了将我们的架构改回我们的第一个模型)。记得在<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-1b-introduction-to-neural-networks-8565d97ddd2d">直观深度学习第1b部分</a>中，我们介绍了三种减少过度拟合的策略。</p><p id="b96b" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">在这三者中，我们将在这里合并L2正规化和辍学。我们在这里没有添加早期停止的原因是因为在我们使用了前两个策略之后，验证损失不会呈现我们上面看到的U形，所以早期停止不会那么有效。</p><p id="75dd" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">首先，让我们导入L2正则化和辍学所需的代码:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="71d1" class="na lz hu mw b fv nb nc l nd ne">from keras.layers import Dropout<br/>from keras import regularizers</span></pre><p id="8de1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">然后，我们指定第三个模型，如下所示:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="9cb7" class="na lz hu mw b fv nb nc l nd ne">model_3 = Sequential([<br/>    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(10,)),<br/>    Dropout(0.3),<br/>    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),<br/>    Dropout(0.3),<br/>    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),<br/>    Dropout(0.3),<br/>    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),<br/>    Dropout(0.3),<br/>    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),<br/>])</span></pre><p id="f763" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">你能看出模型3和模型2的区别吗？有两个主要区别:</p><p id="1658" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">区别1 </strong>:要添加L2正则化，请注意，我们已经在每个密集层中添加了一些额外的代码，如下所示:</p><p id="5932" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">kernel_regularizer=regularizers.l2(0.01)</code></p><p id="fe80" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这告诉Keras将这些参数的平方值包括在我们的总损失函数中，并在损失函数中将它们加权0.01。</p><p id="6e10" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">差异2 </strong>:为了添加漏失，我们添加了一个新图层，如下所示:</p><p id="80fd" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh no np nq mw b">Dropout(0.3),</code></p><p id="94f2" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这就意味着前一层的神经元在训练时有0.3的概率会掉线。让我们编译它，并使用与我们的模型2(过度拟合的模型)相同的参数运行它:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="17b4" class="na lz hu mw b fv nb nc l nd ne">model_3.compile(optimizer='adam',<br/>              loss='binary_crossentropy',<br/>              metrics=['accuracy'])</span><span id="9bf7" class="na lz hu mw b fv nv nc l nd ne">hist_3 = model_3.fit(X_train, Y_train,<br/>          batch_size=32, epochs=100,<br/>          validation_data=(X_val, Y_val))</span></pre><p id="1126" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，让我们绘制损耗和精度图。你会注意到，损失在开始时要高得多，这是因为我们改变了损失函数。为了绘制窗口在0和1.2之间放大的损耗，我们在绘制时添加了一行额外的代码(plt.ylim):</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="429e" class="na lz hu mw b fv nb nc l nd ne">plt.plot(hist_3.history['loss'])<br/>plt.plot(hist_3.history['val_loss'])<br/>plt.title('Model loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Val'], loc='upper right')<br/>plt.ylim(top=1.2, bottom=0)<br/>plt.show()</span></pre><p id="c9bc" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们将得到一个损失图，如下所示:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff ny"><img src="../Images/a43167e9468f500dfc8d3be78accc38b.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*CKPmM3xs62R5VNUUyXtovw.png"/></div></figure><p id="6171" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">您可以看到验证损失与我们的培训损失非常接近。让我们用类似的代码片段来绘制准确性:</p><pre class="jk jl jm jn fq mv mw mx my aw mz dt"><span id="39d8" class="na lz hu mw b fv nb nc l nd ne">plt.plot(hist_3.history['acc'])<br/>plt.plot(hist_3.history['val_acc'])<br/>plt.title('Model accuracy')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Val'], loc='lower right')<br/>plt.show()</span></pre><p id="72f1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们会得到这样一幅图:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff nz"><img src="../Images/f7261052b0d173b2f22dcda52234329a.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*diMurPbdoJO4MW3_LcSuXg.png"/></div></figure><p id="1b0f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">与模型2中的模型相比，我们大大减少了过度拟合！这就是我们如何应用正则化技术来减少对训练集的过度拟合。</p><p id="96eb" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">总结</strong>:为了处理过度拟合，我们可以将以下策略编码到我们的模型中，每个策略大约一行代码:</p><ul class=""><li id="2189" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">L2正则化</li><li id="fed6" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">拒绝传统社会的人</li></ul><p id="6435" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">如果我们将训练/验证损失和准确性可视化，我们可以看到这些增加有助于处理过度拟合！</p></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><p id="165e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">综合摘要</strong>:在这篇文章中，我们编写了Python代码来:</p><ul class=""><li id="e469" class="la lb hu jx b jy jz kb kc ke lc ki ld km le kq lf lg lh li dt translated">探索和处理数据</li><li id="cf0d" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">建立和训练我们的神经网络</li><li id="02a8" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">可视化损失和准确性</li><li id="6039" class="la lb hu jx b jy lj kb lk ke ll ki lm km ln kq lf lg lh li dt translated">给我们的神经网络添加正则化</li></ul><p id="d8a1" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们经历了很多，却没有写太多行代码！构建和训练我们的神经网络只需要大约4到5行代码，并且试验不同的模型架构只是交换不同的层或改变不同的超参数的简单问题。Keras确实使构建我们的神经网络变得更加容易，我们将继续将其用于计算机视觉和自然语言处理中更高级的应用。</p><p id="f373" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">下一步</strong>:在我们下一个<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/build-your-first-convolutional-neural-network-to-recognize-images-84b9c78fe0ce">编码伴侣第2部分</a>中，我们将探索如何编码我们自己的卷积神经网络(CNN)来进行图像识别！</p><div class="oa ob fm fo oc od"><a rel="noopener follow" target="_blank" href="/intuitive-deep-learning/build-your-first-convolutional-neural-network-to-recognize-images-84b9c78fe0ce"><div class="oe ab ej"><div class="of ab og cl cj oh"><h2 class="bd hv fv z el oi eo ep oj er et ht dt translated">建立你的第一个卷积神经网络来识别图像</h2><div class="ok l"><h3 class="bd b fv z el oi eo ep oj er et ek translated">一步一步的指南，建立自己的图像识别软件与卷积神经网络使用Keras上…</h3></div><div class="ol l"><p class="bd b gc z el oi eo ep oj er et ek translated">medium.com</p></div></div><div class="om l"><div class="on l oo op oq om or jt od"/></div></div></a></div><p id="1c5a" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">一定要先在这里对CNN有个直观的了解:<a class="ae lw" rel="noopener" href="/intuitive-deep-learning/intuitive-deep-learning-part-2-cnns-for-computer-vision-24992d050a27">直观的深度学习第二部分:计算机视觉的CNN</a></p></div><div class="ab cl lo lp hc lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hn ho hp hq hr"><p id="b937" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">关于作者:</strong></p><p id="2d23" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">你好，我是约瑟夫！我最近从斯坦福大学毕业，在那里我和吴恩达一起在<a class="ae lw" href="https://stanfordmlgroup.github.io/" rel="noopener ugc nofollow" target="_blank">斯坦福机器学习小组</a>工作。我想让深度学习概念尽可能直观，尽可能容易被每个人理解，这激励了我的出版:<a class="ae lw" href="https://medium.com/intuitive-deep-learning" rel="noopener">直观的深度学习</a>。</p></div></div>    
</body>
</html>