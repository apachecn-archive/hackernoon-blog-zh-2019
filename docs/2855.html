<html>
<head>
<title>How to run Keras model on RK3399Pro</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在RK3399Pro上运行Keras模型</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-run-keras-model-on-rk3399pro-86093bf60372?source=collection_archive---------3-----------------------#2019-05-04">https://medium.com/hackernoon/how-to-run-keras-model-on-rk3399pro-86093bf60372?source=collection_archive---------3-----------------------#2019-05-04</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="d83a" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">要获得完整的源代码，请查看我的GitHub库。</h2></div><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff jk"><img src="../Images/02005f51e13dcef369e589e9388b8f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tDkFCJ1GhenVheV6.png"/></div></div></figure><p id="7dfc" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">此前，我们已经推出了多种嵌入式边缘计算解决方案并进行基准测试，包括用于英特尔神经计算棒的<a class="ae jj" href="https://www.dlology.com/blog/how-to-run-keras-model-inference-x3-times-faster-with-cpu-and-intel-openvino-1/" rel="noopener ugc nofollow" target="_blank"> OpenVINO </a>、用于ARM微控制器的<a class="ae jj" href="https://www.dlology.com/blog/how-to-run-deep-learning-model-on-microcontroller-with-cmsis-nn/" rel="noopener ugc nofollow" target="_blank"> CMSIS-NN </a>以及用于<a class="ae jj" href="https://www.dlology.com/blog/how-to-run-keras-model-on-jetson-nano/" rel="noopener ugc nofollow" target="_blank"> Jetson Nano </a>的TensorRT模型。</p><p id="deef" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">它们的共同点是每个硬件提供商都有自己的工具和API来量化张量流图，并结合相邻层来加速推理。</p><p id="056f" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">这一次，我们将看看RockChip RK3399Pro SoC，它内置NPU(神经计算单元)，在8位精度下的推理速度为2.4次，能够以超过28 FPS的速度运行Inception V3模型。您将会看到，在电路板上部署Keras模型与前面提到的解决方案非常相似。</p><ol class=""><li id="de5c" class="ks kt hu jy b jz ka kc kd kf ku kj kv kn kw kr kx ky kz la dt translated">将Keras模型冻结为张量流图，并用RKNN工具包创建推理模型。</li><li id="b3f6" class="ks kt hu jy b jz lb kc lc kf ld kj le kn lf kr kx ky kz la dt translated">将RKNN模型加载到RK3399Pro开发板上并进行预测。</li></ol><p id="ec78" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">让我们开始第一次设置。</p><h1 id="4fbd" class="lg lh hu bd li lj lk ll lm ln lo lp lq ja lr jb ls jd lt je lu jg lv jh lw lx dt translated">设置RK3399Pro板</h1><p id="f7e8" class="pw-post-body-paragraph jw jx hu jy b jz ly iv kb kc lz iy ke kf ma kh ki kj mb kl km kn mc kp kq kr hn dt translated">任何带有RK3399Pro SoC的开发板，如<a class="ae jj" href="https://www.amazon.com/Toybrick-Development-Artificial-Intelligence-Acceleration/dp/B07P3M7683" rel="noopener ugc nofollow" target="_blank"> Rockchip Toybrick RK3399PRO开发板</a>或<a class="ae jj" href="http://shop.t-firefly.com/goods.php?id=98" rel="noopener ugc nofollow" target="_blank"> Firefly Core-3399Pro </a>都应该可以工作。我有一个Rockchip Toybrick RK3399PRO板，6GB内存(2GB专用于NPU)。</p><p id="2794" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">该板带有许多类似于Jetson Nano的连接器和接口。值得一提的是，HDMI连接器无法与我的显示器一起工作，但是，我可以让USB Type-C转HDMI适配器工作。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff md"><img src="../Images/9f625ada0e473639efea9e6641bbf998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Pj4r3OglhITdVbmj.png"/></div></div><figcaption class="me mf fg fe ff mg mh bd b be z ek"><a class="ae jj" href="https://www.amazon.com/Toybrick-Development-Artificial-Intelligence-Acceleration/dp/B07P3M7683" rel="noopener ugc nofollow" target="_blank">Rockchip Toybrick RK3399PRO Board</a></figcaption></figure><p id="be1a" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">它预装了Fedora Linux release 28，默认用户名和密码为“toybrick”。</p><p id="26c5" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">RK3399Pro有6个内核64位CPU，采用<a class="ae jj" href="https://en.wikipedia.org/wiki/ARM_architecture#AArch64" rel="noopener ugc nofollow" target="_blank"> aarch64架构</a>与<a class="ae jj" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/" rel="noopener ugc nofollow" target="_blank">杰特森纳米</a>相同的架构，但与只有ARMv7 32位的树莓3B+截然不同。这意味着任何针对Raspberry Pi的预编译python wheel包都不太可能与RK3399Pro或Jetson Nano一起工作。不过不要绝望，可以从我的<a class="ae jj" href="https://coding.net/u/zcw607/p/aarch64_python_packages/git" rel="noopener ugc nofollow" target="_blank">aarch 64 _ python _ packages</a>repo下载预编译的aarch64 python wheel包文件包括scipy、onnx、tensorflow和rknn_toolkit从他们的<a class="ae jj" href="https://github.com/rockchip-toybrick/RKNPUTool/tree/master/rknn-toolkit/package" rel="noopener ugc nofollow" target="_blank">官方GitHub </a>下载。</p><p id="c220" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">将这些wheel文件传输到RK3399Pro板，然后运行以下命令。</p><figure class="jl jm jn jo fq jp"><div class="bz el l di"><div class="mi mj l"/></div></figure><h1 id="a419" class="lg lh hu bd li lj lk ll lm ln lo lp lq ja lr jb ls jd lt je lu jg lv jh lw lx dt translated">步骤1:冻结Keras模型并转换为RKNN模型</h1><p id="ef56" class="pw-post-body-paragraph jw jx hu jy b jz ly iv kb kc lz iy ke kf ma kh ki kj mb kl km kn mc kp kq kr hn dt translated">如果选择在开发板上运行，从TensorFlow图形到RKNN模型的转换将需要相当长的时间。因此，建议购买一台Linux开发机器，可以是Windows WSL、Ubuntu VM，甚至是<a class="ae jj" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>。</p><p id="52ef" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">第一次设置你的开发，你可以从他们的<a class="ae jj" href="https://github.com/rockchip-toybrick/RKNPUTool/tree/master/rknn-toolkit/package" rel="noopener ugc nofollow" target="_blank">官方GitHub </a>找到rknn工具包轮子包文件。</p><figure class="jl jm jn jo fq jp"><div class="bz el l di"><div class="mi mj l"/></div></figure><p id="cc3f" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">将一个Keras模型冻结到一个单独的<code class="eh mk ml mm mn b">.pb</code>文件类似于之前的教程。你可以在GitHub上的<a class="ae jj" href="https://github.com/Tony607/Keras_RK3399pro/freeze_graph.py" rel="noopener ugc nofollow" target="_blank"> freeze_graph.py </a>中找到代码。一旦完成，你将有一个ImageNet InceptionV3冻结模型接受输入与形状</p><p id="b4ec" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">记下输入和输出节点名，因为我们将在使用RKNN工具包加载冻结模型时指定它们。对于InceptionV3和许多其他<a class="ae jj" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank"> Keras ImageNet型号</a>来说，</p><pre class="jl jm jn jo fq mo mn mp mq aw mr dt"><span id="9858" class="ms lh hu mn b fv mt mu l mv mw">INPUT_NODE: ['input_1']<br/>OUTPUT_NODE: ['predictions/Softmax']</span></pre><p id="7772" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">然后，您可以运行<a class="ae jj" href="https://github.com/Tony607/Keras_RK3399pro/convert_rknn.py" rel="noopener ugc nofollow" target="_blank"> convert_rknn.py </a>脚本，将您的模型量化为uint8数据类型，或者更具体地说，非对称量化uint8类型。</p><p id="6a86" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">对于非对称量化，与对称模式相比，量化范围得到了充分利用。这是因为我们将浮点范围的最小/最大值精确地映射到量化范围的最小/最大值。下图说明了两种基于范围的线性量化方法。你可以在这里阅读更多关于它的<a class="ae jj" href="https://nervanasystems.github.io/distiller/algo_quantization.html" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/176f9133ddf66865b9b64cf5d0bcfcec.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/0*Z6LzsimOQ9ZFNWGz.png"/></div><figcaption class="me mf fg fe ff mg mh bd b be z ek">Asymmetric vs the symmetric mode</figcaption></figure><p id="601e" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><code class="eh mk ml mm mn b">rknn.config</code>还允许您用4个值的列表<code class="eh mk ml mm mn b">(M0, M1, M2, S0)</code>来指定<code class="eh mk ml mm mn b">channel_mean_value</code>，以此来自动将uint8(0~255)数据类型的图像数据标准化到推理管道中的不同范围。具有TensorFlow后端的Keras ImageNet模型期望图像数据值归一化在-1到1之间。为了实现这一点，我们将<code class="eh mk ml mm mn b">channel_mean_value</code>设置为<code class="eh mk ml mm mn b">"128 128 128 128"</code>，其中前三个值是每个RGB颜色通道的平均值，最后一个值是比例参数。输出数据计算如下。</p><pre class="jl jm jn jo fq mo mn mp mq aw mr dt"><span id="503d" class="ms lh hu mn b fv mt mu l mv mw">R_out = (R - M0)/S0<br/>G_out = (G - M1)/S0<br/>B_out = (B - M2)/S0</span></pre><p id="561e" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">如果您使用Python OpenCV读取或捕获图像，颜色通道是BGR顺序的，在这种情况下，您可以将<code class="eh mk ml mm mn b">rknn.config()</code>的<code class="eh mk ml mm mn b">reorder_channel</code>参数设置为<code class="eh mk ml mm mn b">"2 1 0"</code>，这样颜色通道将在推理管道中重新排序为RGB。</p><figure class="jl jm jn jo fq jp"><div class="bz el l di"><div class="mi mj l"/></div></figure><p id="9a0c" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">运行脚本后，项目目录中会有<code class="eh mk ml mm mn b">inception_v3.rknn</code>，将文件传输到开发板进行推理。</p><h1 id="75aa" class="lg lh hu bd li lj lk ll lm ln lo lp lq ja lr jb ls jd lt je lu jg lv jh lw lx dt translated">步骤2:加载RKNN模型并进行预测</h1><p id="8775" class="pw-post-body-paragraph jw jx hu jy b jz ly iv kb kc lz iy ke kf ma kh ki kj mb kl km kn mc kp kq kr hn dt translated">推理管道负责包括图像标准化和颜色通道重新排序在内的工作，如前一步所配置的那样。留给您的是加载模型、初始化运行时环境和运行推理。</p><figure class="jl jm jn jo fq jp"><div class="bz el l di"><div class="mi mj l"/></div></figure><p id="62a7" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">输出形状为(1，1，1000 ),代表1000个类的逻辑。</p><h1 id="9643" class="lg lh hu bd li lj lk ll lm ln lo lp lq ja lr jb ls jd lt je lu jg lv jh lw lx dt translated">基准测试结果</h1><p id="f183" class="pw-post-body-paragraph jw jx hu jy b jz ly iv kb kc lz iy ke kf ma kh ki kj mb kl km kn mc kp kq kr hn dt translated">基准设定。</p><ul class=""><li id="d43b" class="ks kt hu jy b jz ka kc kd kf ku kj kv kn kw kr my ky kz la dt translated">型号:Inception V3</li><li id="5908" class="ks kt hu jy b jz lb kc lc kf ld kj le kn lf kr my ky kz la dt translated">量化:uint8</li><li id="a06f" class="ks kt hu jy b jz lb kc lc kf ld kj le kn lf kr my ky kz la dt translated">输入大小:(1，499，499，3)</li></ul><p id="7e50" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">让我们运行几次推理，看看它能有多快。</p><figure class="jl jm jn jo fq jp"><div class="bz el l di"><div class="mi mj l"/></div></figure><p id="9db9" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">它实现了28.94 的平均<strong class="jy hv"> FPS，甚至比运行小得多的MobileNetV2模型的<a class="ae jj" href="https://www.dlology.com/blog/how-to-run-keras-model-on-jetson-nano/" rel="noopener ugc nofollow" target="_blank"> Jetson Nano </a>的27.18 FPS还要快。</strong></p><h1 id="1999" class="lg lh hu bd li lj lk ll lm ln lo lp lq ja lr jb ls jd lt je lu jg lv jh lw lx dt translated">结论和进一步阅读</h1><p id="422b" class="pw-post-body-paragraph jw jx hu jy b jz ly iv kb kc lz iy ke kf ma kh ki kj mb kl km kn mc kp kq kr hn dt translated">这篇文章向你展示了如何开始使用RK3399Pro开发板，转换和实时运行Keras图像分类。</p><h2 id="c1ec" class="ms lh hu bd li mz na nb lm nc nd ne lq kf nf ng ls kj nh ni lu kn nj nk lw nl dt translated">要获得完整的源代码，请查看我的GitHub库。</h2></div><div class="ab cl nm nn hc no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="hn ho hp hq hr"><p id="84dd" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><em class="nt">最初发表于</em><a class="ae jj" href="https://www.dlology.com/blog/how-to-run-keras-model-on-rk3399pro/" rel="noopener ugc nofollow" target="_blank"><em class="nt">【https://www.dlology.com】</em></a><em class="nt">。</em></p></div></div>    
</body>
</html>