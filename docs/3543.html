<html>
<head>
<title>Getting Started With Pytorch In Google Collab With Free GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用免费 GPU 在 Google Collab 中开始使用 Pytorch</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/getting-started-with-pytorch-in-google-collab-with-free-gpu-61a5c70b86a#2019-06-09">https://medium.com/hackernoon/getting-started-with-pytorch-in-google-collab-with-free-gpu-61a5c70b86a#2019-06-09</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div class="fe ff ir"><img src="../Images/92b11ea8bfd48907b32243cc7436cacb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*g9H8bFnKp-aJXkDA"/></div></figure><p id="f19f" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">Pytorch 是深度学习框架；基于<a class="ae jw" href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29" rel="noopener ugc nofollow" target="_blank"> Torch </a>的一组函数和库，允许你进行为 Python 语言设计的高阶编程。Torch 是一个基于编程语言<a class="ae jw" href="https://www.lua.org/" rel="noopener ugc nofollow" target="_blank"> Lua </a>的开源机器学习包。它主要由脸书的人工智能研究小组开发，优步的<em class="jx"> Pyro </em>概率编程语言软件就是基于它开发的。</p><p id="95c6" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">PyTorch 更“pythonic 化”，有更一致的 API。它还有本机的 ONNX 模型导出，可以用来加速推理。PyTorch 与<a class="ae jw" href="https://github.com/wkentaro/pytorch-for-numpy-users" rel="noopener ugc nofollow" target="_blank"> numpy </a>共享许多命令，这有助于轻松学习框架。</p><p id="e63c" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">PyTorch 的核心提供了两个主要特性:</p><ul class=""><li id="93b1" class="jy jz hu ja b jb jc jf jg jj ka jn kb jr kc jv kd ke kf kg dt translated">n 维张量，类似于 Numpy，但可以在 GPU 上运行</li><li id="5702" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated">用于建立和训练神经网络的自动微分</li></ul><p id="546f" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">如果您使用的是 anaconda 发行版，可以通过在 anaconda 提示符下运行下面的命令来安装 Pytorch。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="faf6" class="kv kw hu kr b fv kx ky l kz la">conda install pytorch-cpu torchvision-cpu -c pytorch</span></pre><p id="6578" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><strong class="ja hv">文章的其余部分结构如下:</strong></p><ul class=""><li id="0658" class="jy jz hu ja b jb jc jf jg jj ka jn kb jr kc jv kd ke kf kg dt translated"><strong class="ja hv">到底什么是 Colab？</strong></li><li id="e265" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated"><strong class="ja hv">在 Colab 中设置 GPU</strong></li><li id="8d47" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated"><strong class="ja hv"> Pytorch 张量</strong></li><li id="b705" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated"><strong class="ja hv">简单的张量运算</strong></li><li id="7f76" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated">Pytorch 到 Numpy 桥</li><li id="e68b" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated"><strong class="ja hv"> CUDA 支持</strong></li><li id="cf65" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated"><strong class="ja hv">自动微分</strong></li><li id="3eba" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated"><strong class="ja hv">结论</strong></li></ul><p id="358c" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">如果你想跳过理论部分，直接进入代码，</p><div class="lb lc fm fo ld le"><a href="https://github.com/Niranjankumar-c/DeepLearning-PadhAI/tree/master/DeepLearning_Materials/2_GettingStarted_With_Pytorch" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab ej"><div class="lg ab lh cl cj li"><h2 class="bd hv fv z el lj eo ep lk er et ht dt translated">niranjankumar-c/deep learning-PadhAI</h2><div class="ll l"><h3 class="bd b fv z el lj eo ep lk er et ek translated">来自 pad hai-Niranjankumar-c/deep learning-pad hai 的深度学习课程相关的所有代码文件</h3></div><div class="lm l"><p class="bd b gc z el lj eo ep lk er et ek translated">github.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls iw le"/></div></div></a></div><h1 id="8165" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">Colab —合作实验室</h1><p id="2cfb" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated"><a class="ae jw" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>是机器学习教育和研究的研究工具。这是一个 Jupyter 笔记本电脑环境，不需要设置即可使用。Colab 提供由谷歌托管的免费 GPU 云服务，以鼓励机器学习领域的合作，而不用担心硬件要求。Colab 于 2017 年 10 月由谷歌向公众发布。</p><figure class="km kn ko kp fq iv fe ff paragraph-image"><div class="fe ff mv"><img src="../Images/e17fa26e04c9451ccb7c670893505286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*VvUksMmJn4k_1w4ZhGqyKw.png"/></div></figure><h1 id="0bba" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">Colab 入门</h1><ul class=""><li id="b42a" class="jy jz hu ja b jb mq jf mr jj mw jn mx jr my jv kd ke kf kg dt translated">使用您的 Google 帐户登录</li><li id="b83f" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated">通过<strong class="ja hv">文件- &gt;新建 Python 3 笔记本或新建 Python 2 笔记本</strong>创建一个新笔记本</li></ul><p id="1619" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">你也可以通过 Google Drive 在 Colab 中创建一个笔记本</p><ul class=""><li id="0c26" class="jy jz hu ja b jb jc jf jg jj ka jn kb jr kc jv kd ke kf kg dt translated">转到<a class="ae jw" href="http://drive.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌驱动</a></li><li id="fc70" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated">在驱动器中创建一个任意名称的文件夹来保存项目</li><li id="173a" class="jy jz hu ja b jb kh jf ki jj kj jn kk jr kl jv kd ke kf kg dt translated">通过<strong class="ja hv">右键单击&gt;更多&gt;协作室</strong>创建新笔记本</li></ul><figure class="km kn ko kp fq iv fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/09162f75d05546fc63838104f7091a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/0*iKhfZgliLEeC2pvN"/></div></figure><p id="a90a" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">要重命名笔记本，只需点击笔记本顶部的文件名。</p><figure class="km kn ko kp fq iv fe ff paragraph-image"><div class="fe ff ir"><img src="../Images/a1fba8dd522b2dc4bd05c0895b287b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*2c1BkDyGMmHied1q"/></div></figure><h1 id="7dc7" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">在 Colab 中设置 GPU</h1><p id="1e15" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">在 Colab 中，您将获得 12 小时的执行时间，但是如果您的空闲时间超过 60 分钟，会话将被断开。这意味着每 12 小时，我们分配的虚拟机上的磁盘、RAM、CPU 缓存和数据将被擦除。</p><p id="78f1" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">要启用 GPU 硬件加速器，只需进入<strong class="ja hv">运行时- &gt;更改运行时类型- &gt;硬件加速器- &gt; GPU </strong></p><figure class="km kn ko kp fq iv fe ff paragraph-image"><div class="fe ff na"><img src="../Images/9949748d6dbf0b4fe7452082a23e1fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/0*bBTbHAAhUewpI0Uw"/></div></figure><h1 id="3784" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">Pytorch —张量</h1><p id="5775" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">基于 Numpy 的运算没有优化到利用 GPU 来加速其数值计算。对于现代深度神经网络，GPU 通常会提供<a class="ae jw" href="https://github.com/jcjohnson/cnn-benchmarks" rel="noopener ugc nofollow" target="_blank">50 倍或更大的加速比</a>。所以，不幸的是，numpy 对于现代深度学习来说是不够的。Pytorch 在这里引入了张量的概念。Pytorch 张量在概念上等同于 n 维 numpy 数组。与 numpy 不同，PyTorch 张量可以利用 GPU 来加速它们的数值计算</p><p id="0a90" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">让我们看看如何创建 Pytorch 张量。首先，我们将导入所需的库。记住 torch，numpy 和 matplotlib 是预装在 Colab 的虚拟机里的。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="55d5" class="kv kw hu kr b fv kx ky l kz la">import torch import numpy <br/>import matplotlib.pyplot as plt</span></pre><p id="f219" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">PyTorch 中的默认张量类型是定义为<code class="eh nb nc nd kr b"><strong class="ja hv">torch.FloatTensor</strong></code>的浮点张量。我们可以通过使用<code class="eh nb nc nd kr b">torch</code>包中的内置函数来创建张量。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="323d" class="kv kw hu kr b fv kx ky l kz la">## creating a tensor of 3 rows and 2 columns consisting of ones <br/>&gt;&gt; x = torch.ones(3,2) <br/>&gt;&gt; print(x) tensor([[1., 1.], [1., 1.], [1., 1.]]) </span><span id="a402" class="kv kw hu kr b fv ne ky l kz la">## creating a tensor of 3 rows and 2 columns consisting of zeros <br/>&gt;&gt; x = torch.zeros(3,2) <br/>&gt;&gt; print(x) tensor([[0., 0.], [0., 0.], [0., 0.]])</span></pre><p id="b997" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">通过随机初始化创建张量</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="d3bd" class="kv kw hu kr b fv kx ky l kz la">To increase the reproducibility, we often set the random seed to a specific value first. <br/>&gt;&gt; torch.manual_seed(2) #generating tensor randomly <br/>&gt;&gt; x = torch.rand(3, 2) <br/>&gt;&gt; print(x) #generating tensor randomly from normal distribution <br/>&gt;&gt; x = torch.randn(3,3) <br/>&gt;&gt; print(x)</span></pre><h1 id="d782" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">简单张量运算</h1><h1 id="e64f" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">张量的切片</h1><p id="fb8d" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">你可以像切<code class="eh nb nc nd kr b">ndarrays</code>一样切 PyTorch 张量</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="f07b" class="kv kw hu kr b fv kx ky l kz la">#create a tensor <br/>&gt;&gt; x = torch.tensor([[1, 2], [3, 4], [5, 6]]) <br/>&gt;&gt; print(x[:, 1]) # Every row, only the last column &gt;&gt; print(x[0, :]) # Every column in first row &gt;&gt; y = x[1, 1] # take the element in first row and first column and create a another tensor &gt;&gt; print(y)</span></pre><h1 id="b367" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">重塑张量</h1><h2 id="d116" class="kv kw hu bd lu nf ng nh ly ni nj nk mc jj nl nm mg jn nn no mk jr np nq mo nr dt translated">将张量整形为不同的形状</h2><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="eb00" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; x = torch.tensor([[1, 2], [3, 4], [5, 6]]) #(3 rows and 2 columns) <br/>&gt;&gt; y = x.view(2, 3) #reshaping to 2 rows and 3 columns</span></pre><h2 id="feb2" class="kv kw hu bd lu nf ng nh ly ni nj nk mc jj nl nm mg jn nn no mk jr np nq mo nr dt translated">使用<code class="eh nb nc nd kr b">-1</code>重塑张量</h2><p id="fd94" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated"><code class="eh nb nc nd kr b">-1</code>表示形状将从以前的维度推断出来。在下面的代码片段中<code class="eh nb nc nd kr b">x.view(6,-1)</code>将产生一个形状为<code class="eh nb nc nd kr b">6x1</code>的张量，因为我们已经将行的大小固定为 6，Pytorch 现在将推断列的最佳可能维度，这样它将能够容纳张量中存在的所有值。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="e922" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; x = torch.tensor([[1, 2], [3, 4], [5, 6]]) #(3 rows and 2 columns) <br/>&gt;&gt; y = x.view(6,-1) #y shape will be 6x1</span></pre><h1 id="e5b6" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">数学运算</h1><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="7fab" class="kv kw hu kr b fv kx ky l kz la">#Create two tensors <br/>&gt;&gt; x = torch.ones([3, 2]) <br/>&gt;&gt; y = torch.ones([3, 2]) #adding two tensors <br/>&gt;&gt; z = x + y #method 1 <br/>&gt;&gt; z = torch.add(x,y) #method 2 <br/>#subtracting two tensors <br/>&gt;&gt; z = x - y #method 1 <br/>&gt;&gt; torch.sub(x,y) #method 2</span></pre><h2 id="ea81" class="kv kw hu bd lu nf ng nh ly ni nj nk mc jj nl nm mg jn nn no mk jr np nq mo nr dt translated">就地操作</h2><p id="12d3" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">在 Pytorch 中，在张量上就地操作的所有操作都有一个<code class="eh nb nc nd kr b">_</code>后缀。比如<code class="eh nb nc nd kr b">add</code>是不在位版本，<code class="eh nb nc nd kr b">add_</code>是在位版本。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="2691" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; y.add_(x) #tensor y added with x and result will be stored in y</span></pre><h1 id="e513" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">Pytorch 到 Numpy 桥</h1><p id="82c1" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">将 Pytorch 张量转换成 numpy ndarray 有时非常有用。通过在张量上使用<code class="eh nb nc nd kr b">.numpy()</code>，我们可以很容易地将张量转换为 n 数组。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="3887" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; x = torch.linspace(0 , 1, steps = 5) #creating a tensor using linspace <br/>&gt;&gt; x_np = x.numpy() #convert tensor to numpy <br/>&gt;&gt; print(type(x), type(x_np)) <br/>&lt;class 'torch.Tensor'&gt; &lt;class 'numpy.ndarray'&gt;</span></pre><p id="75a4" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">要将 numpy ndarray 转换为 pytorch 张量，我们可以使用<code class="eh nb nc nd kr b">.from_numpy()</code>将 ndarray 转换为张量。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="d67b" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; a = np.random.randn(5) #generate a random numpy array <br/>&gt;&gt; a_pt = torch.from_numpy(a) #convert numpy array to a tensor <br/>&gt;&gt; print(type(a), type(a_pt)) <br/>&lt;class 'numpy.ndarray'&gt; &lt;class 'torch.Tensor'&gt;</span></pre><p id="5027" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">在转换过程中，Pytorch tensor 和 numpy ndarray 将共享它们的底层内存位置，更改其中一个将会更改另一个。</p><h1 id="93d3" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">CUDA 支持</h1><p id="157c" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">要检查机器上连接了多少支持 CUDA 的 GPU，您可以使用下面的代码片段。如果您在 Colab 中执行代码，您将得到 1，这意味着 Colab 虚拟机连接到一个 GPU。用于设置和运行 CUDA 操作。它会跟踪当前选择的 GPU。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="496d" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; print(torch.cuda.device_count()) <br/>1</span></pre><p id="54d5" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">如果您想获取连接到机器的 GPU 卡的名称:</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="495b" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; print(torch.cuda.get_device_name(0)) <br/>Tesla T4</span></pre><p id="9f0f" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">需要注意的重要一点是，我们可以将这个 CUDA 支持的 GPU 卡引用到一个变量，并使用这个变量进行任何 Pytorch 操作。您分配的所有 CUDA 张量都将在该设备上创建。选择的 GPU 设备可以用<code class="eh nb nc nd kr b"><a class="ae jw" href="https://pytorch.org/docs/stable/cuda.html#torch.cuda.device" rel="noopener ugc nofollow" target="_blank">torch.cuda.device</a></code>上下文管理器改变。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="fc83" class="kv kw hu kr b fv kx ky l kz la">#Assign cuda GPU located at location '0' to a variable <br/>&gt;&gt; cuda0 = torch.device('cuda:0') #Performing the addition on GPU <br/>&gt;&gt; a = torch.ones(3, 2, device=cuda0) #creating a tensor 'a' on GPU &gt;&gt; b = torch.ones(3, 2, device=cuda0) #creating a tensor 'b' on GPU &gt;&gt; c = a + b <br/>&gt;&gt; print(c) <br/>tensor([[2., 2.], [2., 2.], [2., 2.]], device='cuda:0')</span></pre><p id="993e" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">从上面的代码片段中可以看出，张量是在 GPU 上创建的，对这些张量的任何操作都将在 GPU 上完成。如果你想把结果转移到 CPU，你只需要做<code class="eh nb nc nd kr b">.cpu()</code></p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="1a9c" class="kv kw hu kr b fv kx ky l kz la">#moving the result to cpu <br/>&gt;&gt; c = c.cpu() <br/>&gt;&gt; print(c) <br/>tensor([[2., 2.], [2., 2.], [2., 2.]])</span></pre><h1 id="a407" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">自动微分</h1><p id="4a53" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">在本节中，我们将讨论 Pytorch 中称为自动微分或<code class="eh nb nc nd kr b">autograd</code>的重要包。<code class="eh nb nc nd kr b">autograd</code>包使我们能够对张量上的所有操作执行自动微分或自动梯度计算。它是一个由运行定义的框架，这意味着您的反向传播是由您的代码如何运行来定义的。</p><p id="6bf5" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">让我们通过一个简单的例子来看看如何进行自动微分。首先，我们创建一个参数设置为<code class="eh nb nc nd kr b">True</code>的张量，因为我们想要跟踪在这个张量上执行的所有操作。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="d339" class="kv kw hu kr b fv kx ky l kz la">#create a tensor with requires_grad = True <br/>&gt;&gt; x = torch.ones([3,2], requires_grad = True) <br/>&gt;&gt; print(x) <br/>tensor([[1., 1.], [1., 1.], [1., 1.]], requires_grad=True)</span></pre><p id="2a2e" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">执行简单的张量加法运算。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="edd6" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; y = x + 5 #tensor addition <br/>&gt;&gt; print(y) #check the result <br/>tensor([[6., 6.], [6., 6.], [6., 6.]], grad_fn=&lt;AddBackward0&gt;)</span></pre><p id="eef1" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">因为<code class="eh nb nc nd kr b">y</code>是在<code class="eh nb nc nd kr b">x</code>上操作的结果，所以它有一个<code class="eh nb nc nd kr b">grad_fn</code>。对<code class="eh nb nc nd kr b">y</code>执行更多操作，创建一个新张量<code class="eh nb nc nd kr b">z</code>。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="ff8c" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; z = y*y + 1 <br/>&gt;&gt; print(z) <br/>tensor([[37., 37.], [37., 37.], [37., 37.]], grad_fn=&lt;AddBackward0&gt;) &gt;&gt; t = torch.sum(z) #adding all the values in z <br/>&gt;&gt; print(t) <br/>tensor(222., grad_fn=&lt;SumBackward0&gt;)</span></pre><h2 id="77c7" class="kv kw hu bd lu nf ng nh ly ni nj nk mc jj nl nm mg jn nn no mk jr np nq mo nr dt translated">反向传播</h2><p id="2c06" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">要执行反向传播，只需调用<code class="eh nb nc nd kr b">t.backward()</code></p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="635b" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; t.backward() <br/>#peform backpropagation but pytorch will not print any output.</span></pre><p id="a382" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">打印渐变<code class="eh nb nc nd kr b">d(t)/dx</code>。</p><pre class="km kn ko kp fq kq kr ks kt aw ku dt"><span id="b3b0" class="kv kw hu kr b fv kx ky l kz la">&gt;&gt; print(x.grad) <br/>tensor([[12., 12.], [12., 12.], [12., 12.]])</span></pre><p id="e242" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><code class="eh nb nc nd kr b">x.grad</code>会给出<code class="eh nb nc nd kr b">t</code>相对于<code class="eh nb nc nd kr b">x</code>的偏导数。如果你能理解我们如何得到一个所有值都等于 12 的张量，那么你就理解了自动微分。如果不是，不用担心，继续，当我们执行<code class="eh nb nc nd kr b">t.backward()</code>时，我们正在计算<code class="eh nb nc nd kr b">t</code>相对于<code class="eh nb nc nd kr b">x</code>的偏导数。记住<code class="eh nb nc nd kr b">t</code>是<code class="eh nb nc nd kr b">z</code>的函数，而 T7 又是<code class="eh nb nc nd kr b">x</code>的函数。</p><blockquote class="ns"><p id="3f2a" class="nt nu hu bd nv nw nx ny nz oa ob jv ek translated"><strong class="ak"> d(t)/dx = 2y * 1，x = 1，y = 6，其中 y = x + 5 </strong></p></blockquote><figure class="od oe of og oh iv fe ff paragraph-image"><div role="button" tabindex="0" class="oi oj di ok bf ol"><div class="fe ff oc"><img src="../Images/18beedbb2bd622d134997506bf76e5d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZD40xRP125iD4k9yjV4dpw.png"/></div></div></figure><p id="106b" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">需要注意的重要一点是，导数的值是在我们初始化张量<code class="eh nb nc nd kr b">x</code>的时候计算的。因为我们将<code class="eh nb nc nd kr b">x</code>初始化为等于 1 的值，所以我们得到一个所有值都等于 12 的输出张量。</p><p id="6e15" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">本文中讨论的全部代码都存在于 Kaggle 内核中。随意叉或者下载。<strong class="ja hv">最棒的是，你可以直接在 Kaggle 内核中运行代码，无需担心安装包</strong>。</p><div class="lb lc fm fo ld le"><a href="https://www.kaggle.com/niranjankumarc/gettingstartedwithpytorch-gpu" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab ej"><div class="lg ab lh cl cj li"><h2 class="bd hv fv z el lj eo ep lk er et ht dt translated">gettingstartedwithpythorch _ GPU</h2><div class="ll l"><h3 class="bd b fv z el lj eo ep lk er et ek translated">使用来自非数据源的数据</h3></div><div class="lm l"><p class="bd b gc z el lj eo ep lk er et ek translated">www.kaggle.com</p></div></div><div class="ln l"><div class="om l lp lq lr ln ls iw le"/></div></div></a></div><p id="fb62" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">如果 Colab 是你的 jam，点击<a class="ae jw" href="https://colab.research.google.com/github/Niranjankumar-c/DeepLearning-PadhAI/blob/master/DeepLearning_Materials/2_GettingStarted_With_Pytorch/PytorchIntro.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>直接执行代码，弄脏你的手。</p><div class="lb lc fm fo ld le"><a href="https://github.com/Niranjankumar-c/DeepLearning-PadhAI/tree/master/DeepLearning_Materials/2_GettingStarted_With_Pytorch" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab ej"><div class="lg ab lh cl cj li"><h2 class="bd hv fv z el lj eo ep lk er et ht dt translated">niranjankumar-c/deep learning-PadhAI</h2><div class="ll l"><h3 class="bd b fv z el lj eo ep lk er et ek translated">来自 pad hai-Niranjankumar-c/deep learning-pad hai 的深度学习课程相关的所有代码文件</h3></div><div class="lm l"><p class="bd b gc z el lj eo ep lk er et ek translated">github.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls iw le"/></div></div></a></div><h1 id="bb49" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">结论</h1><p id="6795" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">在这篇文章中，我们简要地看了 Pytorch &amp; Google Colab，我们也看到了如何在 Colab 中启用 GPU 硬件加速器。然后，我们看到了如何在 Pytorch 中创建张量，并利用 CUDA 支持的 GPU 对这些张量执行一些基本操作。之后，我们讨论了 Pytorch <code class="eh nb nc nd kr b">autograd</code>包，它通过一个简单的例子给了我们在张量上执行自动梯度计算的能力。如果你在执行上述代码时有任何问题或疑问，欢迎在下面的评论区提问，或者在引用这篇文章的<a class="ae jw" href="https://linkedin.com/in/niranjankumar-c/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>给我发消息。</p><h1 id="ae45" class="lt kw hu bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp dt translated">了解更多信息</h1><p id="799d" class="pw-post-body-paragraph iy iz hu ja b jb mq jd je jf mr jh ji jj ms jl jm jn mt jp jq jr mu jt ju jv hn dt translated">如果你想学习更多的数据科学，机器学习。查看来自<a class="ae jw" href="https://courses.starttechacademy.com/full-site-access/?coupon=NKSTACAD" rel="noopener ugc nofollow" target="_blank"> Starttechacademy </a>的 Abhishek 和 Pukhraj 的<a class="ae jw" href="https://courses.starttechacademy.com/full-site-access/?coupon=NKSTACAD" rel="noopener ugc nofollow" target="_blank">机器学习基础知识</a>和<a class="ae jw" href="https://courses.starttechacademy.com/full-site-access/?coupon=NKSTACAD" rel="noopener ugc nofollow" target="_blank">高级机器学习</a>。这些课程的一个优点是它们同时用 Python 和 R 语言授课，所以这是你的选择。</p></div><div class="ab cl on oo hc op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="hn ho hp hq hr"><p id="d960" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><em class="jx">推荐阅读</em></p><div class="lb lc fm fo ld le"><a rel="noopener follow" target="_blank" href="/datadriveninvestor/deep-learning-best-practices-activation-functions-weight-initialization-methods-part-1-c235ff976ed"><div class="lf ab ej"><div class="lg ab lh cl cj li"><h2 class="bd hv fv z el lj eo ep lk er et ht dt translated">深度学习最佳实践:激活函数和权重初始化方法—第 1 部分</h2><div class="ll l"><h3 class="bd b fv z el lj eo ep lk er et ek translated">最佳激活函数和权重初始化方法可提高精确度</h3></div><div class="lm l"><p class="bd b gc z el lj eo ep lk er et ek translated">medium.com</p></div></div><div class="ln l"><div class="ou l lp lq lr ln ls iw le"/></div></div></a></div><div class="lb lc fm fo ld le"><a href="https://hackernoon.com/demystifying-different-variants-of-gradient-descent-optimization-algorithm-19ae9ba2e9bc" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab ej"><div class="lg ab lh cl cj li"><h2 class="bd hv fv z el lj eo ep lk er et ht dt translated">揭秘梯度下降优化算法的不同变体</h2><div class="ll l"><h3 class="bd b fv z el lj eo ep lk er et ek translated">了解对梯度下降的不同改进，并使用 2D 等高线图比较它们的更新规则。</h3></div><div class="lm l"><p class="bd b gc z el lj eo ep lk er et ek translated">hackernoon.com</p></div></div><div class="ln l"><div class="ov l lp lq lr ln ls iw le"/></div></div></a></div><p id="c2d4" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">在我的下一篇文章中，我们将讨论如何使用 Pytorch (nn)实现前馈神经网络。功能性，nn。参数)。所以确保你在媒体上跟踪我，以便在它下降时得到通知。</p><p id="28e0" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">直到那时和平:)</p><p id="55cb" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated">NK。</p></div><div class="ab cl on oo hc op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="hn ho hp hq hr"><p id="3b33" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><strong class="ja hv">作者简介</strong></p><p id="2602" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><a class="ow ox gr" href="https://medium.com/u/3e4fb2985698?source=post_page-----61a5c70b86a--------------------------------" rel="noopener" target="_blank"> Niranjan Kumar </a>是汇丰银行分析部门的零售风险分析师实习生。他对深度学习和人工智能充满热情。他是<a class="ae jw" rel="noopener" href="/tag/artificial-intelligence/top-writers">人工智能</a>中<a class="ow ox gr" href="https://medium.com/u/504c7870fdb6?source=post_page-----61a5c70b86a--------------------------------" rel="noopener" target="_blank">媒体</a>的顶尖作家之一。你可以在这里找到 Niranjan 的所有博客。你可以在 LinkedIn<a class="ae jw" href="https://www.linkedin.com/in/niranjankumar-c/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>、<a class="ae jw" href="https://twitter.com/Nkumar_283" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae jw" href="https://github.com/Niranjankumar-c" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上与 Niranjan 联系，了解他的最新博客文章。</p><p id="081f" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><strong class="ja hv">免责声明</strong> —这篇文章中可能有一些相关资源的附属链接。你可以以尽可能低的价格购买捆绑包。如果你购买这门课程，我会收到一小笔佣金。</p></div><div class="ab cl on oo hc op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="hn ho hp hq hr"><p id="e4b7" class="pw-post-body-paragraph iy iz hu ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv hn dt translated"><em class="jx">原载于 2019 年 6 月 9 日</em><a class="ae jw" href="https://www.marktechpost.com/2019/06/09/getting-started-with-pytorch-in-google-collab-with-free-gpu/" rel="noopener ugc nofollow" target="_blank"><em class="jx">【https://www.marktechpost.com】</em></a><em class="jx">。</em></p></div></div>    
</body>
</html>