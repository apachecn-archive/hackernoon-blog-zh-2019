<html>
<head>
<title>ML MODEL TO DETECT THE BIGGEST OBJECT IN AN IMAGE — PART 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">检测图像中最大物体的 ML 模型——第 1 部分</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31#2019-02-12">https://medium.com/hackernoon/single-object-detection-e65a537a1c31#2019-02-12</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="1d27" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">1 -围绕图像中最大的对象绘制边界框。这是为了准备好图像数据进行分析。</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/eac0d69fa13c606cb48512dcc9ae954c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a9eJ9fZcRunVZx2i670PHQ.jpeg"/></div></div></figure><p id="79e7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">欢迎来到 fast.ai 的第 2 部分，在这里我们将处理<strong class="jx hv">单个物体检测。</strong>在我们开始之前，我要感谢<a class="ae kr" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank"><strong class="jx hv"/></a>和<a class="ae kr" href="https://twitter.com/math_rachel" rel="noopener ugc nofollow" target="_blank"> <strong class="jx hv">瑞秋·托马斯</strong> </a>为 AI 民主化所做的努力。</p><p id="0404" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">本部分假设您已经很好地理解了第 1 部分。以下是链接，请按以下顺序随意探索本系列的第一部分。</p><ol class=""><li id="4bf2" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d" rel="noopener" target="_blank">狗 Vs 猫图像分类</a></li><li id="1580" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60" rel="noopener" target="_blank">犬种图像分类</a></li><li id="fba9" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889" rel="noopener" target="_blank">多标签图像分类</a></li><li id="8802" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1" rel="noopener" target="_blank">使用神经网络的时间序列分析</a></li><li id="6d6d" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">对 IMDB 电影数据集的 NLP 情感分析</a></li><li id="1021" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269" rel="noopener" target="_blank">电影推荐系统基础</a></li><li id="1a4e" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a" rel="noopener" target="_blank">从零开始协同过滤</a></li><li id="7c39" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://towardsdatascience.com/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36" rel="noopener" target="_blank">使用神经网络的协同过滤</a></li><li id="aea4" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="c436" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="fab4" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" rel="noopener" href="/hackernoon/single-object-detection-e65a537a1c31"> ML 模型检测图像中最大的物体 Part-1 </a></li><li id="044a" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><a class="ae kr" rel="noopener" href="/hackernoon/single-object-detection-part-2-2deafc911ce7">检测图像中最大物体的 ML 模型 Part-2 </a></li></ol><p id="488f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这篇博文分为两部分。</p><ul class=""><li id="6126" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">第一部分从熟悉对象检测到对象定位的数据格式开始。</li><li id="85ca" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">第二部分处理图像中的最大项目分类器。</li></ul><p id="fa6c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们将使用的数据集是 PASCAL VOC (2007 版)。</p><p id="b479" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们用编码部分来弄脏我们的手。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lh li l"/></div></figure><p id="28b9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">与所有机器学习项目一样，有三件事需要关注</p><ol class=""><li id="45aa" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq kx ky kz la dt translated"><em class="lj">提供数据。</em></li><li id="28df" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><em class="lj">挑选一些合适的架构。</em></li><li id="fdc1" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq kx ky kz la dt translated"><em class="lj">选择一个损失函数。</em></li></ol><p id="75f4" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">第 1 步</strong>将集中于以适当的形式获得数据，以便在此基础上进行分析。</p><p id="cd98" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">步骤 1:- </strong>它包括对每幅图像中最大的物体进行分类和定位。该步骤包括:-</p><ul class=""><li id="b30d" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">对对象进行分类。</li><li id="b35b" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">定位物体。</li><li id="3670" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">标记定位的对象。</li><li id="93a0" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">然后我们会尝试一次完成以上三个步骤。</li></ul></div><div class="ab cl lk ll hc lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hn ho hp hq hr"><p id="3e1c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv"> <em class="lj"> 1.1。安装软件包</em>和</strong></p><p id="cf30" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们使用如下所示的命令安装软件包并下载数据。</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="1ecf" class="lw lx hu ls b fv ly lz l ma mb"># Install the packages<br/># !pip install <a class="ae kr" href="https://github.com/fastai/fastai/archive/master.zip" rel="noopener ugc nofollow" target="_blank">https://github.com/fastai/fastai/archive/master.zip</a><br/>!pip install fastai==0.7.0<br/>!pip install torchtext==0.2.3<br/>!pip install opencv-python<br/>!apt update &amp;&amp; apt install -y libsm6 libxext6<br/>!pip3 install <a class="ae kr" href="http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl" rel="noopener ugc nofollow" target="_blank">http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl</a> <br/>!pip3 install torchvision</span><span id="866a" class="lw lx hu ls b fv mc lz l ma mb"># Download the Data to the required folder<br/>!mkdir data<br/>!wget <a class="ae kr" href="http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar" rel="noopener ugc nofollow" target="_blank">http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar</a> -P data/<br/>!wget <a class="ae kr" href="https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip</a> -P data/<br/>!tar -xf data/VOCtrainval_06-Nov-2007.tar -C data/<br/>!unzip data/PASCAL_VOC.zip -d data/<br/>!rm -rf data/PASCAL_VOC.zip data/VOCtrainval_06-Nov-2007.tar</span><span id="a3f8" class="lw lx hu ls b fv mc lz l ma mb">%matplotlib inline<br/>%reload_ext autoreload<br/>%autoreload 2</span><span id="65b3" class="lw lx hu ls b fv mc lz l ma mb">!pip install Pillow</span><span id="e820" class="lw lx hu ls b fv mc lz l ma mb">from fastai.conv_learner import *<br/>from fastai.dataset import *</span><span id="0f12" class="lw lx hu ls b fv mc lz l ma mb">from pathlib import Path<br/>import json<br/>import PIL<br/>from matplotlib import patches, patheffects<br/></span></pre><p id="fc3d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们检查一下我们的数据中有什么。我们将使用 python 3 标准库<code class="eh md me mf ls b">pathlib</code>进行路径和文件访问。</p><p id="0a88" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv"> <em class="lj"> 1.2。使用</em> </strong> <code class="eh md me mf ls b"><strong class="jx hv"><em class="lj">Pathlib </em></strong></code> <strong class="jx hv"> <em class="lj">对象了解你的数据。</em> </strong></p><p id="d6d3" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><code class="eh md me mf ls b">data</code>文件夹包含不同版本的<a class="ae kr" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/" rel="noopener ugc nofollow" target="_blank"> Pascal VOC </a>。</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="c673" class="lw lx hu ls b fv ly lz l ma mb">PATH = Path('data')<br/>list((PATH/'PASCAL_VOC').iterdir())<br/><strong class="ls hv"># iterdir() helps in iterating through the directory of PASCAL_VOC</strong></span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/c2b23bacb67d000da889bf50e5e7e760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*m2S1K8A23Ygy8qtmlQWcYg.png"/></div></figure><ul class=""><li id="c108" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><code class="eh md me mf ls b">PATH</code>是对目录或文件的面向对象的访问。它是 python 库<code class="eh md me mf ls b">pathlib</code>的一部分。要了解如何利用<code class="eh md me mf ls b">pathlib </code>功能，请做一个<code class="eh md me mf ls b">PATH.TAB</code>。</li><li id="def1" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">因为我们将只使用<code class="eh md me mf ls b">pascal_train2007.json</code>，所以让我们来看看这个文件的内容。</li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="9d19" class="lw lx hu ls b fv ly lz l ma mb">training_json = json.load((PATH/'PASCAL_VOC''pascal_train2007.json').open())<br/><strong class="ls hv"># training_json is a dictionary variable.<br/># As we can see Pathlib object has an open method .<br/># json.load is a part of Json (Java Script Object Notation) library that # we have imported earlier.</strong></span><span id="57e0" class="lw lx hu ls b fv mc lz l ma mb">training_json.keys()</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mh"><img src="../Images/a309edfb07f3aa277289977891b46ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*eZTrwqldgEXOxUvrnnyxBQ.png"/></div></figure><p id="6019" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">该文件包含<strong class="jx hv">图像、类型、注释和类别</strong>。为了使用<em class="lj">制表完成</em>，将其保存在适当的变量名中。</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="d02a" class="lw lx hu ls b fv ly lz l ma mb">IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']</span></pre><p id="d1ee" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们详细看看每一个都有哪些细节:-</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mi"><img src="../Images/839b4a6b066132984a59147a89e1c568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*cVUDtBaQRiwG8WPDvDenJg.png"/></div></div></figure><ul class=""><li id="61cb" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><strong class="jx hv">图像</strong>由<strong class="jx hv">图像名称、高度、宽度和图像 id </strong>组成。</li></ul><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mj"><img src="../Images/3970e866f710c7964f74100d6f4fab4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*6lehwfyWhdpQEf3SKLFYmw.png"/></div></figure><ul class=""><li id="9645" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><strong class="jx hv">注释</strong>由<strong class="jx hv">区域、bbox(边界框)、category_id </strong>组成(每个类别 id 都有一个与之相关的类或名称)。</li><li id="447d" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">一些图像具有多边形分割，即图像中对象周围的边界框。这对我们的讨论不重要。</li><li id="01aa" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">如果<strong class="jx hv">忽略标志=1(真)，忽略标志表示忽略图像中的对象。</strong></li></ul><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mk"><img src="../Images/db48ebb416112a47689266487ecfd1ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*1oZoDg35QM61ax8R8tIihg.png"/></div></figure><ul class=""><li id="df1f" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><strong class="jx hv">类别</strong>由类(名称)和与之相关的 ID 组成。</li></ul><p id="81d7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">为了更容易理解所有这些，让我们把重要的东西转换成字典理解和列表理解。</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="f61f" class="lw lx hu ls b fv ly lz l ma mb">FILE_NAME,ID,IMG_ID,CATEGORY_ID,BBOX = 'file_name','id','image_id','category_id','bbox'</span><span id="9097" class="lw lx hu ls b fv mc lz l ma mb">categories = {o[ID]:o['name'] for o in training_json[CATEGORIES]}<br/><strong class="ls hv"># The categories is a dictionary having  class and an ID associated with # it.</strong><br/><strong class="ls hv"># Lets check out all of the 20 categories using the command below</strong><br/>categories</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff ml"><img src="../Images/7930f2caf9402eabcfa57de91498bf6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*nfd1uYuR4IjZlEpQYjC8OQ.png"/></div></figure><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="ea9e" class="lw lx hu ls b fv ly lz l ma mb"><strong class="ls hv">training_filenames = {o[ID]:o[FILE_NAME] for o in training_json[IMAGES]}<br/>training_filenames</strong> <br/># contains the id and the filename of the images.</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff ml"><img src="../Images/99b9a7af9c191fc37779ca1e87016c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*Gth5pxQdRKjDfAPS2D0_kg.png"/></div></figure><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="0911" class="lw lx hu ls b fv ly lz l ma mb"><strong class="ls hv">training_ids = [o[ID] for o in training_json[IMAGES]]<br/>training_ids <br/></strong># This is a list comprehension.</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mm"><img src="../Images/0f1e5d40fd4773c77f8ec25a84703aa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:144/format:webp/1*pHk6wf76sGhFngkDUPSQjA.png"/></div></figure><p id="143e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，让我们看看存放所有图像的文件夹。</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="e49c" class="lw lx hu ls b fv ly lz l ma mb">list((PATH/'VOCdevkit'/'VOC2007').iterdir())<br/><strong class="ls hv"># The JPEGImages in red is the one with all the Images in it.</strong></span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/8a5bb555318bd3c9b43078d932c9050b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*GkhRzANWII2CWf89klWxVA.png"/></div></figure><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="5825" class="lw lx hu ls b fv ly lz l ma mb">JPEGS = 'VOCdevkit/VOC2007/JPEGImages'<br/>IMG_PATH = PATH/JPEGS<br/><strong class="ls hv"># Set the path of the Images as IMG_PATH<br/></strong>list(IMG_PATH.iterdir())[:5]<br/><strong class="ls hv"># Check out all the Images in the Path</strong></span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mo"><img src="../Images/586a3982d68127370cbf13df6a5845eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*ii7GxbfVhlm0a8SocFATUw.png"/></div></figure><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mp"><img src="../Images/9b79cb5956a535d4c3d342de8267ab25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*xKRi2yCNKC325hw9pjiIxQ.png"/></div></figure><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/44c5636c552a6aa4ebd8bb8b95584dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*5Fz2XS3sXAYx-ig-OHXsEg.png"/></div></figure><p id="2cc9" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">注意:-如上所示，每个图像都有一个与之相关联的唯一 id。</strong></p><p id="aaef" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv"> <em class="lj"> 1.3。边界框</em> </strong></p><p id="bdf5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这里的主要目的是将我们的边界框转换成合适的格式，以便用于绘图。边界框坐标出现在注释中。</p><blockquote class="mr ms mt"><p id="8402" class="jv jw lj jx b jy jz iv ka kb kc iy kd mu kf kg kh mv kj kk kl mw kn ko kp kq hn dt translated">边界框是图像中对象周围的框。</p></blockquote><p id="94a0" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">早先边界框坐标表示(列，行，高度，宽度)。看看下面的图片。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/7a4645a9dcd1d7fdf930624b85753ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*SX82ACV3k9R_TWPSEoCAnQ.png"/></div></figure><ul class=""><li id="5814" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">通过<strong class="jx hv"> hw_bb() </strong>函数将坐标转换为 height_width 到 bounding_box，得到左上角和右下角的坐标，并以(行和列)的形式表示。</li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="50c8" class="lw lx hu ls b fv ly lz l ma mb"><strong class="ls hv">def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])</strong></span></pre><ul class=""><li id="c540" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">现在，我们将<strong class="jx hv">创建一个字典，该字典将图像 id 作为<em class="lj">键</em>，其边界框坐标和类别 id 作为<em class="lj">值</em> </strong>。</li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="4c04" class="lw lx hu ls b fv ly lz l ma mb"><strong class="ls hv"># Python's defaultdict is useful any time you want to have a default     # dictionary entry for new keys. If you try and access a key that doesn’t # exist, it magically makes itself exist and <br/># it sets itself equal to the return value of the function you specify   # (in this case lambda:[]).</strong><br/>training_annotations = collections.defaultdict(lambda:[])<br/>for o in training_json[ANNOTATIONS]:<br/>    if not o['ignore']:<br/>        bb = o[BBOX]<br/>        bb = hw_bb(bb)<br/>        training_annotations[o[IMG_ID]].append((bb,o[CATEGORY_ID]))</span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff my"><img src="../Images/af7eb1987f6039a837aeb57ebc3f29eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*N5-5liWfu5tWDw4iNZHBqg.png"/></div></figure><ul class=""><li id="efb0" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">在上面的代码块中，我们检查了所有的注释，并考虑了那些没有说 ignore 的注释。之后，我们将它添加到一个<strong class="jx hv">字典中，字典中的值是边界框(bbox)和类别 id(class ),对应的图片 id 是关键字。</strong></li><li id="7e62" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">一个问题是，如果还不存在字典条目，那么我们不能向它附加任何 bbox 和 class 列表。为了解决这个问题，我们使用了 Python 的 defaultdict，代码如下。</li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="bc1f" class="lw lx hu ls b fv ly lz l ma mb">training_annotations = collections.defaultdict(lambda:[])</span></pre><ul class=""><li id="9d81" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">它是一个字典，但是如果我们正在访问一个不存在的键，那么<code class="eh md me mf ls b">defaultdict</code>会神奇地创建一个字典，并设置它自己等于函数返回的值。在这种情况下，它是一个空列表。因此，每次我们访问训练注释中的键时，如果它不存在，<code class="eh md me mf ls b">defaultdict</code>会创建一个新的空列表，我们可以向它追加内容。</li></ul><p id="b977" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">有用图像相关信息的汇总</strong></p><p id="8d79" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们深入了解特定图像的注释细节。正如我们在下面的快照中看到的。</p><ul class=""><li id="0caa" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">我们拍一张特定的照片。</li><li id="af85" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">获取其注释，即 BBox 中对象的<strong class="jx hv">边界框和类</strong>。它表示类中存在哪些对象以及这些对象的坐标。</li><li id="2845" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">在下面的例子中检查这个类指的是什么。在这种情况下，类别是汽车。</li></ul><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/7e8f7a479049249915e59f6bc9b43473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*s5jjuRQDXf5YgdhkF519vQ.png"/></div></figure><p id="b040" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">有些库采用 VOC 格式的边界框，因此<strong class="jx hv"> <em class="lj"> bb_hw() </em> </strong>函数有助于将尺寸重置为原始格式:</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="e4ea" class="lw lx hu ls b fv ly lz l ma mb">bb_voc = [155, 96, 196, 174]<br/>bb_fastai = hw_bb(bb_voc) </span><span id="f558" class="lw lx hu ls b fv mc lz l ma mb"><strong class="ls hv"># We won't be using the below function for now .</strong><br/>def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])</span></pre></div><div class="ab cl lk ll hc lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hn ho hp hq hr"><p id="7386" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv">1.4<em class="lj">。围绕对象</em>绘制边界框</strong></p><p id="9c84" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，我们将重点放在创建一个图像周围的边界框。为此，我们将逐步或在单独的函数中创建图。每一步都有明确的目的来创造一个情节。让我们看看每一步的目的。发帖说我们会把重点放在流量上。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lh li l"/></div></figure><ul class=""><li id="dc01" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><strong class="jx hv">下面的代码用于获取轴，我们将在其上绘制图像。</strong></li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="75db" class="lw lx hu ls b fv ly lz l ma mb">def show_img(im, figsize=None, ax=None):<br/><strong class="ls hv"># The ax is used to pass in an axis object. </strong><br/>   if not ax: fig,ax = plt.subplots(figsize=figsize)<br/>   ax.imshow(im)<br/>   ax.get_xaxis().set_visible(False)<br/>   ax.get_yaxis().set_visible(False)<br/>   return ax</span></pre><ul class=""><li id="2113" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><strong class="jx hv">使用以下代码在图像中的对象周围绘制一个矩形。</strong></li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="6469" class="lw lx hu ls b fv ly lz l ma mb">def draw_rect(ax, b):<br/>    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))<br/>    draw_outline(patch, 4)</span><span id="7056" class="lw lx hu ls b fv mc lz l ma mb"><strong class="ls hv"># *b[-2:] in the argument list is the splat operator . It passes b[-2],b[-1] as parameters. Its a shortcut.</strong></span></pre><ul class=""><li id="db73" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><strong class="jx hv"/><code class="eh md me mf ls b"><strong class="jx hv">draw_outline()</strong></code><strong class="jx hv">用于使文本可见，不受背景影响。因此，这里我们使用黑色轮廓的白色文本，反之亦然。</strong></li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="da46" class="lw lx hu ls b fv ly lz l ma mb">def draw_outline(o, lw):<br/>    o.set_path_effects([patheffects.Stroke(<br/>        linewidth=lw, foreground='black'), patheffects.Normal()])</span><span id="c12a" class="lw lx hu ls b fv mc lz l ma mb"><strong class="ls hv"># foreground='black' means to create a black stroke around it.</strong></span></pre><ul class=""><li id="835e" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">在边框附近以文本的形式写下图像所属的类别。</li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="e10d" class="lw lx hu ls b fv ly lz l ma mb">def draw_text(ax, xy, txt, sz=14):<br/>    text = ax.text(*xy, txt,<br/>        verticalalignment='top', color='white', fontsize=sz, weight='bold')<br/>    draw_outline(text, 1)</span><span id="4f18" class="lw lx hu ls b fv mc lz l ma mb"><strong class="ls hv"># Add text and draw outline around it.</strong></span></pre><ul class=""><li id="b091" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated">下面是如何在图像中的物体周围创建一个边界框的流程。</li></ul><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="d02b" class="lw lx hu ls b fv ly lz l ma mb"><strong class="ls hv"># Step 1 :- Returns the axis the image is on by calling the function     # show_img().</strong><br/>ax = show_img(im)<br/><strong class="ls hv"># Step 2 :- Convert the bounding box coordinates into proper format by   # calling the function bb_hw().</strong><br/>b = bb_hw(im0_a[0])<br/><strong class="ls hv"># Step 3:- Draw a rectangle /Bounding box around the object by calling   # the function draw_rect().</strong><br/>draw_rect(ax, b)<br/><strong class="ls hv"># Step 4:- Draw the text near the top left corner b[:2]</strong> .<br/><strong class="ls hv"># And it contains two things , the bounding box  and the class ,<br/># im0_a[1] is the class and to get the text , pass it into               # categories[im0_a[1]]<br/># by calling the function draw_text().</strong><br/>draw_text(ax, b[:2], categories[im0_a[1]]) <br/></span></pre><p id="78a5" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们用如下所示的函数来总结流程步骤</p><pre class="jk jl jm jn fq lr ls lt lu aw lv dt"><span id="29bf" class="lw lx hu ls b fv ly lz l ma mb">def draw_im(im, ann):<br/>    ax = show_img(im, figsize=(16,8))<br/>    for b,c in ann:<strong class="ls hv"> # Destructure the annotations into bbox and class</strong><br/>        b = bb_hw(b)<strong class="ls hv"> # Convert it into appropriate coordinates</strong><br/>        draw_rect(ax, b)<strong class="ls hv"> # Draw rectangle bbox around it.</strong><br/>        draw_text(ax, b[:2], categories[c], sz=16) <br/><strong class="ls hv">        # Write some text around it</strong></span><span id="9d5a" class="lw lx hu ls b fv mc lz l ma mb">def draw_idx(i):<br/>    im_a = training_annotations[i]<strong class="ls hv"> # Grab the annotations with the help of the image id.</strong><br/>    im = open_image(IMG_PATH/training_filenames[i]) <strong class="ls hv"># Open that Image</strong><br/>    print(im.shape) <strong class="ls hv"># Print its shape</strong><br/>    draw_im(im, im_a)<strong class="ls hv"> # Call the draw and print its text</strong></span><span id="29aa" class="lw lx hu ls b fv mc lz l ma mb">draw_idx(17) <br/><strong class="ls hv"># Draw an image of a particular index.</strong></span></pre><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff na"><img src="../Images/f575ceb33c97c56244d1d76ad2ab7644.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*F3HM-YHncHs5QWQr55zg7w.png"/></div></figure><p id="fb69" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">让我们在这里详细总结一下流程:-</p><ul class=""><li id="e959" class="ks kt hu jx b jy jz kb kc ke ku ki kv km kw kq lg ky kz la dt translated"><code class="eh md me mf ls b"><strong class="jx hv">draw_idx(17)</strong></code> <strong class="jx hv"> </strong>调用<code class="eh md me mf ls b"><strong class="jx hv">def draw_idx(i)</strong>:</code>函数，该函数获取已传递给该函数的 17 号图像的注释。</li><li id="1c25" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated"><strong class="jx hv">注意:-对象的注释是该图像中对象的边界框以及该对象所属的类。</strong></li><li id="d211" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">在<code class="eh md me mf ls b"><strong class="jx hv">def draw_idx(i) </strong></code>函数中，获取注释后，我们打开图像，打印出它的形状。</li><li id="9932" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">然后我们用图像及其标注调用<code class="eh md me mf ls b"><strong class="jx hv">def draw_im(im, im_a)</strong></code> <strong class="jx hv"> </strong>函数。</li><li id="d9cd" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">在这个<code class="eh md me mf ls b"><strong class="jx hv">def draw_im(im, im_a) </strong></code>函数中，首先我们打印图像。</li><li id="1cd1" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">然后在 for 循环中，我们遍历每个注释，将边界框和类分别存储在 b 和 c 中。这也称为赋值的析构。</li><li id="8ffd" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated">使用此<code class="eh md me mf ls b"><strong class="jx hv">bb_hw(b)</strong></code> <strong class="jx hv"> </strong>功能将边界框坐标转换成合适的坐标，即左上角和右下角坐标。</li><li id="e25c" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated"><code class="eh md me mf ls b"><strong class="jx hv">draw_rect(ax, b) </strong></code> <strong class="jx hv"> :- </strong>使用这个函数，我们在边界框周围画一个矩形。</li><li id="76c9" class="ks kt hu jx b jy lb kb lc ke ld ki le km lf kq lg ky kz la dt translated"><code class="eh md me mf ls b"><strong class="jx hv">draw_text(ax, b[:2], categories[c], sz=16)</strong></code> <strong class="jx hv"> :- </strong>使用这个功能，我们正在写一些文字。</li></ul><p id="7554" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">这就是我们在图像中定位物体的方式。下一步是对图像中最大的项目进行分类。我们将在<a class="ae kr" href="https://medium.com/p/2deafc911ce7/edit" rel="noopener">下一篇博文</a>中详细讨论下一步。</p><p id="910d" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">大声疾呼<a class="ae kr" rel="noopener" href="/@anweshsatapathy"> Anwesh Satapathy </a>和<a class="ae kr" href="https://twitter.com/shar1pius" rel="noopener ugc nofollow" target="_blank"> Sharwon Pius </a>用简单的方式说明了这个问题。请查看他的<a class="ae kr" href="https://github.com/AI6-Bangalore-Chapter/2018-cycle-2/tree/master/Sessions/Session_12" rel="noopener ugc nofollow" target="_blank"> github Repo </a>和单个对象检测的简化路线图。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="nb li l"/></div></figure><p id="a59e" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">如果您有任何疑问，请随时在 twitter 上提出<a class="ae kr" href="https://twitter.com/ashiskumarpanda" rel="noopener ugc nofollow" target="_blank"> @ashiskumarpanda </a>或在 fastai 论坛上查看。</p><p id="5c11" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated"><strong class="jx hv"> <em class="lj">如果看到了👏 👏按钮，如果你喜欢这篇文章，请随意做你需要做的😄😄😄😄😄。</em> </strong></p><p id="0d51" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">被杰瑞米·霍华德赏识的感觉真的很好。看看他对我的 Fast.ai 第一部分博客的看法。一定要看一看。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="nc li l"/></div></figure><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="nd li l"/></div></figure></div></div>    
</body>
</html>