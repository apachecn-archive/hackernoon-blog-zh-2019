<html>
<head>
<title>12 Key Lessons from ML researchers and practitioners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">来自ML研究者和从业者的12条重要经验</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/12-key-lessons-from-ml-researchers-and-practitioners-3d4818a2feff?source=collection_archive---------4-----------------------#2019-04-18">https://medium.com/hackernoon/12-key-lessons-from-ml-researchers-and-practitioners-3d4818a2feff?source=collection_archive---------4-----------------------#2019-04-18</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><figure class="ht hu fm fo hv hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff hs"><img src="../Images/8a0b540afdcd95becfe48c193a39a6be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6HZ70NwmOsMUC6GF"/></div></div></figure><div class=""/><p id="5de3" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">机器学习算法有望通过从数据中学习来找出如何执行重要任务，即在没有明确告诉做什么的情况下从例子中归纳。这意味着数据量越大，这些算法能处理的棘手问题就越多。然而，<strong class="je ig"> <em class="ka">开发成功的机器学习应用</em> </strong>需要相当多的在教科书或机器学习入门课程中很难找到的“黑艺术”。</p><p id="5219" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我最近偶然发现了<a class="ae kb" href="https://homes.cs.washington.edu/~pedrod/" rel="noopener ugc nofollow" target="_blank">教授Pedro Domingos </a>的一篇伟大的研究论文，该论文汇集了机器学习研究人员和实践者的经验教训。在这篇文章中，我将和你一起浏览这些课程。</p><p id="f921" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">准备了解:<strong class="je ig">要避免的陷阱、要关注的重要问题以及一些常见问题的答案</strong>。</p><h1 id="f5bb" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">1.学习=表示+评估+优化</h1><p id="0c24" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">你有一个应用程序，你认为机器学习可能很适合它。现在，一旦进入机器学习的世界，就有成吨的学习算法可用，每年还有数百种算法发表。用哪个？</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff lf"><img src="../Images/1f245aea986989bc024a8bed5846d1dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*mjlk8u_RJMXBdmb7"/></div></figure><p id="ee58" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在这个巨大的空间中不迷失的关键是理解所有学习算法的配方由三个核心成分组成:</p><ul class=""><li id="a1ae" class="lk ll if je b jf jg jj jk jn lm jr ln jv lo jz lp lq lr ls dt translated"><strong class="je ig">表示:</strong>输入数据，即要使用的特征，学习器和分类器必须用计算机能理解的语言来表示。学习者可能学习的分类器集合被称为学习者的<em class="ka">假设空间</em>。如果分类器不在假设空间中，它就不能被学习。</li></ul><p id="2298" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> <em class="ka">澄清说明</em> </strong> <em class="ka">:我们所说的</em> <strong class="je ig"> <em class="ka">量词vs学习者</em> </strong> <em class="ka">是什么意思？假设你有训练数据，从这些数据中使用一个程序来构建另一个程序(一个模型),例如决策树。学习者将是从输入数据构建决策树模型的程序，而决策树模型将是分类器(能够为输入数据的每个实例提供预测输出的东西)。</em></p><ul class=""><li id="8e3a" class="lk ll if je b jf jg jj jk jn lm jr ln jv lo jz lp lq lr ls dt translated"><strong class="je ig">评估:</strong>需要一个评估函数来区分好的分类器和坏的分类器。算法内部使用的评估函数可以不同于我们希望分类器优化的外部评估度量(为了便于优化，以及由于后面讨论的问题)</li><li id="9d28" class="lk ll if je b jf lt jj lu jn lv jr lw jv lx jz lp lq lr ls dt translated"><strong class="je ig">优化:</strong>最后，我们需要一种方法在分类器中进行搜索，以便我们可以挑选出最好的一个。优化技术的选择是学习者效率的关键。开始使用现成的优化器是很常见的。如果需要，您可以在以后用定制设计的替换它们。</li></ul><p id="4bc0" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下表显示了这三个组件的一些常见示例。</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff ly"><img src="../Images/669b102236ca4fcaeed5640a68b22d2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8HrOssujdANi_I2B"/></div></div></figure><h1 id="f055" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">2.重要的是概括</h1><p id="9cfe" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">机器学习的根本目标是<strong class="je ig"> <em class="ka">在训练集</em> </strong>中的例子之外进行泛化。因为，无论我们有多少数据，我们都不太可能在测试时再次看到那些精确的例子。在训练中做得好很容易。新手最容易犯的错误就是在训练数据上测试，产生成功的错觉。如果选择的分类器然后在新的数据上被测试，它通常不比随机猜测好。所以，<strong class="je ig"> <em class="ka">从一开始就把一部分数据放到一边</em> </strong>，只在最后用它来测试你选择的分类器，然后在整个数据上学习你最终的分类器。</p><p id="503a" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当然，隐瞒数据会减少可用于培训的数量。这可以通过进行<strong class="je ig"> <em class="ka">交叉验证</em> </strong>来缓解:将你的训练数据随机分成(比方说)十个子集，保留每个子集，同时对其余的子集进行训练，对每个学习过的分类器在其没有看到的例子上进行测试，并对结果进行平均，以查看特定参数设置的效果如何。</p><h1 id="9198" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">3.仅有数据是不够的</h1><p id="ad39" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">当目标是一般化时，我们会遇到另一个主要后果:不管你有多少数据，光有数据是不够的。假设我们想从一百万个例子中学习一个包含100个变量的布尔函数(是/否分类)。这意味着两个⁰⁰-10⁶的例子，它们的类别你不知道。在手头没有更多信息的情况下，这怎么能比掷硬币更好呢？</p><p id="9639" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">听起来我们被困住了，对吗？幸运的是，我们想要在现实世界中学习的函数并不是从所有数学上可能的函数集中统一得出的！事实上，非常一般的假设——就像类似的例子有类似的类——是机器学习如此成功的一个重要原因。</p><p id="c8f1" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这意味着<strong class="je ig"> <em class="ka">领域知识和对数据的理解</em> </strong>对于做出正确的假设非常重要。学习中对知识的需求不应令人惊讶。机器学习不是魔术；它不可能无中生有。它所做的是用更少的资源获得更多。像所有工程一样，编程是一项繁重的工作:我们必须从头开始构建一切。学习更像耕作，让大自然做大部分的工作。农民将种子和养分结合起来种植作物。学习者<strong class="je ig"> <em class="ka">将知识与数据</em> </strong>结合，成长程序。</p><h1 id="f5a4" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">4.过度拟合有很多面</h1><p id="089a" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">过拟合问题是机器学习的难题。当您的学习者输出一个对训练数据100%准确但对测试数据只有50%准确的分类器时，实际上它可以输出一个对两者都有75%准确的分类器，它已经过度拟合了。</p><p id="b26d" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">机器学习中的每个人都知道过度拟合，但它以许多形式出现，不会立即显而易见。理解过拟合的一种方法是将泛化误差分解为<strong class="je ig"> <em class="ka">偏差</em>和<em class="ka">方差</em> </strong> <em class="ka">。</em></p><p id="076a" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">偏见是一个学习者倾向于<strong class="je ig"> <em class="ka">持续地学习同样错误的东西</em> </strong>。方差是学习随机事物的<strong class="je ig"> <em class="ka">趋势</em> </strong>与真实信号无关。通过下图中的飞镖类比可以更好地理解这一点:</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff lz"><img src="../Images/734064f8cafe5ad944311aef12f87952.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/0*bmyQnMsph3Jn9-jU"/></div></figure><p id="d7c7" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">例如，线性学习者具有高偏差，因为当两个类之间的划分不是清晰的超平面时，学习者不能正确地归纳关系。决策树没有这个问题，因为它们的学习方法很灵活。但另一方面，它们可能会受到高方差的影响——在同一任务的不同训练数据集上学习的决策树往往非常不同，而事实上它们应该是相同的。</p><p id="52ee" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，如何处理过度拟合？</p><p id="1bae" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> <em class="ka">交叉验证</em> </strong>在这里可以派上用场，例如通过使用它来选择决策树的最佳大小来学习。然而，请注意，这里又有一个陷阱:如果我们使用它进行太多的参数选择，它本身可能会开始过拟合，我们又回到了同样的陷阱。</p><p id="618d" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">除了交叉验证之外，还有许多方法来对抗过度拟合。最流行的一种是在评估函数中增加一个<strong class="je ig"> <em class="ka">正则化</em> </strong>项。另一种选择是执行像卡方这样的统计显著性测试，以分析增加更多的复杂性是否对类别分布有任何影响。这里重要的一点是，没有特定的技术“解决”过拟合问题。例如，我们可以通过陷入相反的欠拟合误差(偏差)来避免过拟合(方差)。同时避免这两者需要学习一个完美的分类器，没有一种技术总是做得最好<em class="ka">(没有免费的午餐)</em>。</p><h1 id="77b4" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">5.直觉在高维空间失效</h1><p id="aa4b" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">过拟合之后，机器学习最大的问题就是<strong class="je ig"> <em class="ka">维数灾难</em> </strong> <em class="ka">。</em>这个表达式意味着，当输入是高维时，许多在低维中工作良好的算法变得难以处理。随着示例的<strong class="je ig"> <em class="ka">维度(即特征的数量)</em> </strong>的增长，正确概化变得更加困难，因为固定大小的训练集覆盖了输入空间的一小部分(可能的组合变得巨大)。但这正是机器学习既必要又困难的原因。正如你在下图中看到的，即使我们从一维过渡到三维，区分不同例子的工作似乎开始变得越来越难——在高维空间中，所有的例子看起来都一样。</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff ma"><img src="../Images/8b72bfe2949d2221f8956ace5b6d0673.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/0*_Q39inLqPdCgdzQl"/></div></figure><p id="d32f" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里的普遍问题是，我们来自三维世界的直觉在高维空间中让我们失望。例如，高维度橙子的大部分体积在果皮中，而不是果肉！</p><p id="2bd4" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">更令人难以置信的是:如果恒定数量的例子均匀分布在一个高维超立方体中，并且如果我们通过在一个超立方体中刻划它来近似一个超球体，那么在高维空间中，几乎所有超立方体的体积都在超球体之外。这是个坏消息。因为在机器学习中，一种类型的形状通常由另一种类型的形状来近似。</p><p id="a21b" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> <em class="ka">澄清说明</em> </strong> <em class="ka">:如果你被所有的“超立方体的炒作”搞糊涂了，超立方体里面的超球体，在二维和三维看起来是这样的:</em></p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff lf"><img src="../Images/083287516df55281712f544eb411af01.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*fNs6QpX1D_jJ4nAz"/></div></figure><p id="cc3e" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因此，正如你现在所理解的，在二维或三维空间中构建分类器很容易，但在高维空间中，很难理解正在发生的事情。这反过来又使得设计一个好的分类器变得困难。事实上，我们经常陷入这样一个陷阱，认为收集更多的特征没有坏处，因为在最坏的情况下，它们不会提供关于类的新信息。但事实上，它们的好处可能会被维数灾难盖过。</p><p id="c70a" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> <em class="ka">带走</em> </strong>:下次当你考虑添加更多功能时，一定要考虑到当你的维度变得太大时可能出现的潜在问题。</p><h1 id="d926" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">6.特征工程是关键</h1><p id="74f3" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">最后，<strong class="je ig"> <em class="ka">机器学习项目有的成功，有的失败。有什么区别？</em>轻松</strong>最重要的因素是<strong class="je ig">的<em class="ka">特性用到</em>的</strong>。如果你有许多独立的特性，并且每一个都和这个类有很好的关联，那么学习就很容易。另一方面，如果类是基于一个在使用之前需要以复杂的方式处理成分(特性)的配方，事情会变得更困难——特性工程基本上就是从现有的特性中创建新的输入特性。</p><p id="daa0" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">很多时候，原始数据甚至不是以可供学习的形式出现的。但是你可以从中构造出可以用于学习的特征。事实上，这通常是机器学习项目中大部分努力的方向。这通常也是最有趣的部分之一，直觉、创造力和“黑色艺术”与技术一样重要。</p><p id="4012" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">第一次接触机器学习的人通常会惊讶于在一个机器学习项目中实际花在机器学习上的时间是如此之少。但是，如果你考虑到收集数据、整合数据、清理数据和预处理数据是多么耗时，以及在功能设计中可以进行多少尝试和错误，这是有道理的。此外，<strong class="je ig"> <em class="ka">机器学习不是构建数据集和运行学习器的一次性过程</em> </strong>，而是运行学习器、分析结果、修改数据和/或学习器并重复的迭代过程。学习通常是最快的部分，但那是因为我们已经掌握得很好了！特征工程更难，因为它是特定领域的，而学习者可以是通用的。当然，机器学习的圣杯之一是自动化越来越多的特征工程过程。</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mb"><img src="../Images/bca8031f6731f9a8704b6b70c67145c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/0*fCYVsajl2cMoV-4Y"/></div></div></figure><h1 id="873b" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">7.更多的数据胜过更聪明的算法</h1><p id="511d" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">假设您已经构建了尽可能好的特征集，但是您得到的分类器仍然不够准确。你现在能做什么？主要有两个选择:<br/>设计一个更好的学习算法，或者收集更多的数据(更多的例子，可能还有更多的原始特征)。机器学习研究人员会努力改进设计，但在现实世界中，最快的成功之路往往是获得更多数据。<br/>根据经验，拥有大量数据的愚蠢算法胜过拥有少量数据的聪明算法。</p><p id="6abb" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在计算机科学中，通常两个主要的有限资源是时间和内存。在机器学习中，还有第三个:训练数据。在这三者中，目前主要的瓶颈通常是时间——有大量的数据可用，但没有足够的时间来处理这些数据，所以这些数据没有被使用。这意味着<strong class="je ig"> <em class="ka">实际上更简单的分类器</em> </strong>最终会到达终点，因为复杂的分类器需要太长的学习时间。</p><p id="03c7" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">使用更聪明的算法最终没有给出更好的结果的部分原因是因为在一天结束时，他们都在做同样的事情——所有的学习者本质上都是通过将附近的例子分组到同一个类中来工作的；关键的区别在于“附近”的含义当我们有非均匀分布的数据时，即使复杂的学习者可以产生非常不同的边界来分类结果，他们仍然<strong class="je ig"> <em class="ka">最终在重要区域</em> </strong>(具有大量训练示例的区域，因此也是大多数文本示例可能出现的区域)中做出相同的预测。正如你在下图中看到的，无论是一条奇特的曲线、一条直线还是一个阶梯式的边界，我们最终都会得到相同的预测:</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff mc"><img src="../Images/7342f7c2e2282cfd17f13530450083f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/0*AfKFMZfMklr-KX-R"/></div></figure><p id="1a6c" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">作为一个规则，<strong class="je ig"> <em class="ka">先尝试最简单的学习者</em> </strong>(比如先朴素贝叶斯后逻辑回归，先k近邻后支持向量机)。更复杂的学习者是诱人的，但他们通常更难使用，因为他们有更多的旋钮需要你去转动以获得好的结果，因为他们的内部更像是黑盒。</p><h1 id="fdc1" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">8.学习许多模型，而不仅仅是一个</h1><p id="7dfd" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">在机器学习的早期，人们努力尝试许多学习者的许多变化，仍然只选择最好的一个。但是后来研究人员注意到，如果我们不选择找到的最佳变体，而是组合许多变体，结果会更好——通常好得多——并且对用户来说没有额外的努力。创建这样的<em class="ka">模型</em> <strong class="je ig"> <em class="ka">集合</em> </strong>现在非常普遍:</p><ul class=""><li id="f96f" class="lk ll if je b jf jg jj jk jn lm jr ln jv lo jz lp lq lr ls dt translated">在称为<strong class="je ig"> <em class="ka">打包</em></strong><em class="ka"/>的最简单技术中，我们使用相同的算法，但在原始数据的不同子集上对其进行训练。最后，我们只是平均答案或通过某种投票机制将它们组合起来。</li><li id="b340" class="lk ll if je b jf lt jj lu jn lv jr lw jv lx jz lp lq lr ls dt translated">在<strong class="je ig"> <em class="ka">助推</em></strong><em class="ka"/>中，学习者被逐一按顺序训练。每一个后续的都将大部分注意力放在被前一个错误预测的数据点上。我们继续下去，直到我们对结果满意为止。</li><li id="f90a" class="lk ll if je b jf lt jj lu jn lv jr lw jv lx jz lp lq lr ls dt translated">在<strong class="je ig"> <em class="ka">堆叠</em></strong><em class="ka"/>中，不同独立分类器的输出成为新分类器的输入，新分类器给出最终预测。</li></ul><p id="fbec" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在网飞奖中，来自世界各地的团队竞相打造最佳视频推荐系统。随着比赛的进行，团队发现他们通过将他们的学习者与其他团队结合起来获得了最好的结果，并合并成越来越大的团队。冠军和亚军都是超过100名学习者的组合，将这两个组合结合起来进一步改善了结果。<strong class="je ig"> <em class="ka">在一起更好！</em>T3】</strong></p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff md"><img src="../Images/c8e2a4ec44f0976634499ec6d83097ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/0*vSPQ-H8WgcKDI05Y"/></div></figure><h1 id="8d2d" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">9.理论上的保证并不像它们看起来那样</h1><p id="1e1d" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">机器学习论文充满了理论保障。我们应该如何看待这些保证？归纳法在传统上与演绎法形成对比:在演绎法中，你可以保证结论是正确的；在入职培训中，所有的赌注都是无效的。最近几十年的主要发展之一是认识到，事实上，如果我们愿意接受概率保证，我们可以对归纳的结果有保证。</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff me"><img src="../Images/6b11e3b3a254b7b043a8f5ec6411e537.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/0*usElYHEiBltAjSnE"/></div></figure><p id="a07f" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">例如，我们可以保证，如果给定足够大的训练集，我们的学习者将很有可能要么返回一个概括得很好的假设，要么无法找到一致的假设。</p><p id="85a0" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">另一种常见的理论保证是，给定无限数据，保证学习者输出正确的分类器。在实践中，由于我们之前讨论的偏差-方差权衡，如果给定无限数据，学习者A比学习者B好，则B通常比给定有限数据好。</p><p id="6ba0" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">理论保证在机器学习中的主要作用<strong class="je ig"> <em class="ka">不是作为实际决策的标准</em> </strong>而是作为理解算法设计的来源。</p><h1 id="4ceb" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">10.简单并不意味着准确</h1><p id="5049" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">在机器学习中，奥卡姆剃刀通常被认为是指，给定两个具有相同训练误差的分类器，两个分类器中较简单的一个可能具有最低的测试误差。</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div class="fe ff mf"><img src="../Images/40709c179e2efdda729207dbd329db51.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/0*zLNo3p2tgcBcigFk"/></div></figure><p id="0b89" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">但这不是真的，我们之前看到了一个反例:即使在训练误差已经达到零之后，通过增加分类器，增强集成的泛化误差继续改善。与直觉相反，一个模型的参数个数与其过拟合的倾向 之间没有<strong class="je ig"> <em class="ka">的必然联系。也就是说，在机器学习中，更简单的假设仍然是首选，因为<strong class="je ig"> <em class="ka">简单本身就是一种美德</em> </strong>而不是因为它意味着准确。</em></strong></p><h1 id="8baa" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">11.可表现并不意味着可学习</h1><p id="57db" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">一个函数可以被表示出来，并不意味着它可以被学习。例如，标准决策树学习者不能学习比训练样本更多的叶子的树。</p><p id="7197" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">给定有限的数据、时间和记忆，标准学习者只能学习所有可能函数的极小子集，这些子集对于具有不同表征的学习者是不同的。因此，这里的关键是，尝试不同的学习者 (并可能结合他们)是值得的。</p><h1 id="8113" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">12.相关性并不意味着因果关系</h1><p id="dc5e" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">我们都听说过相关性并不意味着因果关系，但人们仍然经常倾向于认为相关性意味着因果关系。</p><figure class="lg lh li lj fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mg"><img src="../Images/d23c059e828b36239cbc4487b136aade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cq1xTYFyJ3EO_wfH"/></div></div></figure><p id="3a40" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">通常，学习预测模型的目的是将它们用作行动指南。如果我们发现啤酒和尿布经常在超市一起买，那么<strong class="je ig"> <em class="ka">也许</em> </strong>把啤酒放在尿布区旁边会增加销量。但是除非我们做一个实际的实验，否则很难判断这是不是真的。相关性<strong class="je ig"> <em class="ka">是一种潜在因果联系的标志</em> </strong>，我们可以把它作为进一步调查 的<strong class="je ig"> <em class="ka">指南，而不是作为我们的最终结论。</em></strong></p><h1 id="004f" class="kc kd if bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">结论</h1><p id="f177" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated">像任何学科一样，机器学习有很多“民间智慧”，可能很难获得，但对成功至关重要。感谢多明戈斯教授，我们今天获得了一些智慧。希望本演练对您有所帮助。请在下面的评论区告诉我你的想法。</p></div><div class="ab cl mh mi hc mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="hn ho hp hq hr"><h1 id="2d29" class="kc kd if bd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku kv ms kx ky kz dt translated"><strong class="ak">喜欢用直观的方式学习ML概念？</strong></h1><p id="7e7b" class="pw-post-body-paragraph jc jd if je b jf la jh ji jj lb jl jm jn lc jp jq jr ld jt ju jv le jx jy jz hn dt translated"><em class="ka">本文原载于我的</em> <a class="ae kb" href="https://towardsml.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="je ig"> <em class="ka"> ML博客</em> </strong> </a> <em class="ka">。在那里查看我的其他作品，并且不要错过最新的！</em></p></div><div class="ab cl mh mi hc mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="hn ho hp hq hr"><h1 id="9ccb" class="kc kd if bd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku kv ms kx ky kz dt translated">参考资料和进一步阅读</h1><ul class=""><li id="05cc" class="lk ll if je b jf la jj lb jn mt jr mu jv mv jz lp lq lr ls dt translated"><a class="ae kb" href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf" rel="noopener ugc nofollow" target="_blank">原论文</a></li><li id="39aa" class="lk ll if je b jf lt jj lu jn lv jr lw jv lx jz lp lq lr ls dt translated"><a class="ae kb" href="https://www.amazon.com/dp/0465065708/ref=asc_df_04650657081553943600000?tag=shopzilla0d-20&amp;ascsubtag=shopzilla_rev_484-20;15546255828613203600910070301008005&amp;creative=395261&amp;creativeASIN=0465065708&amp;linkCode=asn" rel="noopener ugc nofollow" target="_blank">教授的深入研究之书:大师算法</a></li></ul></div></div>    
</body>
</html>