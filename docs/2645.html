<html>
<head>
<title>Organisations Need to Introduce Processes that Ensure we trust AI decisions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">组织需要引入确保我们信任人工智能决策的流程</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/can-we-trust-ai-decisions-organisations-need-to-introduce-processes-that-ensure-we-can-da3a55d043a3#2019-04-24">https://medium.com/hackernoon/can-we-trust-ai-decisions-organisations-need-to-introduce-processes-that-ensure-we-can-da3a55d043a3#2019-04-24</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/></div><div class="ab cl ir is hc it" role="separator"><span class="iu bw bk iv iw ix"/><span class="iu bw bk iv iw ix"/><span class="iu bw bk iv iw"/></div><div class="hn ho hp hq hr"><figure class="iz ja jb jc fq jd fe ff paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="fe ff iy"><img src="../Images/82e48bb4071a98a63139d1079e2c133d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sc8GGAks3Iy8gX0wM7y5BA.png"/></div></div></figure><p id="f143" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">人工智能正在通过击败人类象棋和围棋冠军而成为头条新闻，并以虚拟语音助手、汽车导航系统和电子商店购买推荐的形式悄然进入我们的生活。它在幕后提供了更多公众看不到的好处，从人工智能帮助组织保护自己免受贷款相关风险，到诊断医疗状况，甚至计算行人。</p><p id="31a5" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">所有这些都很有用，但也伴随着对算法偏差和个人隐私的新担忧。人工智能带来的新挑战包括潜在导致不公平决定的无意歧视风险，以及与消费者对人工智能如何参与做出重大或敏感决定的知识有关的问题。许多大问题仍然没有答案，甚至更大的问题还没有被提出。</p><p id="2881" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">尽管面临这些挑战，人工智能仍然为提高生产率、增强竞争力以及推出新产品和服务提供了前所未有的机遇。然而，组织需要应用一套指导原则来确保当人工智能用于决策时，该过程是可解释的、透明的和公平的。开发和部署人工智能的首要考虑应该是保护人类的利益，包括他们的福祉和安全。只有这样才能促进对人工智能的信任。</p><p id="2f8b" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">这项技术本身有助于确保实现其中一些目标。一些人声称，区块链可以对用于训练人工智能模型的数据的完整性提供强有力的监督。几家 IT 公司已经宣布开发软件，可以可视化人工智能算法如何做出决策，还可以检测出不必要的偏差。然而，这些解决方案是否足以有效理解，更重要的是解释复杂的深度学习人工智能算法，仍有待观察。</p><p id="9881" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">在任何情况下，组织都应该引入内部治理结构和措施，以确保对人工智能使用的监督。可以调整现有的治理结构:道德考虑可以作为企业价值观引入，相关的风险可以通过现有的企业风险管理结构来管理。</p><p id="1197" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">管理与人工智能算法相关的风险的一种基本方法是，将对个人造成伤害的概率和严重程度分类为对该个人所做决策的影响。我们如何定义伤害的概率和严重程度取决于具体情况——与对患者病情的错误诊断相关的伤害不同于与电子商店的错误购买建议相关的伤害。</p><p id="e494" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">由此产生的人工智能风险管理模型应该表明决策过程中的人工监督水平。在伤害的可能性和/或严重性很大的领域，人类应该有完全的控制权，而人工智能应该只提供建议。</p><p id="7060" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">另一种情况可能是，人工智能提供了一系列可供选择的选择，人类可以做出决定，例如当 GPS 导航建议一系列路线时，人类可以选择，然后人工智能可以适应沿途的任何人类决定，比如不可预见的道路拥堵。也许当自动驾驶汽车到来时，当司机不再亲自指挥汽车时，它应该保持这种状态。</p><p id="c071" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">很容易理解，人工智能算法的好坏取决于用来训练它们的数据，因此组织应该确保它们使用高质量的数据。产生坏数据的方式有很多:数据集可能不完整、有偏见、过时、不准确、被修改，或者只是与正在解决的问题不太相关。</p><p id="c185" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">不同的数据集应该用于训练、测试和验证。测试数据用于确定使用训练数据开发的模型的准确性，并使用验证数据进行验证。应该始终测试不同的人口统计群体，以识别可能的偏见。</p><p id="64d4" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">许多算法来自外国，并可能在样本上进行训练，这些样本在我们的空间中可能不完全适用。例如，如果欧洲的一个机场决定使用在中国训练的算法来扫描乘客的面部，并将其与已知恐怖分子的生物特征数据库进行比较，那么在分析欧洲罗姆人时，这可能是不准确的。</p><p id="a717" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">有些问题只有在解决方案大规模应用时才变得明显。例如，智能停车系统可以很好地建议司机在特定的地点停车，但是当该系统被广泛使用并且 100 个司机被建议在同一个地点停车时，问题就出现了。</p><p id="8aee" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">最后，在部署人工智能时，组织应该管理公开透明的沟通。他们应该提供关于他们的产品和/或服务中是否使用人工智能的信息，并解释如何使用人工智能来做出关于个人的决定。同样重要的是，要认真考虑为选择不接受人工智能算法的个人提供“退出”选项。</p><p id="3d2f" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">随着人工智能技术的发展，相关的道德和治理问题也将随之发展。进步等于技术加上公民社会。因此，以道德的方式使用这些技术非常重要，只有这样，它们才能造福整个社会。</p><h2 id="d072" class="ki kj hu bd kk kl km kn ko kp kq kr ks jv kt ku kv jz kw kx ky kd kz la lb lc dt translated">放弃</h2><p id="7343" class="pw-post-body-paragraph jk jl hu jm b jn ld jp jq jr le jt ju jv lf jx jy jz lg kb kc kd lh kf kg kh hn dt translated">此处包含的信息是严格保密的，只提供给有限数量的具有参与私募股权、不受监管的计划和其他此类复杂投资的必要专业经验的潜在投资者、高净值个人、公司和协会，以及可以合法传达信息的其他人员(所有此类人员统称为“相关人员”)。本文件所涉及的任何投资或投资活动仅适用于相关人员，所有非相关人员不得依赖本文件或依据本文件行事。这不是广告，也不打算公开使用或分发。未经 NKB 集团事先明确同意，不得出于任何目的复制、再分发或拷贝本文件的全部或部分内容。</p><p id="da79" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">本文档是本着诚信原则编写的，但是其中包含的信息可能会在不通知的情况下发生更改，并且是在指定的日期提供的。NKB 集团股份有限公司或其任何关联公司、董事、高级职员、雇员、顾问或任何其他人员不代表其对本文信息或观点的准确性、公平性或完整性做出任何明示或暗示的陈述或保证，除非存在欺诈，否则任何此类人员不承担任何损失责任，无论此类损失是直接或间接因使用此类信息或观点而产生，还是因与此相关而产生。</p><p id="5902" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">本文件仅供讨论之用，并不包含构成投资决策基础所需的所有信息。本文件中的任何内容均不构成任何类型的建议或投资、账户、法律、监管、税务或其他建议。接受者应就参与本文件中提及的任何投资机会的潜在后果咨询其专业顾问，包括但不限于基于其个人情况的此类投资的潜在法律、监管、信贷、税收和会计影响。</p><p id="266d" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">尚未采取任何措施允许在任何需要此类措施的司法管辖区分发本文件。此类分发在某些司法管辖区可能会受到限制，因此，本文件不构成对任何司法管辖区内任何人的要约或邀约，也不得用于此目的</p><p id="8b7e" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">在考虑本文件中包含的任何绩效数据时，请注意，过去或目标绩效并不一定代表未来的结果，投资的价值和从这些投资中获得的收入可能会下降或上升。未来的回报是不保证的，可能会发生本金的全部损失。</p><p id="8e2d" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">NKB 集团股份公司。在奥地利注册，注册号为 486551t。NKB 控股英国有限公司在英格兰和威尔士注册，注册号为 11314202，注册办事处位于伦敦康诺特广场 1 号，W2 2ET。</p><figure class="iz ja jb jc fq jd fe ff paragraph-image"><div class="fe ff li"><img src="../Images/dce0f5c498238f329ac2168794904306.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*ZWNtH2NTHxTTZisOjHI4TA.png"/></div></figure><p id="cd59" class="pw-post-body-paragraph jk jl hu jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hn dt translated">米罗斯拉夫·皮库斯<br/>首席技术官</p><figure class="iz ja jb jc fq jd"><div class="bz el l di"><div class="lj lk l"/></div></figure></div></div>    
</body>
</html>