<html>
<head>
<title>Mueller Report for Nerds! Spark meets NLP with TensorFlow and BERT (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">书呆子的穆勒报告！Spark 与 TensorFlow 和 BERT 相遇 NLP(第 1 部分)</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/mueller-report-for-nerds-spark-meets-nlp-with-tensorflow-and-bert-part-1-32490a8f8f12#2019-05-01">https://medium.com/hackernoon/mueller-report-for-nerds-spark-meets-nlp-with-tensorflow-and-bert-part-1-32490a8f8f12#2019-05-01</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><h1 id="7d98" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated">Apache Spark 实现 NLP 的正确方法</h1><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff jp"><img src="../Images/b2c77edeea09bdbb787f3b2c18885778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TN4D52XajcYPSmWVhaarRA.jpeg"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Photo by <a class="ae kf" href="https://unsplash.com/photos/9wXvgLMDetA?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Michael</a> on <a class="ae kf" href="https://unsplash.com/search/photos/department-of-justice?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9685" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">你有没有想过，如果你不读这本书，你能说出书里的内容？如果你能画一张所有重要人物、地点、事件以及它们之间关系的地图会怎么样？这就是<strong class="ki hv">自然语言处理</strong> (NLP)和<strong class="ki hv">文本挖掘</strong>技术可以帮助我们以一种新的和不同的方式理解自然语言数据的地方。</p><p id="2f2c" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">好吧！也许“阅读一本书”不是一个好的例子，因为每个人<strong class="ki hv">每个月至少应该阅读两到四本书！</strong></p><blockquote class="le"><p id="dfa4" class="lf lg hu bd lh li lj lk ll lm ln ld ek translated"><em class="lo">这是一系列文章，通过使用基于 Apache Spark 构建的</em><a class="ae kf" href="https://github.com/JohnSnowLabs/spark-nlp" rel="noopener ugc nofollow" target="_blank"><em class="lo">Spark NLP</em></a><em class="lo">库和由 TensorFlow 和 BERT 支持的预训练模型来探索“穆勒报告”。</em></p><p id="d029" class="lf lg hu bd lh li lj lk ll lm ln ld ek translated">这些文章对于那些有兴趣学习如何使用 Apache Spark 进行 NLP 的人来说是纯教育性的。</p></blockquote><p id="7b79" class="pw-post-body-paragraph kg kh hu ki b kj lp kl km kn lq kp kq kr lr kt ku kv ls kx ky kz lt lb lc ld hn dt lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> F </span> <strong class="ki hv">第一部分:</strong>通过使用 Spark NLP 提供的预训练管道和模型，执行 NLP 任务并注释“<strong class="ki hv"> Mueller 报告”</strong>。</p><p id="1792" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">S</span>T22】第二部分<em class="md"> : </em> 使用 BERT 训练的模型，在 Spark NLP 中训练一个 POS 标记器模型，数据清洗，通过 POS 和 NER 分块提取关键词/短语。</p><p id="d8c3" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">T</span>T<strong class="ki hv">第三部分:<a class="ae kf" href="https://github.com/graphframes/graphframes" rel="noopener ugc nofollow" target="_blank"> GraphFrames </a>的</strong>图形算法，Spark ML 的聚类和主题建模，以及<a class="ae kf" href="https://gephi.org/" rel="noopener ugc nofollow" target="_blank"> Gephi </a>的网络可视化。</p><div class="jq jr js jt fq ab cb"><figure class="me ju mf mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/90d61ed09790b3b4150d70aca385e199.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*dKu4OtRqYECe0V9GJ1rz_w.png"/></div></figure><figure class="me ju mk mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/5617cba52e3fc92ba003ccae3a7874b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*tCMwMgwneobnzcp0b0HxnA.png"/></div></figure></div><div class="ab cb"><figure class="me ju ml mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/ef2c14dcce42c7697039f553c8defb46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*bp4I4GCfcSiyU3zvwROILg.png"/></div></figure><figure class="me ju mm mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/4601190d4aaaa45409991d7128a2bbba.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*6QTIrRWeHZR5mtyWhchghQ.png"/></div></figure><figure class="me ju mn mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/02d880408f5ecbb6a588c5bf349e4c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*y6hpDyXSF-fV2qN82O4IXw.png"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek mo di mp mq">Extracting keywords from the Mueller Report by using Spark NLP</figcaption></figure></div></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><h1 id="1aa5" class="ir is hu bd it iu my iw ix iy mz ja jb jc na je jf jg nb ji jj jk nc jm jn jo dt translated">关于俄罗斯干涉 2016 年总统选举的调查报告</h1><p id="e942" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated"><strong class="ki hv">米勒报告俗称</strong></p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff ni"><img src="../Images/8f53d03a8ad6ffe3a2b50395891bf5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2pg51fR-6FH3rh0WXr3psA.jpeg"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Robert Mueller, 2012</figcaption></figure><p id="c9a9" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">最初的报告是由美国发布的。司法部(<a class="ae kf" href="https://www.justice.gov/storage/report.pdf" rel="noopener ugc nofollow" target="_blank">原始文件</a>)对于我们这些不熟悉他的调查的人来说:</p><blockquote class="nj nk nl"><p id="70de" class="kg kh md ki b kj kk kl km kn ko kp kq nm ks kt ku nn kw kx ky no la lb lc ld hn dt translated">经过多年的调查，司法部周四公布了特别顾问罗伯特·穆勒报告的编辑副本。这份报告将近<strong class="ki hv"> 400 </strong>页，涵盖了从<strong class="ki hv">俄罗斯</strong>干涉 2016 <strong class="ki hv">美国总统选举</strong>到<strong class="ki hv">唐纳德·川普</strong>总统是否妨碍司法公正等问题。<a class="np nq gr" href="https://medium.com/u/374a801b3eb2#tokenizer" rel="noopener ugc nofollow" target="_blank">分词器</a></li><li id="5128" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#normalizer" rel="noopener ugc nofollow" target="_blank">规格化器</a></li><li id="119f" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#stemmer" rel="noopener ugc nofollow" target="_blank">斯特梅尔</a></li><li id="2818" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#lemmatizer" rel="noopener ugc nofollow" target="_blank"> Lemmatizer </a></li><li id="0f5c" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher" rel="noopener ugc nofollow" target="_blank">正则表达式匹配器</a></li><li id="e468" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#textmatcher" rel="noopener ugc nofollow" target="_blank">文本匹配器</a></li><li id="82a1" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#chunker" rel="noopener ugc nofollow" target="_blank">切饼机</a></li><li id="190b" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#datematcher" rel="noopener ugc nofollow" target="_blank">约会对象</a></li><li id="0b9d" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#sentencedetector" rel="noopener ugc nofollow" target="_blank">sentenced 检测器</a></li><li id="eddf" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#deepsentencedetector" rel="noopener ugc nofollow" target="_blank">深度检测器</a></li><li id="a5ba" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#postagger" rel="noopener ugc nofollow" target="_blank">后置标记</a></li><li id="dddf" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#viveknsentimentdetector" rel="noopener ugc nofollow" target="_blank">viveksentimentdetector</a></li><li id="a461" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#sentimentdetector" rel="noopener ugc nofollow" target="_blank">情感探测器:情感分析</a></li><li id="4eaa" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#word-embeddings" rel="noopener ugc nofollow" target="_blank">词语嵌入</a></li><li id="1bcf" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#ner-crf" rel="noopener ugc nofollow" target="_blank"> NER CRF </a></li><li id="8146" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#ner-dl" rel="noopener ugc nofollow" target="_blank"> NER DL </a></li><li id="70e6" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#norvig-spellchecker" rel="noopener ugc nofollow" target="_blank">诺维格拼写检查器</a></li><li id="db08" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#symmetric-spellchecker" rel="noopener ugc nofollow" target="_blank">对称拼写检查器</a></li><li id="377d" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#dependency-parser" rel="noopener ugc nofollow" target="_blank">依赖解析器</a></li><li id="2fa5" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators#typed-dependency-parser" rel="noopener ugc nofollow" target="_blank">类型依赖解析器</a></li></ul><p id="6653" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">关于注释器、模型和管道的完整列表，您可以阅读<a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/annotators" rel="noopener ugc nofollow" target="_blank">他们的在线文档</a>。</p><blockquote class="le"><p id="b68c" class="lf lg hu bd lh li lj lk ll lm ln ld ek translated">完全披露:我是<a class="ae kf" href="https://github.com/JohnSnowLabs/spark-nlp/graphs/contributors" rel="noopener ugc nofollow" target="_blank">投稿人</a>之一！</p></blockquote><h1 id="5565" class="ir is hu bd it iu iv iw ix iy iz ja jb jc of je jf jg og ji jj jk oh jm jn jo dt translated">安装 Spark NLP</h1><p id="a54d" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">我的环境:</p><ul class=""><li id="f9dd" class="nr ns hu ki b kj kk kn ko kr nt kv nu kz nv ld nw nx ny nz dt translated"><a class="ae kf" href="https://github.com/JohnSnowLabs/spark-nlp" rel="noopener ugc nofollow" target="_blank">火花 NLP </a> 2.0.3 发布</li><li id="40c4" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">阿帕奇火花 2.4.1</li><li id="d7f2" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">阿帕奇齐柏林飞艇版本 0.8.2</li><li id="f46a" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">使用 MacBook Pro/macOS 进行本地设置</li><li id="6a1c" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">使用 40 台服务器的 Cloudera/CDH 6.2 集群设置</li><li id="0542" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">编程语言:Scala(但是不用担心，Spark 和 Spark NLP 中的 Python APIs 与 Scala 语言非常相似)</li></ul><p id="75bb" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">我将解释如何为我的环境设置 Spark NLP。尽管如此，如果您希望尝试一些不同的东西，您可以通过访问主要的公共存储库或查看包含大量示例的 showcase 存储库来了解有关如何使用 Spark NLP 的更多信息:</p><p id="4791" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv">主</strong>公共知识库:</p><div class="oi oj fm fo ok ol"><a href="https://github.com/johnsnowlabs/spark-nlp" rel="noopener  ugc nofollow" target="_blank"><div class="om ab ej"><div class="on ab oo cl cj op"><h2 class="bd hv fv z el oq eo ep or er et ht dt translated">约翰·斯诺实验室/spark-nlp</h2><div class="os l"><h3 class="bd b fv z el oq eo ep or er et ek translated">Apache Spark 自然语言理解库。约翰·斯诺实验室/spark-nlp</h3></div><div class="ot l"><p class="bd b gc z el oq eo ep or er et ek translated">github.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz jz ol"/></div></div></a></div><p id="b6f7" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv">展柜</strong>储存库:</p><div class="oi oj fm fo ok ol"><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop" rel="noopener  ugc nofollow" target="_blank"><div class="om ab ej"><div class="on ab oo cl cj op"><h2 class="bd hv fv z el oq eo ep or er et ht dt translated">约翰·斯诺实验室/spark-NLP-车间</h2><div class="os l"><h3 class="bd b fv z el oq eo ep or er et ek translated">为 Apache Spark 使用 John Snow Labs 的 NLP 的公共运行示例。— JohnSnowLabs/spark-nlp 工作室</h3></div><div class="ot l"><p class="bd b gc z el oq eo ep or er et ek translated">github.com</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz jz ol"/></div></div></a></div><p id="77c8" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">我们开始吧！要在 Apache Zeppelin 中使用 Spark NLP，您有两种选择。要么使用<strong class="ki hv"> Spark 包</strong>，要么你可以自己构建一个胖罐子，并在 Spark 会话中将其作为<strong class="ki hv">外部罐子</strong>加载。要不我给你们俩看看？</p><h2 id="c64d" class="pb is hu bd it pc pd pe ix pf pg ph jb kr pi pj jf kv pk pl jj kz pm pn jn po dt translated">首先，带 Spark 包:</h2><p id="8c10" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">要么把这个添加到你的<strong class="ki hv"> conf/zeppelin-env.sh </strong></p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="fad7" class="pb is hu pq b fv pu pv l pw px"><em class="md"># set options to pass spark-submit command</em><br/>export SPARK_SUBMIT_OPTIONS<strong class="pq hv">=</strong>"--packages <!-- -->com.johnsnowlabs.nlp:spark-nlp_2.11:2.0.3<!-- -->"</span></pre><p id="29bd" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">2.或者，将其添加到<strong class="ki hv">通用内联配置解释器</strong>(在开始 Spark 会话之前，在笔记本的开头):</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="c3b2" class="pb is hu pq b fv pu pv l pw px">%spark.conf</span><span id="f3c8" class="pb is hu pq b fv py pv l pw px"># spark.jars.packages can be used for adding packages into spark interpreter<br/>spark.jars.packages com.johnsnowlabs.nlp:spark-nlp_2.11:2.0.3</span></pre><h2 id="34ad" class="pb is hu bd it pc pd pe ix pf pg ph jb kr pi pj jf kv pk pl jj kz pm pn jn po dt translated">其次，加载外部 JAR:</h2><p id="2b5d" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">要建造一个大罐子，你需要做的就是:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="1e5b" class="pb is hu pq b fv pu pv l pw px">$ git clone <a class="ae kf" href="https://github.com/JohnSnowLabs/spark-nlp#apache-zeppelin" rel="noopener ugc nofollow" target="_blank">https://github.com/JohnSnowLabs/spark-nlp</a><br/>$ cd spark-nlp<br/>$ sbt assembly</span></pre><p id="d74e" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">然后，您可以按照我提到的两种方法之一来添加这个外部 JAR。您只需要在第一个选项中将“— packages”改为“— jars”。或者对于第二个解决方案，只需要“spark.jars”。</p><h2 id="e9ee" class="pb is hu bd it pc pd pe ix pf pg ph jb kr pi pj jf kv pk pl jj kz pm pn jn po dt translated">用 Spark NLP 启动 Spark</h2><p id="a86e" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">现在，我们可以通过导入 Spark NLP 注释器开始将<strong class="ki hv"> Spark NLP 2.0.3 </strong>与<strong class="ki hv"> Zeppelin 0.8.2 </strong>和<strong class="ki hv"> Spark 2.4.1 </strong>一起使用:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="5100" class="pb is hu pq b fv pu pv l pw px">import com.johnsnowlabs.nlp.base._<br/>import com.johnsnowlabs.nlp.annotator._<br/>import org.apache.spark.ml.Pipeline</span></pre><p id="2333" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">Apache Zeppelin 将启动一个新的 Spark 会话，它与 Spark NLP 一起提供，不管您使用的是 Spark 包还是外部 JAR。</p><h2 id="30ff" class="pb is hu bd it pc pd pe ix pf pg ph jb kr pi pj jf kv pk pl jj kz pm pn jn po dt translated">阅读穆勒报告 PDF 文件</h2><p id="1b61" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">还记得关于 PDF 文件不是真正的 PDF 的问题吗？我们有三个选择:</p><ol class=""><li id="1fab" class="nr ns hu ki b kj kk kn ko kr nt kv nu kz nv ld pz nx ny nz dt translated">您可以使用任何您喜欢的 OCR 工具/库来生成 PDF 或文本文件。</li><li id="2c4e" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld pz nx ny nz dt translated">或者您可以使用社区创建的已经可搜索和可选择的 PDF 文件。</li><li id="c920" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld pz nx ny nz dt translated">或者你可以直接用 Spark NLP！</li></ol><p id="abd9" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">Spark NLP 带有一个<strong class="ki hv"> OCR </strong>包，可以读取 PDF 文件和扫描图像。但是，我把选项 2 和选项 3 混在了一起。(我需要在整个集群上为基于图像的 OCR 安装 Tesseract 4.x+,所以我有点懒)</p><p id="66c0" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">您可以从 Scribd 下载这两个 PDF 文件:</p><ul class=""><li id="34b4" class="nr ns hu ki b kj kk kn ko kr nt kv nu kz nv ld nw nx ny nz dt translated"><a class="ae kf" href="https://www.scribd.com/document/406904220/Word-searchable-Mueller-Report-Redacted-Vol-I" rel="noopener ugc nofollow" target="_blank">穆勒报告编辑第一卷</a></li><li id="e7c7" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://www.scribd.com/document/406904826/Word-searchable-Mueller-Report-Redacted-Vol-II" rel="noopener ugc nofollow" target="_blank">穆勒报告修订第二卷</a></li></ul><p id="0e08" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">当然你也可以直接下载文字版，用 Spark 看。但是，我想向您展示如何使用 Spark NLP 附带的 OCR。</p><p id="faa1" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv"> Spark NLP OCR: </strong></p><p id="c488" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">让我们为与 OCR 相关的一切创建一个助手函数:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="5f44" class="pb is hu pq b fv pu pv l pw px">import com.johnsnowlabs.nlp.util.io.OcrHelper<br/>val ocrHelper = new OcrHelper()</span></pre><p id="dc35" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">现在，我们需要阅读 PDF 并根据其内容创建一个数据集。Spark NLP 中的 OCR 每页创建一行:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="506e" class="pb is hu pq b fv pu pv l pw px">//If you do this locally you can use <strong class="pq hv">file:///</strong> or <strong class="pq hv">hdfs:///</strong> if the files are hosted in Hadoop</span><span id="8d8b" class="pb is hu pq b fv py pv l pw px"><strong class="pq hv">val muellerFirstVol = ocrHelper.createDataset</strong>(spark, "/tmp/Mueller/Mueller-Report-Redacted-Vol-I-Released-04.18.2019-Word-Searchable.-Reduced-Size.pdf")</span></pre><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qa"><img src="../Images/ab3ad912c74f77504ef8cfc019a4b2ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LGlDxmYV0kuO9JDl8IPW-g.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">DataFrame created by reading the PDF file</figcaption></figure><p id="186b" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">如您所见，我正在将该报告的“第一卷”以 PDF 格式加载到一个数据集中。我在本地这样做只是为了说明使用 Apache Spark 和 Spark NLP 并不总是需要集群！</p><p id="ac30" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv">提示 1 </strong>:如果 PDF 实际上是扫描图像，我们可以使用这些设置(但在我们的用例中，我们发现了一个可选的 PDF):</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="4eff" class="pb is hu pq b fv pu pv l pw px">ocrHelper.setPreferredMethod("image")<br/>ocrHelper.setFallbackMethod(false)<br/>ocrHelper.setMinSizeBeforeFallback(0)</span></pre><p id="06f9" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv">提示 2 </strong>:如果需要，您可以通过以下方式将 Spark 数据集转换为 DataFrame:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="97fe" class="pb is hu pq b fv pu pv l pw px"><strong class="pq hv">muellerFirstVol.toDF()</strong></span></pre><h1 id="b6b0" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated">Spark NLP 管道和模型</h1><h2 id="6161" class="pb is hu bd it pc pd pe ix pf pg ph jb kr pi pj jf kv pk pl jj kz pm pn jn po dt translated">机器学习和深度学习的自然语言处理</h2><p id="0ed0" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">现在是时候做一些 NLP 任务了。正如我在开始时提到的，我们希望使用已经预先培训好的由 Spark NLP 在第一部分中提供的<strong class="ki hv">管道</strong>和<strong class="ki hv">型号</strong>。这些是一些可用的<a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/pipelines" rel="noopener ugc nofollow" target="_blank">管道</a>和<a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/models" rel="noopener ugc nofollow" target="_blank">型号</a>:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qb"><img src="../Images/0dc4f488479be8907fdbb50b7f840740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5gBtYRBg1dhZtK26BlSEQ.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Spark NLP pre-trained Pipelines and Models (full list of <a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/pipelines" rel="noopener ugc nofollow" target="_blank">pipelines</a> and <a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/models" rel="noopener ugc nofollow" target="_blank">models</a>)</figcaption></figure><p id="21a3" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">不过，我想先用一个名为<strong class="ki hv">“explain _ document _ dl”</strong>的管道。让我们看看如何下载这个管道，用它来注释一些输入，以及它到底提供了什么:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="f61b" class="pb is hu pq b fv pu pv l pw px">import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline</span><span id="1187" class="pb is hu pq b fv py pv l pw px">val pipeline = PretrainedPipeline("<strong class="pq hv">explain_document_dl</strong>", "<strong class="pq hv">en</strong>")</span><span id="41fe" class="pb is hu pq b fv py pv l pw px">// This DataFrame has one sentence for testing<br/>val testData = Seq(<br/>    "Donald Trump is the 45th President of the United States"<br/>    ).toDS.toDF("text")</span><span id="2132" class="pb is hu pq b fv py pv l pw px">// Let's use our pre-trained pipeline to predict the test dataset<br/>pipeline.transform(testData).show</span></pre><p id="9261" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">以下是的结果。显示():</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qc"><img src="../Images/79d84565edfd1f9b8180bfc61e8fd1bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQTpVZmH0hn12JSrJzqNVw.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Spark NLP pre-trained “<strong class="bd qd">explain_document_dl</strong>” pipeline</figcaption></figure><p id="b9b9" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">我知道！这条管道里有很多东西。让我们从我们在<strong class="ki hv">“explain _ document _ dl”</strong>管道中的 NLP 注释器开始:</p><ul class=""><li id="80bd" class="nr ns hu ki b kj kk kn ko kr nt kv nu kz nv ld nw nx ny nz dt translated">文件汇编员</li><li id="5d19" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">判刑检测员</li><li id="0023" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">标记器</li><li id="3541" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">引理模型</li><li id="5201" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">斯特梅尔</li><li id="46ce" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">感知器模型</li><li id="bb6a" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">ContextSpellCheckerModel</li><li id="ccc1" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">WordEmbeddings(手套 6B 100)</li><li id="a1f4" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">NerDLModel</li><li id="85be" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">NerConverter(分块)</li></ul><p id="be2d" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">据我所知，这个管道中有一些标注器正在使用由<strong class="ki hv"> TensorFlow </strong>驱动的<strong class="ki hv">深度学习</strong>进行监督学习。例如，当您加载此管道时，您会注意到这几行:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="f06d" class="pb is hu pq b fv pu pv l pw px">pipeline: com.johnsnowlabs.nlp.pretrained.PretrainedPipeline = PretrainedPipeline(<strong class="pq hv">explain_document_dl</strong>,en,public/models)</span><span id="f1ae" class="pb is hu pq b fv py pv l pw px">adding (ner-dl/mac/_sparse_feature_cross_op.so,ner-dl/mac/_lstm_ops.so)</span><span id="c477" class="pb is hu pq b fv py pv l pw px">loading to <strong class="pq hv">tensorflow</strong></span></pre><p id="4155" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">为简单起见，我将分别选择一组列，这样我们就可以实际看到一些结果:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qe"><img src="../Images/b2bfe30084e6056f5936085588de5e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t6BInZsPG9h80C-OlJkoKQ.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Spark NLP pre-trained “<strong class="bd qd">explain_document_dl</strong>” pipeline</figcaption></figure><p id="c08a" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">这是一个非常完整的 NLP 管道。像其他 NLP 库一样，它有许多 NLP 任务，甚至更像<strong class="ki hv">拼写检查。</strong>但是，如果你只是在寻找一个或两个自然语言处理任务，如 POS 或 NER，这可能有点重。</p><p id="b3c9" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">让我们尝试另一个预先训练好的管道，名为<strong class="ki hv">“entity _ recognizer _ dl”:</strong></p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="7fe6" class="pb is hu pq b fv pu pv l pw px">import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline</span><span id="dcb4" class="pb is hu pq b fv py pv l pw px">val pipeline = PretrainedPipeline("<strong class="pq hv">entity_recognizer_dl</strong>", "<strong class="pq hv">en</strong>")</span><span id="ff57" class="pb is hu pq b fv py pv l pw px">val testData = Seq(<br/>    "Donald Trump is the 45th President of the United States"    ).toDS.toDF("text")</span><span id="e229" class="pb is hu pq b fv py pv l pw px">// Let's use our pre-trained pipeline to predict the test dataset<br/>pipeline.transform(testData).show</span></pre><p id="e0c8" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">如您所见，使用预先训练的管道非常容易。你只需要改变它的名字，它就会下载并缓存在本地。这条管道里有什么？</p><ul class=""><li id="cbfa" class="nr ns hu ki b kj kk kn ko kr nt kv nu kz nv ld nw nx ny nz dt translated">文件</li><li id="e906" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">句子</li><li id="d6ed" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated">代币</li><li id="a4b2" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><strong class="ki hv">嵌入</strong></li><li id="f4cf" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><strong class="ki hv"> NER </strong></li><li id="4951" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><strong class="ki hv"> NER 大块</strong></li></ul><p id="bba8" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">让我们来看看 NER 模式在这两条管道中发生了什么。<strong class="ki hv">命名实体识别(NER) </strong>使用<strong class="ki hv">单词嵌入</strong> ( <strong class="ki hv">手套</strong>或<strong class="ki hv">伯特</strong>)进行训练。我可以引用该项目的主要维护者之一的话来说明它是什么:</p><blockquote class="le"><p id="1fd8" class="lf lg hu bd lh li lj lk ll lm ln ld ek translated">NerDLModel 是一个训练过程的结果，由 NerDLApproach SparkML estimator 发起。这个估算器是一个张量流 DLmodel。它遵循具有卷积神经网络的双 LSTM 方案，利用单词嵌入进行令牌和子令牌分析。</p></blockquote><p id="c5c5" class="pw-post-body-paragraph kg kh hu ki b kj lp kl km kn lq kp kq kr lr kt ku kv ls kx ky kz lt lb lc ld hn dt translated">你可以阅读这篇关于使用<strong class="ki hv">张量流</strong>图以及 Spark NLP 如何使用它来训练其 NER 模型的完整文章:</p><div class="oi oj fm fo ok ol"><a rel="noopener follow" target="_blank" href="/@saif1988/spark-nlp-walkthrough-powered-by-tensorflow-9965538663fd"><div class="om ab ej"><div class="on ab oo cl cj op"><h2 class="bd hv fv z el oq eo ep or er et ht dt translated">Spark NLP 演练，由 TensorFlow 提供支持</h2><div class="os l"><h3 class="bd b fv z el oq eo ep or er et ek translated">本文是一个演练解决一个现实的用例自然语言理解在医疗保健使用…</h3></div><div class="ot l"><p class="bd b gc z el oq eo ep or er et ek translated">medium.com</p></div></div><div class="ou l"><div class="qf l ow ox oy ou oz jz ol"/></div></div></a></div><p id="5243" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">回到我们的管道，NER 块将提取命名实体块。例如，如果你有<strong class="ki hv">唐纳德</strong> - &gt;伊佩尔和<strong class="ki hv">川普</strong> - &gt;伊佩尔，就会产生<strong class="ki hv">姜懿翔川普</strong>。看一下这个例子:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qg"><img src="../Images/99cbeb4b2fc4e0899eacfb0d897c0842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_bX7tlRNR9e4U-8dekSbwQ.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Spark NLP pre-trained “<strong class="bd qd">entity_recognizer_dl</strong>” pipeline</figcaption></figure><h2 id="a2e7" class="pb is hu bd it pc pd pe ix pf pg ph jb kr pi pj jf kv pk pl jj kz pm pn jn po dt translated">自定义管道</h2><p id="dab8" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">就个人而言，当我处理预先训练好的模型时，我更喜欢构建自己的 NLP 管道。通过这种方式，我可以完全控制我想要使用什么类型的注释器，我想要 ML 还是 DL 模型，在混合中使用我自己训练的模型，定制每个注释器的输入/输出，集成 Spark ML 函数，等等！</p><blockquote class="le"><p id="762f" class="lf lg hu bd lh li lj lk ll lm ln ld ek translated">是否有可能创建自己的 NLP 管道，但仍然利用预先训练的模型？</p></blockquote><p id="38b8" class="pw-post-body-paragraph kg kh hu ki b kj lp kl km kn lq kp kq kr lr kt ku kv ls kx ky kz lt lb lc ld hn dt translated">答案是<strong class="ki hv">是的</strong>！让我们看一个例子:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="f3d3" class="pb is hu pq b fv pu pv l pw px">val document = new DocumentAssembler()<br/>  .setInputCol("text")<br/>  .setOutputCol("document")</span><span id="1d1f" class="pb is hu pq b fv py pv l pw px">val sentence = new SentenceDetector()<br/>  .setInputCols(Array("document"))<br/>  .setOutputCol("sentence")<br/>  .setExplodeSentences(true)</span><span id="8943" class="pb is hu pq b fv py pv l pw px">val token = new Tokenizer()<br/>  .setInputCols(Array("document"))<br/>  .setOutputCol("token")</span><span id="ac18" class="pb is hu pq b fv py pv l pw px">val normalized = new Normalizer()<br/>  .setInputCols(Array("token"))<br/>  .setOutputCol("normalized")</span><span id="00eb" class="pb is hu pq b fv py pv l pw px">val pos = PerceptronModel.pretrained()<br/>    .setInputCols("sentence", "normalized")<br/>    .setOutputCol("pos")</span><span id="6812" class="pb is hu pq b fv py pv l pw px">val chunker = new Chunker()<br/>  .setInputCols(Array("document", "pos"))<br/>  .setOutputCol("pos_chunked")<br/>  .setRegexParsers(Array(<br/>      "&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;"<br/>    ))</span><span id="87ea" class="pb is hu pq b fv py pv l pw px">val embeddings = WordEmbeddingsModel.pretrained()<br/>    .setOutputCol("embeddings")</span><span id="ecfa" class="pb is hu pq b fv py pv l pw px">val ner = NerDLModel.pretrained()<br/>    .setInputCols("document", "normalized", "embeddings")<br/>    .setOutputCol("ner")</span><span id="8162" class="pb is hu pq b fv py pv l pw px">val nerConverter = new NerConverter()<br/>    .setInputCols("document", "token", "ner")<br/>    .setOutputCol("ner_chunked")</span><span id="4e71" class="pb is hu pq b fv py pv l pw px">val pipeline = new Pipeline().setStages(Array(<br/>      document, <br/>      sentence,<br/>      token, <br/>      normalized,<br/>      pos,<br/>      chunker,<br/>      embeddings,<br/>      ner,<br/>      nerConverter   <br/>))</span></pre><p id="9e0c" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">就是这样！相当简单和活泼。重要的是，您可以为每个注释器设置想要的输入。例如，对于词性标注，我可以使用标记、词干标记、词汇化标记或规范化标记。这可能会改变注释器的结果。NerDLModel 也一样。我为 POS 和 Ner 模型都选择了规范化的令牌，因为我猜我的数据集有点乱，需要清理一下。</p><p id="18ca" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">让我们使用我们定制的管道。如果你了解 Spark ML 管道，它有两个阶段。一个是拟合，即在管道内训练模型。第二是通过将数据转换成新的数据框架来预测新数据。</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="b52e" class="pb is hu pq b fv pu pv l pw px">val nlpPipelineModel = pipeline.<strong class="pq hv">fit</strong>(<strong class="pq hv">muellerFirstVol</strong>)</span><span id="746a" class="pb is hu pq b fv py pv l pw px">val nlpPipelinePrediction = nlpPipelineModel.<strong class="pq hv">transform</strong>(<strong class="pq hv">muellerFirstVol</strong>)</span></pre><p id="d3ea" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">的。fit()在这里是用来装饰的，因为所有的东西都是预先训练好的。我们不需要训练任何东西。transform()是我们使用管道中的模型来创建一个包含所有预测的新数据框架的地方。但是如果我们有自己的模型或者 Spark ML 函数需要训练，那么。fit()需要一些时间来训练模型。</p><p id="c196" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">在本地机器上，这需要大约 3 秒钟来运行。我的笔记本电脑有酷睿 i9、32G 内存和 Vega 20(如果这很重要的话)，所以它是一台相当不错的机器。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qh"><img src="../Images/1f572c3ef385aa300c74d9523c822d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k7gLkiMnhNPN4PNYPOJJPA.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Apache Spark on Local machine</figcaption></figure><p id="74b1" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">这个例子与大数据场景完全不同，在大数据场景中，您需要处理数百万条记录、句子或单词。其实连小数据都算不上。然而，我们使用 Apache Spark 是有原因的！让我们在一个可以分配任务的集群中运行它。</p></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><p id="a70b" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">例如，不久前我有一个更大更复杂的 Spark NLP 管道来处理整个法国大辩论，它被称为“<a class="ae kf" href="https://granddebat.fr/" rel="noopener ugc nofollow" target="_blank"><strong class="ki hv">Le Grand débat Nationale</strong></a>”。</p><div class="jq jr js jt fq ab cb"><figure class="me ju qi mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/088c577dc1c52034cae0362342d219ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*IBWvsipsME9zOlN8Dp_e4g.png"/></div></figure><figure class="me ju qj mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/cb83b9cf428854058467edf9b6fd2257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*6G-cU6KjhkCyZlCz7JnnwQ.png"/></div></figure></div><div class="ab cb"><figure class="me ju qk mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/6b66627ea01b3a0fe3b061cc716fdfdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*S165HRNzI8CNjZoEif6okw.png"/></div></figure><figure class="me ju ql mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/9593777da414c43f857ecac61f8fd2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*iP3dM_qOLkd9OOIzi5pLjw.png"/></div></figure><figure class="me ju qm mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/570e66db0086cfb5e08a0cc8253abfd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*gbX3oZKSgp3PydVwgyDENQ.png"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek qn di qo mq">Politoscope project: <a class="ae kf" href="https://politoscope.org/2019/03/gdn-preliminaires/" rel="noopener ugc nofollow" target="_blank">https://politoscope.org/2019/03/gdn-preliminaires/</a></figcaption></figure></div><p id="079b" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">最终，我能够将我的 Spark NLP 管道放在一个集群中，该集群拥有超过 25 万用户生成的数百万个句子。当你被困在一台机器上时，这些类型的 NLP 项目是非常困难的，甚至几乎是不可能的。</p></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><p id="65cc" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv">回到我们自己的演示</strong>！在集群中，我们需要做的就是将数据帧从 1 个分区(因为它是 1 个文件)重新分区到大约 60 个分区(取决于有多少个执行器，每个执行器有多少个内核，等等。).这样，Spark 可以将任务分配给更多的执行者，并并行运行它们:</p><pre class="jq jr js jt fq pp pq pr ps aw pt dt"><span id="e3d5" class="pb is hu pq b fv pu pv l pw px"><strong class="pq hv">muellerFirstVol</strong>.rdd.getNumPartitions<br/>val newMuellerFirstVolDF = <strong class="pq hv">muellerFirstVol</strong>.repartition(60)</span><span id="819b" class="pb is hu pq b fv py pv l pw px">//Now this runs in parallel</span><span id="349b" class="pb is hu pq b fv py pv l pw px">val nlpPipelineModel = pipeline.<strong class="pq hv">fit</strong>(<strong class="pq hv">newMuellerFirstVolDF</strong>)<br/>val nlpPipelinePrediction = nlpPipelineModel.<strong class="pq hv">transform</strong>(<strong class="pq hv">newMuellerFirstVolDF</strong>)</span></pre><p id="1b16" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated"><strong class="ki hv">注意</strong>:我创建新数据帧的原因是，rdd 本质上是不可变的。所以你不能只改变他们的分区数量。但是，您可以创建具有不同数量分区的新 rdd(数据帧)。</p><p id="1fe8" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">这一次，在集群上运行管道用了<strong class="ki hv"> 0.4 秒，而不是 3 秒</strong>。也许在一个作业中快几秒钟并不值得注意，但是您可以将它应用于数万个 pdf 或数百万条记录，这样我们就可以利用 Apache Spark 分布式引擎。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qp"><img src="../Images/ca087f076c3c5215be369947fd483e33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*My95VO9lG73i_EWjfNJJmg.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Apache Spark on a cluster</figcaption></figure><p id="4656" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">现在让我们来看看我们定制的管道的结果。我想做的是对 NER 模型中的组块进行简单的分组:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qq"><img src="../Images/b49bfa4358c8d18fbdd1beab427c569a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q6OyR59guR2tcUBFo8-KWQ.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Spark NLP: NER chunking on Mueller Report</figcaption></figure><p id="6e04" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">正如你所看到的，它需要一些数据清理，以排除错误的实体，如“p”。我们将在第二部分。如果我们在 Mueller 报告的第一卷中创建这些命名实体的共现矩阵，我们可以在 Gephi 中可视化它们，我将在第三部分解释如何实现:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff qr"><img src="../Images/49b750e814950d53c69f942683643d21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rYlWGuS17s4fISpjngJe6Q.png"/></div></div></figure><div class="jq jr js jt fq ab cb"><figure class="me ju qs mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/4cdf964aadcb81184927f0ff397a6f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*ozvyGCKo_87ZYkAwkK5U7A.png"/></div></figure><figure class="me ju qt mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/c4741a67658ce452cab52e701661d127.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*9UsjRpETkB4CvmvrhwgOHA.png"/></div></figure><figure class="me ju qt mg mh mi mj paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><img src="../Images/6888931369cd4499328d47ddd704d642.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*ZPJkOj2N0gLoiahOPvlsLA.png"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek qu di qv mq">Spark NLP: Mueller Report Named Entities co-occurrence graph</figcaption></figure></div></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><h1 id="32f0" class="ir is hu bd it iu my iw ix iy mz ja jb jc na je jf jg nb ji jj jk nc jm jn jo dt translated">接下来是什么:</h1><p id="ac1d" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">恭喜你！现在，您已经知道如何使用 Spark NLP 预训练管道和模型在 Apache Spark 中执行 NLP 任务。这为您提供了 Apache Spark 中分布式引擎的优势，可以在数千个 CPU 内核上运行大规模 NLP 作业。</p><p id="b95b" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">请记住，这是开始使用 Spark NLP 的一种非常快速简单的方法。在下一部分中，我想试验一个由 BERT 单词嵌入而不是 GloVe 训练的 NER 模型，在 Spark NLP 中从通用依存关系训练我自己的 POS 标记器模型，运行一些数据清洗，最后通过 POS 和 NER 分块提取一些关键字/短语。</p></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><h1 id="b7cd" class="ir is hu bd it iu my iw ix iy mz ja jb jc na je jf jg nb ji jj jk nc jm jn jo dt translated">资源:</h1><ul class=""><li id="5631" class="nr ns hu ki b kj nd kn ne kr qw kv qx kz qy ld nw nx ny nz dt translated"><a class="ae kf" href="https://github.com/JohnSnowLabs/spark-nlp" rel="noopener ugc nofollow" target="_blank"><em class="md">GitHub 上的 Spark NLP</em></a></li><li id="f9d7" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/" rel="noopener ugc nofollow" target="_blank"> <em class="md"> Spark NLP 网站</em> </a></li><li id="b292" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://github.com/JohnSnowLabs/spark-nlp-workshop" rel="noopener ugc nofollow" target="_blank"> <em class="md"> Spark NLP 示例</em> </a></li><li id="128c" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/pipelines" rel="noopener ugc nofollow" target="_blank">火花 NLP 管道</a></li><li id="8093" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://nlp.johnsnowlabs.com/docs/en/models" rel="noopener ugc nofollow" target="_blank"> Spark NLP 车型</a></li><li id="ef2e" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://join.slack.com/t/spark-nlp/shared_invite/enQtNjA4MTE2MDI1MDkxLWVjNWUzOGNlODg1Y2FkNGEzNDQ1NDJjMjc3Y2FkOGFmN2Q3ODIyZGVhMzU0NGM3NzRjNDkyZjZlZTQ0YzY1N2I" rel="noopener ugc nofollow" target="_blank"> <em class="md">火花 NLP 松弛</em> </a></li><li id="7226" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://blog.dominodatalab.com/comparing-the-functionality-of-open-source-natural-language-processing-libraries/" rel="noopener ugc nofollow" target="_blank"> <em class="md"> Spark NLP vs 其他 NLP 库</em> </a></li><li id="8289" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" href="https://www.oreilly.com/ideas/comparing-production-grade-nlp-libraries-training-spark-nlp-and-spacy-pipelines" rel="noopener ugc nofollow" target="_blank"> <em class="md">火花 NLP vs 空间</em> </a></li><li id="f6b7" class="nr ns hu ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz dt translated"><a class="ae kf" rel="noopener" href="/@saif1988/spark-nlp-walkthrough-powered-by-tensorflow-9965538663fd"><em class="md">tensor flow 供电的 Spark NLP</em></a></li></ul><h1 id="ee7b" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated">问题？</h1><p id="52f3" class="pw-post-body-paragraph kg kh hu ki b kj nd kl km kn ne kp kq kr nf kt ku kv ng kx ky kz nh lb lc ld hn dt translated">如果您有任何问题，请在这里留言或在<a class="ae kf" href="https://twitter.com/MaziyarPanahi" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上发推文给我。</p></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><p id="29cb" class="pw-post-body-paragraph kg kh hu ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">觉得这篇文章有趣？请在媒体上关注我(<a class="np nq gr" href="https://medium.com/u/fe4b780b61e1?source=post_page-----32490a8f8f12--------------------------------" rel="noopener" target="_blank"> Maziyar Panahi </a>)以获取未来的文章和掌声👏如果你喜欢的话，来几次吧！😊</p></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><figure class="jq jr js jt fq ju"><div class="bz el l di"><div class="qz ra l"/></div></figure></div></div>    
</body>
</html>