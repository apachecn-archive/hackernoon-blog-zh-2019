<html>
<head>
<title>Logistic Regression with TensorFlow and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 和 Keras 的逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/logistic-regression-with-tensorflow-and-keras-83d2487aed89#2019-01-10">https://medium.com/hackernoon/logistic-regression-with-tensorflow-and-keras-83d2487aed89#2019-01-10</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="9a37" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">在这篇文章中，Armando Fandango 通过 TensorFlow 和 Keras 学习逻辑回归，他是人工智能产品的发明者，利用深度学习、机器学习、分布式计算和计算方法方面的专业知识。他还在初创公司和大型企业中担任首席数据科学家和总监等思想领袖角色。</em></p><p id="0189" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">本文将向您展示如何实现一种称为多项式逻辑回归的分类算法来识别手写数字数据集。您将使用 TensorFlow core 和 Keras 来实现这个逻辑回归算法。</p><h1 id="0428" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">张量流逻辑回归</h1><p id="be1d" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated">关于多类分类的一个最流行的例子是标记手写数字的图像。本例中的类别或标签为<strong class="it hv"> <em class="jp"> {0，1，2，3，4，5，6，7，8，9} </em> </strong>。您将使用的数据集通常被称为 MNIST，可通过以下链接获得:<a class="ae kt" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">http://yann.lecun.com/exdb/mnist/</a>。MNIST 数据集有 60，000 幅用于训练的图像和 10，000 幅用于测试的图像。数据集中的图像如下所示:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff ku"><img src="../Images/e08b2c7b92d48629a07eef1a463f8d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*qGxr1hmyNv9ftAb6MEibZA.png"/></div></figure><p id="d52f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">1.首先，从<a class="ae kt" href="https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Projects" rel="noopener ugc nofollow" target="_blank">https://github . com/packt publishing/tensor flow-Machine-Learning-Projects</a>导入<code class="eh lc ld le lf b">datasetslib</code>，一个库:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="d30c" class="lk jr hu lf b fv ll lm l ln lo">DSLIB_HOME = '../datasetslib'</span><span id="e47a" class="lk jr hu lf b fv lp lm l ln lo">import sys</span><span id="f486" class="lk jr hu lf b fv lp lm l ln lo">if not DSLIB_HOME in sys.path:</span><span id="40ac" class="lk jr hu lf b fv lp lm l ln lo">sys.path.append(DSLIB_HOME)</span><span id="8dfd" class="lk jr hu lf b fv lp lm l ln lo">%reload_ext autoreload</span><span id="f63a" class="lk jr hu lf b fv lp lm l ln lo">%autoreload 2</span><span id="6d15" class="lk jr hu lf b fv lp lm l ln lo">import datasetslib as dslib</span><span id="d4de" class="lk jr hu lf b fv lp lm l ln lo">from datasetslib.utils import imutil</span><span id="05e5" class="lk jr hu lf b fv lp lm l ln lo">from datasetslib.utils import nputil</span><span id="47b2" class="lk jr hu lf b fv lp lm l ln lo">from datasetslib.mnist import MNIST</span></pre><p id="9222" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">2.将路径设置为您的主目录中的<code class="eh lc ld le lf b">datasets</code>文件夹，这是您想要存储所有<code class="eh lc ld le lf b">datasets</code>的位置:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="5b94" class="lk jr hu lf b fv ll lm l ln lo">import os</span><span id="2b20" class="lk jr hu lf b fv lp lm l ln lo">datasets_root = os.path.join(os.path.expanduser('~'),'datasets')</span></pre><p id="246f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">3.使用<code class="eh lc ld le lf b">datasetslib</code>获取 MNIST 数据，并打印图形以确保数据正确加载:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="2da1" class="lk jr hu lf b fv ll lm l ln lo">mnist=MNIST()</span><span id="0f62" class="lk jr hu lf b fv lp lm l ln lo">x_train,y_train,x_test,y_test=mnist.load_data()</span><span id="4a3f" class="lk jr hu lf b fv lp lm l ln lo">mnist.y_onehot = True</span><span id="c498" class="lk jr hu lf b fv lp lm l ln lo">mnist.x_layout = imutil.LAYOUT_NP</span><span id="d77f" class="lk jr hu lf b fv lp lm l ln lo">x_test = mnist.load_images(x_test)</span><span id="5036" class="lk jr hu lf b fv lp lm l ln lo">y_test = nputil.onehot(y_test)</span><span id="07c3" class="lk jr hu lf b fv lp lm l ln lo">print('Loaded x and y')</span><span id="b289" class="lk jr hu lf b fv lp lm l ln lo">print('Train: x:{}, y:{}'.format(len(x_train),y_train.shape))</span><span id="6658" class="lk jr hu lf b fv lp lm l ln lo">print('Test: x:{}, y:{}'.format(x_test.shape,y_test.shape))</span></pre><p id="6426" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">4.定义用于训练模型的超参数:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="7136" class="lk jr hu lf b fv ll lm l ln lo">learning_rate = 0.001</span><span id="a964" class="lk jr hu lf b fv lp lm l ln lo">n_epochs = 5</span><span id="6deb" class="lk jr hu lf b fv lp lm l ln lo">mnist.batch_size = 100</span></pre><p id="1196" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">5.为简单模型定义占位符和参数:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="ebcc" class="lk jr hu lf b fv ll lm l ln lo"># define input images</span><span id="4529" class="lk jr hu lf b fv lp lm l ln lo">x = tf.placeholder(dtype=tf.float32, shape=[None, mnist.n_features])</span><span id="f548" class="lk jr hu lf b fv lp lm l ln lo"># define output labels</span><span id="7670" class="lk jr hu lf b fv lp lm l ln lo">y = tf.placeholder(dtype=tf.float32, shape=[None, mnist.n_classes])</span><span id="e4e2" class="lk jr hu lf b fv lp lm l ln lo"># model parameters</span><span id="ca65" class="lk jr hu lf b fv lp lm l ln lo">w = tf.Variable(tf.zeros([mnist.n_features, mnist.n_classes]))</span><span id="a33c" class="lk jr hu lf b fv lp lm l ln lo">b = tf.Variable(tf.zeros([mnist.n_classes]))</span></pre><p id="9732" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">6.用<code class="eh lc ld le lf b">logits</code>和<code class="eh lc ld le lf b">y_hat</code>定义型号:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="1b23" class="lk jr hu lf b fv ll lm l ln lo">logits = tf.add(tf.matmul(x, w), b)</span><span id="0d57" class="lk jr hu lf b fv lp lm l ln lo">y_hat = tf.nn.softmax(logits)</span></pre><p id="b8f1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">7.定义<code class="eh lc ld le lf b">loss</code>功能:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="42e7" class="lk jr hu lf b fv ll lm l ln lo">epsilon = tf.keras.backend.epsilon()</span><span id="5be8" class="lk jr hu lf b fv lp lm l ln lo">y_hat_clipped = tf.clip_by_value(y_hat, epsilon, 1 - epsilon)</span><span id="0dc6" class="lk jr hu lf b fv lp lm l ln lo">y_hat_log = tf.log(y_hat_clipped)</span><span id="4bcb" class="lk jr hu lf b fv lp lm l ln lo">cross_entropy = -tf.reduce_sum(y * y_hat_log, axis=1)</span><span id="f068" class="lk jr hu lf b fv lp lm l ln lo">loss_f = tf.reduce_mean(cross_entropy)</span></pre><p id="aded" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">8.定义<code class="eh lc ld le lf b">optimizer</code>功能:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="2932" class="lk jr hu lf b fv ll lm l ln lo">optimizer = tf.train.GradientDescentOptimizer</span><span id="4fef" class="lk jr hu lf b fv lp lm l ln lo">optimizer_f = optimizer(learning_rate=learning_rate).minimize(loss_f)</span></pre><p id="4ef9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">9.定义函数以检查训练模型的准确性:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="63c1" class="lk jr hu lf b fv ll lm l ln lo">predictions_check = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))</span><span id="4b7e" class="lk jr hu lf b fv lp lm l ln lo">accuracy_f = tf.reduce_mean(tf.cast(predictions_check, tf.float32))</span></pre><p id="e634" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">10.在 TensorFlow 会话中为每个历元运行<code class="eh lc ld le lf b">training</code>循环:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="3d31" class="lk jr hu lf b fv ll lm l ln lo">n_batches = int(60000/mnist.batch_size)</span><span id="42e4" class="lk jr hu lf b fv lp lm l ln lo">with tf.Session() as tfs:</span><span id="4f0e" class="lk jr hu lf b fv lp lm l ln lo">tf.global_variables_initializer().run()</span><span id="92fe" class="lk jr hu lf b fv lp lm l ln lo">for epoch in range(n_epochs):</span><span id="b947" class="lk jr hu lf b fv lp lm l ln lo">mnist.reset_index()</span><span id="f2e2" class="lk jr hu lf b fv lp lm l ln lo">for batch in range(n_batches):</span><span id="78ec" class="lk jr hu lf b fv lp lm l ln lo">x_batch, y_batch = mnist.next_batch()</span><span id="8875" class="lk jr hu lf b fv lp lm l ln lo">feed_dict={x: x_batch, y: y_batch}</span><span id="3ed4" class="lk jr hu lf b fv lp lm l ln lo">batch_loss,_ = tfs.run([loss_f, optimizer_f],feed_dict=feed_dict )</span><span id="2381" class="lk jr hu lf b fv lp lm l ln lo">#print('Batch loss:{}'.format(batch_loss))</span></pre><p id="1ce0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">11.使用之前创建的相同 TensorFlow 会话中的测试数据，为每个历元运行评估函数:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="efe0" class="lk jr hu lf b fv ll lm l ln lo">feed_dict = {x: x_test, y: y_test}</span><span id="9042" class="lk jr hu lf b fv lp lm l ln lo">accuracy_score = tfs.run(accuracy_f, feed_dict=feed_dict)</span><span id="8e7e" class="lk jr hu lf b fv lp lm l ln lo">print('epoch {0:04d}  accuracy={1:.8f}'</span><span id="6e44" class="lk jr hu lf b fv lp lm l ln lo">.format(epoch, accuracy_score))</span></pre><p id="331c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">您将获得以下输出:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="282c" class="lk jr hu lf b fv ll lm l ln lo">epoch 0000 accuracy=0.73280001 epoch 0001 accuracy=0.72869998 epoch 0002 accuracy=0.74550003 epoch 0003 accuracy=0.75260001 epoch 0004 accuracy=0.74299997</span></pre><p id="641e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">给你。您刚刚使用 TensorFlow 训练了您的第一个逻辑回归模型，用于对手写数字图像进行分类，并获得了 74.3%的准确率。现在，看看在 Keras 中编写相同的模型如何使这个过程变得更加容易。</p><h1 id="f999" class="jq jr hu bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dt translated">使用 Keras 的逻辑回归</h1><p id="6b27" class="pw-post-body-paragraph ir is hu it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hn dt translated"><strong class="it hv"> Keras </strong>是一个高级库，是 TensorFlow 的一部分。在本节中，您将使用 Keras 重建之前使用 TensorFlow core 构建的相同模型:</p><p id="46a7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">1.Keras 采用不同格式的数据，因此您必须首先使用<code class="eh lc ld le lf b">datasetslib</code>重新格式化数据:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="e5fd" class="lk jr hu lf b fv ll lm l ln lo">x_train_im = mnist.load_images(x_train)</span><span id="dfcb" class="lk jr hu lf b fv lp lm l ln lo">x_train_im, x_test_im = x_train_im / 255.0, x_test / 255.0</span></pre><p id="8881" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在前面的代码中，在缩放训练图像和测试图像之前，将训练图像加载到内存中，方法是将它们除以<code class="eh lc ld le lf b">255</code>。</p><p id="6e2e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">2.然后，您构建模型:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="1148" class="lk jr hu lf b fv ll lm l ln lo">model = tf.keras.models.Sequential([</span><span id="1637" class="lk jr hu lf b fv lp lm l ln lo">tf.keras.layers.Flatten(),</span><span id="1f62" class="lk jr hu lf b fv lp lm l ln lo">tf.keras.layers.Dense(10, activation=tf.nn.softmax)</span><span id="c484" class="lk jr hu lf b fv lp lm l ln lo">])</span></pre><p id="ff03" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">3.用<code class="eh lc ld le lf b">sgd</code>优化器编译模型。将分类熵设置为<code class="eh lc ld le lf b">loss</code>函数，将准确度设置为度量标准来测试模型:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="4772" class="lk jr hu lf b fv ll lm l ln lo">model.compile(optimizer='sgd',</span><span id="9a16" class="lk jr hu lf b fv lp lm l ln lo">loss='sparse_categorical_crossentropy',</span><span id="5ed3" class="lk jr hu lf b fv lp lm l ln lo">metrics=['accuracy'])</span></pre><p id="abaf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">4.使用图像和标签的训练集为<code class="eh lc ld le lf b">5</code>时代训练模型:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="e193" class="lk jr hu lf b fv ll lm l ln lo">model.fit(x_train_im, y_train, epochs=5)</span><span id="25de" class="lk jr hu lf b fv lp lm l ln lo">Epoch 1/5</span><span id="bdca" class="lk jr hu lf b fv lp lm l ln lo">60000/60000 [==============================] - 3s 45us/step - loss: 0.7874 - acc: 0.8095</span><span id="6a7a" class="lk jr hu lf b fv lp lm l ln lo">Epoch 2/5</span><span id="028f" class="lk jr hu lf b fv lp lm l ln lo">60000/60000 [==============================] - 3s 42us/step - loss: 0.4585 - acc: 0.8792</span><span id="d597" class="lk jr hu lf b fv lp lm l ln lo">Epoch 3/5</span><span id="dfb0" class="lk jr hu lf b fv lp lm l ln lo">60000/60000 [==============================] - 2s 42us/step - loss: 0.4049 - acc: 0.8909</span><span id="ce3b" class="lk jr hu lf b fv lp lm l ln lo">Epoch 4/5</span><span id="18de" class="lk jr hu lf b fv lp lm l ln lo">60000/60000 [==============================] - 3s 42us/step - loss: 0.3780 - acc: 0.8965</span><span id="c746" class="lk jr hu lf b fv lp lm l ln lo">Epoch 5/5</span><span id="10f7" class="lk jr hu lf b fv lp lm l ln lo">60000/60000 [==============================] - 3s 42us/step - loss: 0.3610 - acc: 0.9012</span><span id="643a" class="lk jr hu lf b fv lp lm l ln lo">10000/10000 [==============================] - 0s 24us/step</span></pre><p id="af92" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">5.用测试数据评估模型:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="e697" class="lk jr hu lf b fv ll lm l ln lo">model.evaluate(x_test_im, nputil.argmax(y_test))</span></pre><p id="cca0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">您将获得以下评估分数作为输出:</p><pre class="kv kw kx ky fq lg lf lh li aw lj dt"><span id="4672" class="lk jr hu lf b fv ll lm l ln lo">[0.33530342621803283, 0.9097]</span></pre><p id="575a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">哇！使用 Keras，可以获得更高的精度。在这里，你达到了大约 90%的准确率。这是因为 Keras 内部设置了许多最佳值，以便您可以快速开始构建模型。</p><p id="afbe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">如果你觉得这篇文章有意思，可以探索</em> <a class="ae kt" href="https://www.amazon.com/TensorFlow-Machine-Learning-Projects-computations-ebook/dp/B07GDHJBDZ" rel="noopener ugc nofollow" target="_blank"> TensorFlow 机器学习项目</a> <em class="jp">实现 TensorFlow 的 TensorBoard、TensorFlow.js、TensorFlow Probability、TensorFlow Lite 等产品，构建智能自动化项目。在</em> <a class="ae kt" href="https://www.packtpub.com/big-data-and-business-intelligence/tensorflow-machine-learning-projects" rel="noopener ugc nofollow" target="_blank"> TensorFlow 机器学习项目</a> <em class="jp">的帮助下，您不仅可以学习如何使用不同的数据集构建高级项目，还可以使用 TensorFlow 生态系统中的一系列库来应对常见挑战。</em></p></div></div>    
</body>
</html>