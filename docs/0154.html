<html>
<head>
<title>Digital Humans Need Digital Ethics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数字人类需要数字伦理</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/digital-humans-need-digital-ethics-eda02c92b8d7#2019-01-07">https://medium.com/hackernoon/digital-humans-need-digital-ethics-eda02c92b8d7#2019-01-07</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/aba91ec260fcd1c8c265dd62cc948890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EA_-JrrQ7dt-nk9Go9q1mg.jpeg"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Emotional mural at our Belfast HQ, by local artist &amp; friend Key Largey – a constant reminder to keep us on the right track</figcaption></figure><p id="5213" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">2018 年是道德和权利的重要一年，因为新形式的技术和媒体与我们认为人类社会可以接受的行为发生了冲突。现在，像<a class="ae ke" href="https://sensum.co" rel="noopener ugc nofollow" target="_blank"> ours </a>这样的公司建立了<a class="ae ke" href="https://hackernoon.com/tagged/digital" rel="noopener ugc nofollow" target="_blank"> digital </a> <a class="ae ke" href="https://hackernoon.com/tagged/tools" rel="noopener ugc nofollow" target="_blank"> tools </a>越来越个人化，我们需要继续发展我们的观念，即做正确的事情意味着什么。</p><p id="1ea4" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我们相信，下一代人工智能技术的一个关键组成部分将是<em class="kf">数字共情</em>。通过将我们的生理和行为数据输入智能系统，它们将能够理解我们的情绪，并学会做出适当的反应。我们可以期待这种移情技术给我们带来更丰富、更有益的人机交互。但这也让我们有很多要担心的。</p><p id="11cb" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">以下是我和我的团队这些天来思考的一些主要问题，因为我们的物种冒险进入了一个日益智能、互联技术的未知领域。</p><ol class=""><li id="c8d3" class="kg kh hu ji b jj jk jn jo jr ki jv kj jz kk kd kl km kn ko dt translated">立法与创新:找到正确的治理水平。</li><li id="dc0d" class="kg kh hu ji b jj kp jn kq jr kr jv ks jz kt kd kl km kn ko dt translated">社会启发法:默认做“正确的事情”。</li><li id="e627" class="kg kh hu ji b jj kp jn kq jr kr jv ks jz kt kd kl km kn ko dt translated">个人数据:所有权和控制权的新模式。</li><li id="1465" class="kg kh hu ji b jj kp jn kq jr kr jv ks jz kt kd kl km kn ko dt translated">超越人类主义:将权利延伸到肉体之外。</li><li id="ec93" class="kg kh hu ji b jj kp jn kq jr kr jv ks jz kt kd kl km kn ko dt translated">商业困境:从他人的数据中获利。</li></ol><p id="bbd4" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">依次解决每个问题，然后…</p><h1 id="c4b4" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">1.立法与创新</h1><p id="a734" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">关于未来，我们知道的一件事是我们什么都不知道。没有人能确切地告诉你未来几年将会出现什么样的人机交互，也没有人能确切地告诉你这些人机交互的道德底线在哪里。毫无疑问，我们的世界最终会有适当的立法、指导和规范，但它们可能会遵循一些早期的错误，而不是先发制人。</p><p id="7485" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">最近的一个例子是<a class="ae ke" href="https://ico.org.uk/for-organisations/guide-to-the-general-data-protection-regulation-gdpr/" rel="noopener ugc nofollow" target="_blank"> GDPR </a>，今年在欧洲推出，以回应多年来对用户个人数据的可疑处理。像 GDPR 这样的措施很重要，但它也是相对较小的一步，跟随着我们作为一个物种所经历的巨大的技术和社会冲击。正式的政策在发布时往往已经过时。</p><p id="1e3f" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">这不仅仅是因为立法往往来得太晚。在颠覆性创新的早期阶段，法律置身事外可能也是有益的，甚至是必要的。我们已经看到，互联网在很大程度上保持了狂野西部式的访问自由。这可能会导致假新闻和破坏行业的数据盗版等痛苦，但它也以前所未有的方式团结、教育和娱乐了世界。因此，当前关于保持网络中立的问题令人不快，因为世界正在为一个长期稳定的位置而努力。</p><h1 id="ff24" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">2.社会启发法</h1><p id="7315" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">我怀疑我们会看到我和我的同事正在开发的移情技术也将展开类似的演变，这种技术目前刚刚进入<a class="ae ke" href="https://en.wikipedia.org/wiki/Diffusion_of_innovations" rel="noopener ugc nofollow" target="_blank">创新-采用曲线</a>的初始阶段。一些完全不同的服务已经出现，人们开始发现什么适合他们，什么不适合他们。在接下来的几年里，借助人工智能爆炸的东风，像我们这样的公司正在冒险探索移情技术，这种技术将变得无处不在，被捆绑为智能汽车、智能手机、智能手表、智能家居……“智能”任何东西的更大包装的一部分。在这个过渡阶段，我们不能指望政府和法律帮助我们走在正确的道路上，也许我们不应该这样做。相反，我们需要依靠社会规范和启发式的模糊框架。你知道，良好的人际关系。</p><p id="eb03" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我担心游说人们不要使用他们从一开始就不完全信任的服务是浪费精力，尽管这种行为应该是理所当然的。我知道我有罪。我们已经看到人们多么容易放弃他们的数据来换取娱乐或有用的服务，特别是如果他们得到更便宜的服务。我们在社交网络中看到了这一点，社交网络可以免费交易我们提供的个人数据，现在我们不得不处理像<a class="ae ke" href="https://www.theguardian.com/news/2018/mar/26/the-cambridge-analytica-files-the-story-so-far" rel="noopener ugc nofollow" target="_blank">剑桥分析公司丑闻</a>这样的狗屎事情。好吧，所以用户应该是有洞察力的，但是从另一方面来说，组织不能通过说他们的用户不介意牺牲一点自由和隐私来获得免费的东西来逃避责任。</p><p id="2642" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">现在，像 GDPR 这样的机制正在抵制个人数据滥用，但人们仍然在这一过程中受到伤害。组织不能等到立法出台后才主动承担责任来减少此类入侵事件。</p><p id="fcf0" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">这么说感觉像是在逃避，但采用生理或心理数据分析等亲密行为的组织(公共和私人)只需要<em class="kf">做正确的事情</em>。他们需要避免剥削他们的用户。我们的用户需要睁大眼睛寻找这种剥削的迹象，而不是盲目地采用提供给我们的下一个闪亮的功能。</p><h1 id="09a6" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">3.个人资料</h1><p id="c5d6" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">GDPR 背后的一些原则可能会为我们迈向下一代数字权利、规则和伦理提供一个良好的开端。GDPR 的基础是增强用户对其数据的授权和所有权。对于个人用户来说，GDPR 的目标是提供对他们数据的权利，比如知情权、访问权和删除权。这是一个好的开始，但如果我们进一步推断呢？凭借一点想象力，或许我们可以为我们的数字生活制定一个更全面的监管框架。</p><p id="14fa" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">最终，每个个人用户都应该拥有他们的个人数据，无论这些数据在全球范围内传播到哪里，并有权决定如何使用这些数据。当然，这种全球数据所有权的概念存在大量的实用性问题。这不仅需要巨大的社区支持，还需要对数字服务的基础架构进行一些改变。但是像区块链这样的技术已经是很有前途的潜在解决方案，比如数字自我主权身份(这里巧妙地解释了<a class="ae ke" rel="noopener" href="/@AlexPreukschat/self-sovereign-identity-a-guide-to-privacy-for-your-digital-identity-5b9e95677778">)。</a></p><h1 id="47d5" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">4.超人类主义</h1><p id="dd42" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">2018 年是<a class="ae ke" href="http://www.un.org/en/universal-declaration-human-rights/" rel="noopener ugc nofollow" target="_blank">世界人权宣言</a>发表 70 周年。从那以后，事情发生了变化。</p><p id="74cf" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">就在《世界人权宣言》发表的六天前，乔治·奥威尔提交了他 1984 年的最终手稿，描述了一个反乌托邦式的普遍监控的未来，这种未来随着每一个过去的十年都变得越来越贴切。同年，曼彻斯特大学发明了世界上第一台电子存储程序计算机。它由十七条指令组成。当我们每个人的口袋里都装着一台功能强大得不可思议的电脑时，我们现在需要以怎样的不同方式来思考权利？当技术可以自己思考时，什么才是合适的行为？</p><p id="aa21" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">与其说我们正在盲目地步入一个人工智能技术时代，不如说技术正在崛起，掩盖我们的现状。无所事事不会让你远离日益智能、复杂和普及的数字系统。因此，任何保护和赋予我们权力的条款都必须像创新一样广泛。也许对于将与人工智能和物联网生活在一起的一代人来说，需要一个新的普世权利宣言。如果是这样，这些权利可能需要超越大多数人目前认为的“人”。</p><p id="27de" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">我们这个物种有自我改造的悠久历史，用技术增强我们的自然能力，从火和衣服到助听器和智能手机。很容易为“他们”机器和“我们”人类宣传一套不同的伦理，而我们却继续模糊两者之间的界限。与此同时，通过我们在线活动产生的每一个数据点，我们塑造了我们自己更详细的数字版本。因此，随着人类、电子人、人工智能和数字自我的不断融合，我们可能不得不设计一套适用于整个连续体的伦理——也许会引出一个 <a class="ae ke" href="https://en.wikipedia.org/wiki/Transhumanism" rel="noopener ugc nofollow" target="_blank"> <strong class="ji hv">超人类</strong> </a> <strong class="ji hv">权利</strong>的<strong class="ji hv">普遍宣言。</strong></p><figure class="ly lz ma mb fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lx"><img src="../Images/218d786049e70d0c63bca8ce77e18f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCBZAsp-Ct5EI6KouKKUiA.jpeg"/></div></div></figure><h1 id="b019" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">5.商业困境</h1><p id="8fe5" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">我们是一家初创公司，仍然透过玫瑰色的镜片凝视着我们想象中为后代构建的数字乌托邦。在这个早期阶段，我们很容易说教和预言，而像移情人工智能这样的技术仍然处于萌芽状态。我们只是开始在这个新的领域表明我们的道德立场。但是，我们想要成为的公司已经面临商业驱动的挑战。拒绝那些能保证你未来几个月生意的客户和项目并不容易。我们已经做了几次，但这在经济上是痛苦的。此外，当我们在本质上不可知的未来公开定义我们的道德立场时——这些主张可能会影响我们的声誉或限制我们的潜在市场——我们会感到脆弱和暴露。</p><p id="12de" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">但我们并不孤单。任何人建立一个高度依赖个人用户数据的存储、分析或交易，或者任何其他亲密的人机交互的商业模式，都不能忽视他们工作的道德含义。他们必须划清界限，并坚持到底。尽管这样做可能很可怕，但这并不勇敢，这只是应该做的事情。但是振作起来，我们发现我们的客户和顾客，通常是大型全球品牌，很欣赏这一点。它们也是由人类管理的。如果可以选择，他们中的许多人更喜欢负责任的道路。</p><p id="60df" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">做正确的事情通常对企业有益。</p><h1 id="a8e4" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">数字人类时代的新社会</h1><p id="7f33" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">早在 5 月份，我们的首席执行官兼联合创始人加韦恩·莫瑞森参加了 rights con 的一些小组讨论，全球社区的成员聚集在一起讨论数字时代的各种权利问题。几天后，GDPR 踢了进来。类似这样的积极活动是在脸书丑闻和网络中立辩论等一些极具争议的事件背景下展开的。现在空气中弥漫着某种东西。</p><p id="8fcf" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">这篇文章只是一个广泛的开始练习，将对话扩展到更广泛的受众。还有更多的话要说，更多的事要做。细节需要充实。解决方案需要测试、选择和实施。但是我们不想再离开它了。</p><p id="7a48" class="pw-post-body-paragraph jg jh hu ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated">随着我们继续让我们的机器接触越来越多关于我们身体、思想和行为的隐私和准确的数据，我们的机器同时也在向我们在人类身份光谱上的位置靠近。我们正把自己接入几乎无所不包的互联网，这让我们的数字自我变得越来越聪明、越来越普及、越来越强大。我们的数字自我需要我们的爱，我们需要为我们的数字未来找到一种新的伦理和权利模式。</p><h1 id="1986" class="ku kv hu bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">进一步阅读</h1><p id="4b5e" class="pw-post-body-paragraph jg jh hu ji b jj ls jl jm jn lt jp jq jr lu jt ju jv lv jx jy jz lw kb kc kd hn dt translated">我们有几个相关的故事:</p><ul class=""><li id="d14d" class="kg kh hu ji b jj jk jn jo jr ki jv kj jz kk kd mc km kn ko dt translated"><a class="ae ke" href="https://hackernoon.com/how-to-engineer-trust-in-the-age-of-autonomy-dbba1f2c0c71" rel="noopener ugc nofollow" target="_blank">如何在自治时代创造信任</a></li><li id="c819" class="kg kh hu ji b jj kp jn kq jr kr jv ks jz kt kd mc km kn ko dt translated"><a class="ae ke" rel="noopener" href="/@ben.bland/alexa-hug-me-exploring-human-machine-emotional-relations-1f0f6e04e1db"> Alexa，拥抱我:探索人机情感关系</a></li></ul><figure class="ly lz ma mb fq iv"><div class="bz el l di"><div class="md me l"/></div></figure></div></div>    
</body>
</html>